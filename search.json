[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":" website work--progress 2nd edition “R Data Science”. book teach data science R: ’ll learn get data R, get useful structure, transform , visualise model .\n book, find practicum skills data science.\nJust chemist learns clean test tubes stock lab, ’ll learn clean data draw plots—many things besides.\nskills allow data science happen, find best practices things R.\n’ll learn use grammar graphics, literate programming, reproducible research save time.\n’ll also learn manage cognitive resources facilitate discoveries wrangling, visualising, exploring data.website (always ) free use, licensed Creative Commons Attribution-NonCommercial-NoDerivs 3.0 License.\n’d like physical copy book, can order amazon; published O’Reilly January 2017.\n’d like give back please make donation Kākāpō Recovery: kākāpō (appears cover R4DS) critically endangered native NZ parrot; 213 left.Please note R4DS uses Contributor Code Conduct.\ncontributing book, agree abide terms.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Welcome","heading":"Acknowledgements","text":"R4DS collaborative effort many people contributed fixes improvements via pull request: adi pradhan (@adidoit), Andrea Gilardi (@agila5), Ajay Deonarine (@ajay-d), @AlanFeder, pete (@alonzi), Alex (@ALShum), Andrew Landgraf (@andland), @andrewmacfarland, Michael Henry (@aviast), Mara Averick (@batpigandme), Brent Brewington (@bbrewington), Bill Behrman (@behrman), Ben Herbertson (@benherbertson), Ben Marwick (@benmarwick), Ben Steinberg (@bensteinberg), Brandon Greenwell (@bgreenwell), Brett Klamer (@bklamer), Christian Mongeau (@chrMongeau), Cooper Morris (@coopermor), Colin Gillespie (@csgillespie), Rademeyer Vermaak (@csrvermaak), Abhinav Singh (@curious-abhinav), Curtis Alexander (@curtisalexander), Christian G. Warden (@cwarden), Kenny Darrell (@darrkj), David Rubinger (@davidrubinger), David Clark (@DDClark), Derwin McGeary (@derwinmcgeary), Daniel Gromer (@dgromer), @djbirke, Devin Pastoor (@dpastoor), Julian (@duju211), Dylan Cashman (@dylancashman), Dirk Eddelbuettel (@eddelbuettel), Edwin Thoen (@EdwinTh), Ahmed El-Gabbas (@elgabbas), Eric Watt (@ericwatt), Erik Erhardt (@erikerhardt), Etienne B. Racine (@etiennebr), Everett Robinson (@evjrob), Flemming Villalona (@flemingspace), Floris Vanderhaeghe (@florisvdh), Garrick Aden-Buie (@gadenbuie), Garrett Grolemund (@garrettgman), Josh Goldberg (@GoldbergData), bahadir cankardes (@gridgrad), Gustav W Delius (@gustavdelius), Hadley Wickham (@hadley), Hao Chen (@hao-trivago), Harris McGehee (@harrismcgehee), Hengni Cai (@hengnicai), Ian Sealy (@iansealy), Ian Lyttle (@ijlyttle), Ivan Krukov (@ivan-krukov), Jacob Kaplan (@jacobkap), Jazz Weisman (@jazzlw), John D. Storey (@jdstorey), Jeff Boichuk (@jeffboichuk), Gregory Jefferis (@jefferis), 蒋雨蒙 (@JeldorPKU), Jennifer (Jenny) Bryan (@jennybc), Jen Ren (@jenren), Jeroen Janssens (@jeroenjanssens), Jim Hester (@jimhester), JJ Chen (@jjchern), Joanne Jang (@joannejang), John Sears (@johnsears), @jonathanflint, Jon Calder (@jonmcalder), Jonathan Page (@jonpage), Justinas Petuchovas (@jpetuchovas), Jose Roberto Ayala Solares (@jroberayalas), Julia Stewart Lowndes (@jules32), Sonja (@kaetschap), Kara Woo (@karawoo), Katrin Leinweber (@katrinleinweber), Karandeep Singh (@kdpsingh), Kyle Humphrey (@khumph), Kirill Sevastyanenko (@kirillseva), @koalabearski, Kirill Müller (@krlmlr), Noah Landesberg (@landesbergn), @lindbrook, Mauro Lepore (@maurolepore), Mark Beveridge (@mbeveridge), Matt Herman (@mfherman), Mine Cetinkaya-Rundel (@mine-cetinkaya-rundel), Matthew Hendrickson (@mjhendrickson), @MJMarshall, Mustafa Ascha (@mustafaascha), Nelson Areal (@nareal), Nate Olson (@nate-d-olson), Nathanael (@nateaff), Nick Clark (@nickclark1000), @nickelas, Nirmal Patel (@nirmalpatel), Nina Munkholt Jakobsen (@nmjakobsen), Jakub Nowosad (@Nowosad), Peter Hurford (@peterhurford), Patrick Kennedy (@pkq), Radu Grosu (@radugrosu), Ranae Dietzel (@Ranae), Robin Gertenbach (@rgertenbach), Richard Zijdeman (@rlzijdeman), Robin (@Robinlovelace), Emily Robinson (@robinsones), Rohan Alexander (@RohanAlexander), Romero Morais (@RomeroBarata), Albert Y. Kim (@rudeboybert), Saghir (@saghirb), Jonas (@sauercrowd), Robert Schuessler (@schuess), Seamus McKinsey (@seamus-mckinsey), @seanpwilliams, Luke Smith (@seasmith), Matthew Sedaghatfar (@sedaghatfar), Sebastian Kraus (@sekR4), Sam Firke (@sfirke), Shannon Ellis (@ShanEllis), @shoili, S’busiso Mkhondwane (@sibusiso16), @spirgel, Steven M. Mortimer (@StevenMMortimer), Stéphane Guillou (@stragu), Sergiusz Bleja (@svenski), Tal Galili (@talgalili), Tim Waterhouse (@timwaterhouse), TJ Mahr (@tjmahr), Thomas Klebel (@tklebel), Tom Prior (@tomjamesprior), Terence Teo (@tteo), Beasley (@wibeasley), @yahwes, Yihui Xie (@yihui), Yiming (Paul) Li (@yimingli), Hiroaki Yutani (@yutannihilation), @zeal626, Azza Ahmed (@zo0z)R4DS hosted https://www.netlify.com part support open source software communities.","code":""},{"path":"preface-to-the-second-edition.html","id":"preface-to-the-second-edition","chapter":"Preface to the second edition","heading":"Preface to the second edition","text":"Welcome second edition “R Data Science”.","code":""},{"path":"preface-to-the-second-edition.html","id":"major-changes","chapter":"Preface to the second edition","heading":"Major changes","text":"first part renamed “whole game” reflect entire data science cycle, including chapter data import.wrangle part highlight improvements dplyr make data scientists’ lives even easier, new functions rectangling data, working list columns, column-wise row-wise operations.Data import also gains whole part goes beyond importing rectangular data include chapters working spreadsheets, databases, web scraping.iteration chapter gains new case study web scraping multiple pages.modeling part removed. modeling, recommend using packages tidymodels reading Tidy Modeling R Max Kuhn Julia Silge learn .","code":""},{"path":"preface-to-the-second-edition.html","id":"acknowledgements-1","chapter":"Preface to the second edition","heading":"Acknowledgements","text":": Add acknowledgements.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Data science exciting discipline allows turn raw data understanding, insight, knowledge.\ngoal “R Data Science” help learn important tools R allow data science.\nreading book, ’ll tools tackle wide variety data science challenges, using best parts R.","code":""},{"path":"introduction.html","id":"what-you-will-learn","chapter":"1 Introduction","heading":"1.1 What you will learn","text":"Data science huge field, ’s way can master reading single book.\ngoal book give solid foundation important tools.\nmodel tools needed typical data science project looks something like :First must import data R.\ntypically means take data stored file, database, web application programming interface (API), load data frame R.\ncan’t get data R, can’t data science !’ve imported data, good idea tidy .\nTidying data means storing consistent form matches semantics dataset way stored.\nbrief, data tidy, column variable, row observation.\nTidy data important consistent structure lets focus struggle questions data, fighting get data right form different functions.tidy data, common first step transform .\nTransformation includes narrowing observations interest (like people one city, data last year), creating new variables functions existing variables (like computing speed distance time), calculating set summary statistics (like counts means).\nTogether, tidying transforming called wrangling, getting data form ’s natural work often feels like fight!tidy data variables need, two main engines knowledge generation: visualisation modelling.\ncomplementary strengths weaknesses real analysis iterate many times.Visualisation fundamentally human activity.\ngood visualisation show things expect, raise new questions data.\ngood visualisation might also hint ’re asking wrong question, need collect different data.\nVisualisations can surprise , don’t scale particularly well require human interpret .Models complementary tools visualisation.\nmade questions sufficiently precise, can use model answer .\nModels fundamentally mathematical computational tool, generally scale well.\nEven don’t, ’s usually cheaper buy computers buy brains!\nevery model makes assumptions, nature model question assumptions.\nmeans model fundamentally surprise .last step data science communication, absolutely critical part data analysis project.\ndoesn’t matter well models visualisation led understand data unless can also communicate results others.Surrounding tools programming.\nProgramming cross-cutting tool use every part project.\ndon’t need expert programmer data scientist, learning programming pays becoming better programmer allows automate common tasks, solve new problems greater ease.’ll use tools every data science project, projects ’re enough.\n’s rough 80-20 rule play; can tackle 80% every project using tools ’ll learn book, ’ll need tools tackle remaining 20%.\nThroughout book ’ll point resources can learn .","code":""},{"path":"introduction.html","id":"how-this-book-is-organised","chapter":"1 Introduction","heading":"1.2 How this book is organised","text":"previous description tools data science organised roughly according order use analysis (although course ’ll iterate multiple times).\nexperience, however, best way learn :Starting data ingest tidying sub-optimal 80% time ’s routine boring, 20% time ’s weird frustrating.\n’s bad place start learning new subject!\nInstead, ’ll start visualisation transformation data ’s already imported tidied.\nway, ingest tidy data, motivation stay high know pain worth .Starting data ingest tidying sub-optimal 80% time ’s routine boring, 20% time ’s weird frustrating.\n’s bad place start learning new subject!\nInstead, ’ll start visualisation transformation data ’s already imported tidied.\nway, ingest tidy data, motivation stay high know pain worth .topics best explained tools.\nexample, believe ’s easier understand models work already know visualisation, tidy data, programming.topics best explained tools.\nexample, believe ’s easier understand models work already know visualisation, tidy data, programming.Programming tools necessarily interesting right, allow tackle considerably challenging problems.\n’ll give selection programming tools middle book, ’ll see can combine data science tools tackle interesting modelling problems.Programming tools necessarily interesting right, allow tackle considerably challenging problems.\n’ll give selection programming tools middle book, ’ll see can combine data science tools tackle interesting modelling problems.Within chapter, try stick similar pattern: start motivating examples can see bigger picture, dive details.\nsection book paired exercises help practice ’ve learned.\n’s tempting skip exercises, ’s better way learn practicing real problems.","code":""},{"path":"introduction.html","id":"what-you-wont-learn","chapter":"1 Introduction","heading":"1.3 What you won’t learn","text":"important topics book doesn’t cover.\nbelieve ’s important stay ruthlessly focused essentials can get running quickly possible.\nmeans book can’t cover every important topic.","code":""},{"path":"introduction.html","id":"big-data","chapter":"1 Introduction","heading":"1.3.1 Big data","text":"book proudly focuses small, -memory datasets.\nright place start can’t tackle big data unless experience small data.\ntools learn book easily handle hundreds megabytes data, little care can typically use work 1-2 Gb data.\n’re routinely working larger data (10-100 Gb, say), learn data.table.\nbook doesn’t teach data.table concise interface makes harder learn since offers fewer linguistic cues.\n’re working large data, performance payoff worth extra effort required learn .data bigger , carefully consider big data problem might actually small data problem disguise.\ncomplete data might big, often data needed answer specific question small.\nmight able find subset, subsample, summary fits memory still allows answer question ’re interested .\nchallenge finding right small data, often requires lot iteration.Another possibility big data problem actually large number small data problems.\nindividual problem might fit memory, millions .\nexample, might want fit model person dataset.\ntrivial just 10 100 people, instead million.\nFortunately problem independent others (setup sometimes called embarrassingly parallel), just need system (like Hadoop Spark) allows send different datasets different computers processing.\n’ve figured answer question single subset using tools described book, learn new tools like sparklyr, rhipe, ddr solve full dataset.","code":""},{"path":"introduction.html","id":"python-julia-and-friends","chapter":"1 Introduction","heading":"1.3.2 Python, Julia, and friends","text":"book, won’t learn anything Python, Julia, programming language useful data science.\nisn’t think tools bad.\n’re !\npractice, data science teams use mix languages, often least R Python.However, strongly believe ’s best master one tool time.\nget better faster dive deep, rather spreading thinly many topics.\ndoesn’t mean know one thing, just ’ll generally learn faster stick one thing time.\nstrive learn new things throughout career, make sure understanding solid move next interesting thing.think R great place start data science journey environment designed ground support data science.\nR just programming language, also interactive environment data science.\nsupport interaction, R much flexible language many peers.\nflexibility comes downsides, big upside easy evolve tailored grammars specific parts data science process.\nmini languages help think problems data scientist, supporting fluent interaction brain computer.","code":""},{"path":"introduction.html","id":"non-rectangular-data","chapter":"1 Introduction","heading":"1.3.3 Non-rectangular data","text":"book focuses exclusively rectangular data: collections values associated variable observation.\nlots datasets naturally fit paradigm, including images, sounds, trees, text.\nrectangular data frames extremely common science industry, believe great place start data science journey.","code":""},{"path":"introduction.html","id":"hypothesis-confirmation","chapter":"1 Introduction","heading":"1.3.4 Hypothesis confirmation","text":"’s possible divide data analysis two camps: hypothesis generation hypothesis confirmation (sometimes called confirmatory analysis).\nfocus book unabashedly hypothesis generation, data exploration.\n’ll look deeply data , combination subject knowledge, generate many interesting hypotheses help explain data behaves way .\nevaluate hypotheses informally, using scepticism challenge data multiple ways.complement hypothesis generation hypothesis confirmation.\nHypothesis confirmation hard two reasons:need precise mathematical model order generate falsifiable predictions.\noften requires considerable statistical sophistication.need precise mathematical model order generate falsifiable predictions.\noften requires considerable statistical sophistication.can use observation confirm hypothesis.\nsoon use ’re back exploratory analysis.\nmeans hypothesis confirmation need “preregister” (write advance) analysis plan, deviate even seen data.can use observation confirm hypothesis.\nsoon use ’re back exploratory analysis.\nmeans hypothesis confirmation need “preregister” (write advance) analysis plan, deviate even seen data.’s common think modelling tool hypothesis confirmation, visualisation tool hypothesis generation.\n’s false dichotomy: models often used exploration, little care can use visualisation confirmation.\nkey difference often look observation: look , ’s confirmation; look , ’s exploration.","code":""},{"path":"introduction.html","id":"prerequisites","chapter":"1 Introduction","heading":"1.4 Prerequisites","text":"’ve made assumptions already know order get book.\ngenerally numerically literate, ’s helpful programming experience already.\n’ve never programmed , might find Hands Programming R Garrett useful adjunct book.four things need run code book: R, RStudio, collection R packages called tidyverse, handful packages.\nPackages fundamental units reproducible R code.\ninclude reusable functions, documentation describes use , sample data.","code":""},{"path":"introduction.html","id":"r","chapter":"1 Introduction","heading":"1.4.1 R","text":"download R, go CRAN, comprehensive R archive network.\nCRAN composed set mirror servers distributed around world used distribute R R packages.\nDon’t try pick mirror ’s close : instead use cloud mirror, https://cloud.r-project.org, automatically figures .new major version R comes year, 2-3 minor releases year.\n’s good idea update regularly.\nUpgrading can bit hassle, especially major versions, require reinstall packages, putting makes worse.","code":""},{"path":"introduction.html","id":"rstudio","chapter":"1 Introduction","heading":"1.4.2 RStudio","text":"RStudio integrated development environment, IDE, R programming.\nDownload install http://www.rstudio.com/download.\nRStudio updated couple times year.\nnew version available, RStudio let know.\n’s good idea upgrade regularly can take advantage latest greatest features.\nbook, make sure least RStudio 1.0.0.start RStudio, ’ll see two key regions interface:now, need know type R code console pane, press enter run .\n’ll learn go along!","code":""},{"path":"introduction.html","id":"the-tidyverse","chapter":"1 Introduction","heading":"1.4.3 The tidyverse","text":"’ll also need install R packages.\nR package collection functions, data, documentation extends capabilities base R.\nUsing packages key successful use R.\nmajority packages learn book part -called tidyverse.\npackages tidyverse share common philosophy data R programming, designed work together naturally.can install complete tidyverse single line code:computer, type line code console, press enter run .\nR download packages CRAN install computer.\nproblems installing, make sure connected internet, https://cloud.r-project.org/ isn’t blocked firewall proxy.able use functions, objects, help files package load library().\ninstalled package, can load library() function:tells tidyverse loading ggplot2, tibble, tidyr, readr, purrr, dplyr packages.\nconsidered core tidyverse ’ll use almost every analysis.Packages tidyverse change fairly frequently.\ncan see updates available, optionally install , running tidyverse_update().","code":"\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n#> -- <U+2029>[1mAttaching packages<U+2029>[22m --------------------------------------- tidyverse 1.3.1 --NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mggplot2<U+2029>[39m 3.3.5          <U+2029>[32mv<U+2029>[39m <U+2029>[34mpurrr  <U+2029>[39m 0.3.4     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtibble <U+2029>[39m 3.1.2          <U+2029>[32mv<U+2029>[39m <U+2029>[34mdplyr  <U+2029>[39m 1.0.7     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtidyr  <U+2029>[39m 1.1.3          <U+2029>[32mv<U+2029>[39m <U+2029>[34mstringr<U+2029>[39m 1.4.0.<U+2029>[31m9000<U+2029>[39mNA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mreadr  <U+2029>[39m 2.0.1          <U+2029>[32mv<U+2029>[39m <U+2029>[34mforcats<U+2029>[39m 0.5.1NA#> -- <U+2029>[1mConflicts<U+2029>[22m ------------------------------------------ tidyverse_conflicts() --NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mfilter()<U+2029>[39m masks <U+2029>[34mstats<U+2029>[39m::filter()NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mlag()<U+2029>[39m    masks <U+2029>[34mstats<U+2029>[39m::lag()NA"},{"path":"introduction.html","id":"other-packages","chapter":"1 Introduction","heading":"1.4.4 Other packages","text":"many excellent packages part tidyverse, solve problems different domain, designed different set underlying principles.\ndoesn’t make better worse, just different.\nwords, complement tidyverse messyverse, many universes interrelated packages.\ntackle data science projects R, ’ll learn new packages new ways thinking data.book ’ll use three data packages outside tidyverse:packages provide data airline flights, world development, baseball ’ll use illustrate key data science ideas.","code":"\ninstall.packages(c(\"nycflights13\", \"gapminder\", \"Lahman\"))"},{"path":"introduction.html","id":"running-r-code","chapter":"1 Introduction","heading":"1.5 Running R code","text":"previous section showed couple examples running R code.\nCode book looks like :run code local console, look like :two main differences.\nconsole, type >, called prompt; don’t show prompt book.\nbook, output commented #>; console appears directly code.\ntwo differences mean ’re working electronic version book, can easily copy code book console.Throughout book use consistent set conventions refer code:Functions code font followed parentheses, like sum(), mean().Functions code font followed parentheses, like sum(), mean().R objects (like data function arguments) code font, without parentheses, like flights x.R objects (like data function arguments) code font, without parentheses, like flights x.want make clear package object comes , ’ll use package name followed two colons, like dplyr::mutate(), ornycflights13::flights. also valid R code.want make clear package object comes , ’ll use package name followed two colons, like dplyr::mutate(), ornycflights13::flights. also valid R code.","code":"\n1 + 2\n#> [1] 3> 1 + 2\n[1] 3"},{"path":"introduction.html","id":"getting-help-and-learning-more","chapter":"1 Introduction","heading":"1.6 Getting help and learning more","text":"book island; single resource allow master R.\nstart apply techniques described book data soon find questions answer.\nsection describes tips get help, help keep learning.get stuck, start Google.\nTypically adding “R” query enough restrict relevant results: search isn’t useful, often means aren’t R-specific results available.\nGoogle particularly useful error messages.\nget error message idea means, try googling !\nChances someone else confused past, help somewhere web.\n(error message isn’t English, run Sys.setenv(LANGUAGE = \"en\") re-run code; ’re likely find help English error messages.)Google doesn’t help, try Stack Overflow.\nStart spending little time searching existing answer, including [R] restrict search questions answers use R.\ndon’t find anything useful, prepare minimal reproducible example reprex.\ngood reprex makes easier people help , often ’ll figure problem course making .three things need include make example reproducible: required packages, data, code.Packages loaded top script, ’s easy see ones example needs.\ngood time check ’re using latest version package; ’s possible ’ve discovered bug ’s fixed since installed package.\npackages tidyverse, easiest way check run tidyverse_update().Packages loaded top script, ’s easy see ones example needs.\ngood time check ’re using latest version package; ’s possible ’ve discovered bug ’s fixed since installed package.\npackages tidyverse, easiest way check run tidyverse_update().easiest way include data question use dput() generate R code recreate .\nexample, recreate mtcars dataset R, ’d perform following steps:\nRun dput(mtcars) R\nCopy output\nreproducible script, type mtcars <- paste.\nTry find smallest subset data still reveals problem.easiest way include data question use dput() generate R code recreate .\nexample, recreate mtcars dataset R, ’d perform following steps:Run dput(mtcars) RCopy outputIn reproducible script, type mtcars <- paste.Try find smallest subset data still reveals problem.Spend little bit time ensuring code easy others read:\nMake sure ’ve used spaces variable names concise, yet informative.\nUse comments indicate problem lies.\nbest remove everything related problem.\nshorter code , easier understand, easier fix.\nSpend little bit time ensuring code easy others read:Make sure ’ve used spaces variable names concise, yet informative.Make sure ’ve used spaces variable names concise, yet informative.Use comments indicate problem lies.Use comments indicate problem lies.best remove everything related problem.\nshorter code , easier understand, easier fix.best remove everything related problem.\nshorter code , easier understand, easier fix.Finish checking actually made reproducible example starting fresh R session copying pasting script .also spend time preparing solve problems occur.\nInvesting little time learning R day pay handsomely long run.\nOne way follow Hadley, Garrett, everyone else RStudio RStudio blog.\npost announcements new packages, new IDE features, -person courses.\nmight also want follow Hadley (@hadleywickham) Garrett (@statgarrett) Twitter, follow @rstudiotips keep new features IDE.keep R community broadly, recommend reading http://www.r-bloggers.com: aggregates 500 blogs R around world.\n’re active Twitter user, follow (#rstats) hashtag.\nTwitter one key tools Hadley uses keep new developments community.","code":""},{"path":"introduction.html","id":"acknowledgements-2","chapter":"1 Introduction","heading":"1.7 Acknowledgements","text":"book isn’t just product Hadley Garrett, result many conversations (person online) ’ve many people R community.\npeople ’d like thank particular, spent many hours answering questions helping us better think data science:Jenny Bryan Lionel Henry many helpful discussions around working lists list-columns.Jenny Bryan Lionel Henry many helpful discussions around working lists list-columns.three chapters workflow adapted (permission), http://stat545.com/block002_hello-r-workspace-wd-project.html Jenny Bryan.three chapters workflow adapted (permission), http://stat545.com/block002_hello-r-workspace-wd-project.html Jenny Bryan.Genevera Allen discussions models, modelling, statistical learning perspective, difference hypothesis generation hypothesis confirmation.Genevera Allen discussions models, modelling, statistical learning perspective, difference hypothesis generation hypothesis confirmation.Yihui Xie work bookdown package, tirelessly responding feature requests.Yihui Xie work bookdown package, tirelessly responding feature requests.Bill Behrman thoughtful reading entire book, trying data science class Stanford.Bill Behrman thoughtful reading entire book, trying data science class Stanford.#rstats Twitter community reviewed draft chapters provided tons useful feedback.#rstats Twitter community reviewed draft chapters provided tons useful feedback.Tal Galili augmenting dendextend package support section clustering make final draft.Tal Galili augmenting dendextend package support section clustering make final draft.book written open, many people contributed pull requests fix minor problems.\nSpecial thanks goes everyone contributed via GitHub:Thanks go contributers alphabetical order: @-rosenberg, . s, Abhinav Singh, adi pradhan, Ahmed ElGabbas, Ajay Deonarine, @AlanFeder, Albert Y. Kim, @Alex, Andrea Gilardi, Andrew Landgraf, @andrewmacfarland, Angela Li, Azza Ahmed, bahadir cankardes, @batpigandme, @behrman, Ben Herbertson, Ben Marwick, Ben Steinberg, Benjamin Yeh, Bianca Peterson, Bill Behrman, @BirgerNi, @boardtc, Brandon Greenwell, Brent Brewington, Brett Klamer, Brian G. Barkley, Charlotte Wickham, Christian G. Warden, Christian Heinrich, Christian Mongeau, Colin Gillespie, Cooper Morris, Curtis Alexander, Daniel Gromer, David Clark, David Rubinger, Derwin McGeary, Devin Pastoor, Dirk Eddelbuettel, @djbirke, @DSGeoff, Dylan Cashman, Earl Brown, Edwin Thoen, Eric Watt, Erik Erhardt, Etienne B. Racine, Everett Robinson, Flemming Villalona, Floris Vanderhaeghe, Garrick Aden-Buie, George Wang, Gregory Jefferis, Gustav W Delius, Hao Chen, @harrismcgehee, Hengni Cai, Hiroaki Yutani, Hojjat Salmasian, Ian Lyttle, Ian Sealy, Ivan Krukov, Jacek Kolacz, Jacob Kaplan, Jakub Nowosad, Jazz Weisman, Jeff Boichuk, Jeffrey Arnold, Jen Ren, Jennifer (Jenny) Bryan, @jennybc, Jeroen Janssens, Jim Hester, @jjchern, Joanne Jang, Johannes Gruber, John Blischak, John D. Storey, John Sears, Jon Calder, @Jonas, Jonathan Page, @jonathanflint, Jose Roberto Ayala Solares, Josh Goldberg, @juandering, Julia Stewart Lowndes, Julian , Justinas Petuchovas, @kaetschap, Kara de la Marck, Kara Woo, Katrin Leinweber, @kdpsingh, Kenny Darrell, Kirill Müller, Kirill Sevastyanenko, @koalabearski, Kunal Marwaha, @KyleHumphrey, Lawrence Wu, @lindbrook, Luke Smith, Luke W Johnston, Mara Averick, Maria Paula Caldas, Mark Beveridge, Matt Herman, Matthew Hendrickson, Matthew Sedaghatfar, @MattWittbrodt, Mauro Lepore, Michael Henry, Mine Cetinkaya-Rundel, @MJMarshall, Mustafa Ascha, @nate-d-olson, @nattalides, Nelson Areal, Nicholas Tierney, Nick Clark, @nickelas, Nina Munkholt Jakobsen, Nirmal Patel, Nischal Shrestha, Noah Landesberg, @nwaff, @OaCantona, Pablo E, Patrick Kennedy, @Paul, @pete, Peter Hurford, Rademeyer Vermaak, Radu Grosu, Ranae Dietzel, Riva Quiroga, @rlzijdeman, Rob Tenorio, Robert Schuessler, @robertchu03, Robin Gertenbach, @robinlovelace, @robinsones, Rohan Alexander, @RomeroBarata, S’busiso Mkhondwane, @Saghir, Sam Firke, @seamus-mckinsey, Seamus McKinsey, @seanpwilliams, Sebastian Kraus, Shannon Ellis, @shoili, @sibusiso16, @Sophiazj, @spirgel, Stéphane Guillou, Steve Mortimer, @svenski, Tal Galili, Terence Teo, Thomas Klebel, Tim Waterhouse, TJ Mahr, Tom Prior, @twgardner2, Ulrik Lyngs, Beasley, @yahwes, Yihui Xie, Yiming (Paul) Li, Yu Yu Aung, Zach Bogart, @zeal626, Zhuoer Dong, @蒋雨蒙.","code":""},{"path":"introduction.html","id":"colophon","chapter":"1 Introduction","heading":"1.8 Colophon","text":"online version book available http://r4ds..co.nz.\ncontinue evolve reprints physical book.\nsource book available https://github.com/hadley/r4ds.\nbook powered https://bookdown.org makes easy turn R markdown files HTML, PDF, EPUB.book built :","code":"\nsessioninfo::session_info(c(\"tidyverse\"))\n#> - Session info ---------------------------------------------------------------\n#>  setting  value                         \n#>  version  R version 4.1.1 (2021-08-10)  \n#>  os       Windows 10 x64                \n#>  system   x86_64, mingw32               \n#>  ui       RTerm                         \n#>  language (EN)                          \n#>  collate  Chinese (Simplified)_China.936\n#>  ctype    Chinese (Simplified)_China.936\n#>  tz       Asia/Taipei                   \n#>  date     2021-09-03                    \n#> \n#> - Packages -------------------------------------------------------------------\n#>  package       * version    date       lib source                            \n#>  askpass         1.1        2019-01-13 [1] CRAN (R 4.1.0)                    \n#>  assertthat      0.2.1      2019-03-21 [1] CRAN (R 4.1.0)                    \n#>  backports       1.2.1      2020-12-09 [1] CRAN (R 4.1.0)                    \n#>  base64enc       0.1-3      2015-07-28 [1] CRAN (R 4.1.0)                    \n#>  bit             4.0.4      2020-08-04 [1] CRAN (R 4.1.0)                    \n#>  bit64           4.0.5      2020-08-30 [1] CRAN (R 4.1.0)                    \n#>  blob            1.2.2      2021-07-23 [1] CRAN (R 4.1.0)                    \n#>  broom           0.7.9      2021-07-27 [1] CRAN (R 4.1.1)                    \n#>  callr           3.7.0      2021-04-20 [1] CRAN (R 4.1.0)                    \n#>  cellranger      1.1.0      2016-07-27 [1] CRAN (R 4.1.1)                    \n#>  cli             3.0.1      2021-07-17 [1] CRAN (R 4.1.0)                    \n#>  clipr           0.7.1      2020-10-08 [1] CRAN (R 4.1.0)                    \n#>  colorspace      2.0-2      2021-06-24 [1] CRAN (R 4.1.0)                    \n#>  cpp11           0.3.1      2021-06-25 [1] CRAN (R 4.1.0)                    \n#>  crayon          1.4.1      2021-02-08 [1] CRAN (R 4.1.0)                    \n#>  curl            4.3.2      2021-06-23 [1] CRAN (R 4.1.0)                    \n#>  data.table      1.14.0     2021-02-21 [1] CRAN (R 4.1.0)                    \n#>  DBI             1.1.1      2021-01-15 [1] CRAN (R 4.1.0)                    \n#>  dbplyr          2.1.1      2021-04-06 [1] CRAN (R 4.1.0)                    \n#>  digest          0.6.27     2020-10-24 [1] CRAN (R 4.1.0)                    \n#>  dplyr         * 1.0.7      2021-06-18 [1] CRAN (R 4.1.0)                    \n#>  dtplyr          1.1.0      2021-02-20 [1] CRAN (R 4.1.1)                    \n#>  ellipsis        0.3.2      2021-04-29 [1] CRAN (R 4.1.0)                    \n#>  evaluate        0.14       2019-05-28 [1] CRAN (R 4.1.0)                    \n#>  fansi           0.5.0      2021-05-25 [1] CRAN (R 4.1.0)                    \n#>  farver          2.1.0      2021-02-28 [1] CRAN (R 4.1.0)                    \n#>  fastmap         1.1.0      2021-01-25 [1] CRAN (R 4.1.0)                    \n#>  forcats       * 0.5.1      2021-01-27 [1] CRAN (R 4.1.1)                    \n#>  fs              1.5.0      2020-07-31 [1] CRAN (R 4.1.0)                    \n#>  gargle          1.2.0      2021-07-02 [1] CRAN (R 4.1.1)                    \n#>  generics        0.1.0      2020-10-31 [1] CRAN (R 4.1.0)                    \n#>  ggplot2       * 3.3.5      2021-06-25 [1] CRAN (R 4.1.0)                    \n#>  glue            1.4.2      2020-08-27 [1] CRAN (R 4.1.0)                    \n#>  googledrive     2.0.0      2021-07-08 [1] CRAN (R 4.1.1)                    \n#>  googlesheets4   1.0.0      2021-07-21 [1] CRAN (R 4.1.1)                    \n#>  gtable          0.3.0      2019-03-25 [1] CRAN (R 4.1.0)                    \n#>  haven           2.4.3      2021-08-04 [1] CRAN (R 4.1.1)                    \n#>  highr           0.9        2021-04-16 [1] CRAN (R 4.1.0)                    \n#>  hms             1.1.0      2021-05-17 [1] CRAN (R 4.1.0)                    \n#>  htmltools       0.5.2      2021-08-25 [1] CRAN (R 4.1.1)                    \n#>  httr            1.4.2      2020-07-20 [1] CRAN (R 4.1.0)                    \n#>  ids             1.0.1      2017-05-31 [1] CRAN (R 4.1.1)                    \n#>  isoband         0.2.5      2021-07-13 [1] CRAN (R 4.1.0)                    \n#>  jsonlite        1.7.2      2020-12-09 [1] CRAN (R 4.1.0)                    \n#>  knitr           1.33       2021-04-24 [1] CRAN (R 4.1.0)                    \n#>  labeling        0.4.2      2020-10-20 [1] CRAN (R 4.1.0)                    \n#>  lattice         0.20-44    2021-05-02 [2] CRAN (R 4.1.1)                    \n#>  lifecycle       1.0.0      2021-02-15 [1] CRAN (R 4.1.0)                    \n#>  lubridate       1.7.10     2021-02-26 [1] CRAN (R 4.1.1)                    \n#>  magrittr        2.0.1      2020-11-17 [1] CRAN (R 4.1.0)                    \n#>  markdown        1.1        2019-08-07 [1] CRAN (R 4.1.0)                    \n#>  MASS            7.3-54     2021-05-03 [2] CRAN (R 4.1.1)                    \n#>  Matrix          1.3-4      2021-06-01 [2] CRAN (R 4.1.1)                    \n#>  mgcv            1.8-36     2021-06-01 [2] CRAN (R 4.1.1)                    \n#>  mime            0.11       2021-06-23 [1] CRAN (R 4.1.0)                    \n#>  modelr          0.1.8      2020-05-19 [1] CRAN (R 4.1.1)                    \n#>  munsell         0.5.0      2018-06-12 [1] CRAN (R 4.1.0)                    \n#>  nlme            3.1-152    2021-02-04 [2] CRAN (R 4.1.1)                    \n#>  openssl         1.4.4      2021-04-30 [1] CRAN (R 4.1.0)                    \n#>  pillar          1.6.2      2021-07-29 [1] CRAN (R 4.1.0)                    \n#>  pkgconfig       2.0.3      2019-09-22 [1] CRAN (R 4.1.0)                    \n#>  prettyunits     1.1.1      2020-01-24 [1] CRAN (R 4.1.0)                    \n#>  processx        3.5.2      2021-04-30 [1] CRAN (R 4.1.0)                    \n#>  progress        1.2.2      2019-05-16 [1] CRAN (R 4.1.0)                    \n#>  ps              1.6.0      2021-02-28 [1] CRAN (R 4.1.0)                    \n#>  purrr         * 0.3.4      2020-04-17 [1] CRAN (R 4.1.0)                    \n#>  R6              2.5.1      2021-08-19 [1] CRAN (R 4.1.1)                    \n#>  rappdirs        0.3.3      2021-01-31 [1] CRAN (R 4.1.0)                    \n#>  RColorBrewer    1.1-2      2014-12-07 [1] CRAN (R 4.1.0)                    \n#>  Rcpp            1.0.7      2021-07-07 [1] CRAN (R 4.1.0)                    \n#>  readr         * 2.0.1      2021-08-10 [1] CRAN (R 4.1.1)                    \n#>  readxl          1.3.1      2019-03-13 [1] CRAN (R 4.1.1)                    \n#>  rematch         1.0.1      2016-04-21 [1] CRAN (R 4.1.1)                    \n#>  rematch2        2.1.2      2020-05-01 [1] CRAN (R 4.1.0)                    \n#>  reprex          2.0.1      2021-08-05 [1] CRAN (R 4.1.1)                    \n#>  rlang           0.4.11     2021-04-30 [1] CRAN (R 4.1.0)                    \n#>  rmarkdown       2.10       2021-08-06 [1] CRAN (R 4.1.1)                    \n#>  rstudioapi      0.13       2020-11-12 [1] CRAN (R 4.1.0)                    \n#>  rvest           1.0.1      2021-07-26 [1] CRAN (R 4.1.0)                    \n#>  scales          1.1.1      2020-05-11 [1] CRAN (R 4.1.0)                    \n#>  selectr         0.4-2      2019-11-20 [1] CRAN (R 4.1.1)                    \n#>  stringi         1.7.4      2021-08-25 [1] CRAN (R 4.1.1)                    \n#>  stringr       * 1.4.0.9000 2021-09-02 [1] Github (tidyverse/stringr@6670a37)\n#>  sys             3.4        2020-07-23 [1] CRAN (R 4.1.0)                    \n#>  tibble        * 3.1.2      2021-05-16 [1] CRAN (R 4.1.0)                    \n#>  tidyr         * 1.1.3      2021-03-03 [1] CRAN (R 4.1.0)                    \n#>  tidyselect      1.1.1      2021-04-30 [1] CRAN (R 4.1.0)                    \n#>  tidyverse     * 1.3.1      2021-04-15 [1] CRAN (R 4.1.1)                    \n#>  tinytex         0.33       2021-08-05 [1] CRAN (R 4.1.1)                    \n#>  tzdb            0.1.2      2021-07-20 [1] CRAN (R 4.1.1)                    \n#>  utf8            1.2.1      2021-03-12 [1] CRAN (R 4.1.0)                    \n#>  uuid            0.1-4      2020-02-26 [1] CRAN (R 4.1.0)                    \n#>  vctrs           0.3.8      2021-04-29 [1] CRAN (R 4.1.0)                    \n#>  viridisLite     0.4.0      2021-04-13 [1] CRAN (R 4.1.0)                    \n#>  vroom           1.5.4      2021-08-05 [1] CRAN (R 4.1.1)                    \n#>  withr           2.4.2      2021-04-18 [1] CRAN (R 4.1.0)                    \n#>  xfun            0.25       2021-08-06 [1] CRAN (R 4.1.0)                    \n#>  xml2            1.3.2      2020-04-23 [1] CRAN (R 4.1.0)                    \n#>  yaml            2.2.1      2020-02-01 [1] CRAN (R 4.1.0)                    \n#> \n#> [1] C:/Users/yangm/OneDrive/Documents/R/win-library/4.1\n#> [2] C:/Program Files/R/R-4.1.1/library"},{"path":"explore-intro.html","id":"explore-intro","chapter":"2 Introduction","heading":"2 Introduction","text":"goal first part book introduce data science workflow including data importing, tidying, data exploration quickly possible.\nData exploration art looking data, rapidly generating hypotheses, quickly testing , repeating .\ngoal data exploration generate many promising leads can later explore depth.part book learn useful tools immediate payoff:Visualisation great place start R programming, payoff clear: get make elegant informative plots help understand data.\nChapter 3 ’ll dive visualisation, learning basic structure ggplot2 plot, powerful techniques turning data plots.Visualisation great place start R programming, payoff clear: get make elegant informative plots help understand data.\nChapter 3 ’ll dive visualisation, learning basic structure ggplot2 plot, powerful techniques turning data plots.Visualisation alone typically enough, Chapter 5 ’ll learn key verbs allow select important variables, filter key observations, create new variables, compute summaries.Visualisation alone typically enough, Chapter 5 ’ll learn key verbs allow select important variables, filter key observations, create new variables, compute summaries.Chapter 6, ’ll learn tidy data, consistent way storing data makes transformation, visualisation, modelling easier.\n’ll learn underlying principles, get data tidy form.Chapter 6, ’ll learn tidy data, consistent way storing data makes transformation, visualisation, modelling easier.\n’ll learn underlying principles, get data tidy form.can transform visualise data, need first get data R.\nChapter 8 ’ll learn basics getting plain-text, rectangular data R.can transform visualise data, need first get data R.\nChapter 8 ’ll learn basics getting plain-text, rectangular data R.Finally, Chapter 10, ’ll combine visualisation transformation curiosity scepticism ask answer interesting questions data.Finally, Chapter 10, ’ll combine visualisation transformation curiosity scepticism ask answer interesting questions data.Modelling important part exploratory process, don’t skills effectively learn apply yet details modeling fall outside scope book.Nestled among five chapters teach tools data science three chapters focus R workflow.\nChapters 4, 9, 11, ’ll learn good workflow practices writing organising R code.\nset success long run, ’ll give tools stay organised tackle real projects.","code":""},{"path":"data-visualisation.html","id":"data-visualisation","chapter":"3 Data visualisation","heading":"3 Data visualisation","text":"","code":""},{"path":"data-visualisation.html","id":"introduction-1","chapter":"3 Data visualisation","heading":"3.1 Introduction","text":"“simple graph brought information data analyst’s mind device.” — John TukeyThis chapter teach visualise data using ggplot2.\nR several systems making graphs, ggplot2 one elegant versatile.\nggplot2 implements grammar graphics, coherent system describing building graphs.\nggplot2, can faster learning one system applying many places.’d like learn theoretical underpinnings ggplot2, ’d recommend reading “Layered Grammar Graphics”, http://vita..co.nz/papers/layered-grammar.pdf.","code":""},{"path":"data-visualisation.html","id":"prerequisites-1","chapter":"3 Data visualisation","heading":"3.1.1 Prerequisites","text":"chapter focusses ggplot2, one core members tidyverse.\naccess datasets, help pages, functions use chapter, load tidyverse running code:one line code loads core tidyverse; packages use almost every data analysis.\nalso tells functions tidyverse conflict functions base R (packages might loaded).run code get error message “package called ‘tidyverse’”, ’ll need first install , run library() .need install package , need reload every time start new session.need explicit function (dataset) comes , ’ll use special form package::function().\nexample, ggplot2::ggplot() tells explicitly ’re using ggplot() function ggplot2 package.","code":"\nlibrary(tidyverse)\n#> -- <U+2029>[1mAttaching packages<U+2029>[22m --------------------------------------- tidyverse 1.3.1 --NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mggplot2<U+2029>[39m 3.3.5          <U+2029>[32mv<U+2029>[39m <U+2029>[34mpurrr  <U+2029>[39m 0.3.4     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtibble <U+2029>[39m 3.1.2          <U+2029>[32mv<U+2029>[39m <U+2029>[34mdplyr  <U+2029>[39m 1.0.7     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtidyr  <U+2029>[39m 1.1.3          <U+2029>[32mv<U+2029>[39m <U+2029>[34mstringr<U+2029>[39m 1.4.0.<U+2029>[31m9000<U+2029>[39mNA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mreadr  <U+2029>[39m 2.0.1          <U+2029>[32mv<U+2029>[39m <U+2029>[34mforcats<U+2029>[39m 0.5.1NA#> -- <U+2029>[1mConflicts<U+2029>[22m ------------------------------------------ tidyverse_conflicts() --NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mfilter()<U+2029>[39m masks <U+2029>[34mstats<U+2029>[39m::filter()NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mlag()<U+2029>[39m    masks <U+2029>[34mstats<U+2029>[39m::lag()NA\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)"},{"path":"data-visualisation.html","id":"first-steps","chapter":"3 Data visualisation","heading":"3.2 First steps","text":"Let’s use first graph answer question: cars big engines use fuel cars small engines?\nprobably already answer, try make answer precise.\nrelationship engine size fuel efficiency look like?\npositive?\nNegative?\nLinear?\nNonlinear?","code":""},{"path":"data-visualisation.html","id":"the-mpg-data-frame","chapter":"3 Data visualisation","heading":"3.2.1 The mpg data frame","text":"can test answer mpg data frame found ggplot2 (.k.. ggplot2::mpg).\ndata frame rectangular collection variables (columns) observations (rows).\nmpg contains observations collected US Environmental Protection Agency 38 models car.Among variables mpg :displ, car’s engine size, litres.displ, car’s engine size, litres.hwy, car’s fuel efficiency highway, miles per gallon (mpg).\ncar low fuel efficiency consumes fuel car high fuel efficiency travel distance.hwy, car’s fuel efficiency highway, miles per gallon (mpg).\ncar low fuel efficiency consumes fuel car high fuel efficiency travel distance.learn mpg, open help page running ?mpg.","code":"\nmpg\n#> <U+2029>[90m# A tibble: 234 x 11<U+2029>[39mNA#>   <U+2029>[1mmanufacturer<U+2029>[22m <U+2029>[1mmodel<U+2029>[22m <U+2029>[1mdispl<U+2029>[22m  <U+2029>[1myear<U+2029>[22m   <U+2029>[1mcyl<U+2029>[22m <U+2029>[1mtrans<U+2029>[22m      <U+2029>[1mdrv<U+2029>[22m     <U+2029>[1mcty<U+2029>[22m   <U+2029>[1mhwy<U+2029>[22m <U+2029>[1mfl<U+2029>[22m    <U+2029>[1mclass<U+2029>[22m NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m        <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m NA#> <U+2029>[90m1<U+2029>[39m audi         a4      1.8  <U+2029>[4m1<U+2029>[24m999     4 auto(l5)   f        18    29 p     compa~NA#> <U+2029>[90m2<U+2029>[39m audi         a4      1.8  <U+2029>[4m1<U+2029>[24m999     4 manual(m5) f        21    29 p     compa~NA#> <U+2029>[90m3<U+2029>[39m audi         a4      2    <U+2029>[4m2<U+2029>[24m008     4 manual(m6) f        20    31 p     compa~NA#> <U+2029>[90m4<U+2029>[39m audi         a4      2    <U+2029>[4m2<U+2029>[24m008     4 auto(av)   f        21    30 p     compa~NA#> <U+2029>[90m5<U+2029>[39m audi         a4      2.8  <U+2029>[4m1<U+2029>[24m999     6 auto(l5)   f        16    26 p     compa~NA#> <U+2029>[90m6<U+2029>[39m audi         a4      2.8  <U+2029>[4m1<U+2029>[24m999     6 manual(m5) f        18    26 p     compa~NA#> <U+2029>[90m# ... with 228 more rows<U+2029>[39mNA"},{"path":"data-visualisation.html","id":"creating-a-ggplot","chapter":"3 Data visualisation","heading":"3.2.2 Creating a ggplot","text":"plot mpg, run code put displ x-axis hwy y-axis:plot shows negative relationship engine size (displ) fuel efficiency (hwy).\nwords, cars big engines use fuel.\nconfirm refute hypothesis fuel efficiency engine size?ggplot2, begin plot function ggplot().\nggplot() creates coordinate system can add layers .\nfirst argument ggplot() dataset use graph.\nggplot(data = mpg) creates empty graph, ’s interesting ’m going show .complete graph adding one layers ggplot().\nfunction geom_point() adds layer points plot, creates scatterplot.\nggplot2 comes many geom functions add different type layer plot.\n’ll learn whole bunch throughout chapter.geom function ggplot2 takes mapping argument.\ndefines variables dataset mapped visual properties plot.\nmapping argument always paired aes(), x y arguments aes() specify variables map x y axes.\nggplot2 looks mapped variables data argument, case, mpg.","code":"\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))"},{"path":"data-visualisation.html","id":"a-graphing-template","chapter":"3 Data visualisation","heading":"3.2.3 A graphing template","text":"Let’s turn code reusable template making graphs ggplot2.\nmake graph, replace bracketed sections code dataset, geom function, collection mappings.rest chapter show complete extend template make different types graphs.\nbegin <MAPPINGS> component.","code":"ggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))"},{"path":"data-visualisation.html","id":"exercises","chapter":"3 Data visualisation","heading":"3.2.4 Exercises","text":"Run ggplot(data = mpg).\nsee?Run ggplot(data = mpg).\nsee?many rows mpg?\nmany columns?many rows mpg?\nmany columns?drv variable describe?\nRead help ?mpg find .drv variable describe?\nRead help ?mpg find .Make scatterplot hwy vs cyl.Make scatterplot hwy vs cyl.happens make scatterplot class vs drv?\nplot useful?happens make scatterplot class vs drv?\nplot useful?","code":""},{"path":"data-visualisation.html","id":"aesthetic-mappings","chapter":"3 Data visualisation","heading":"3.3 Aesthetic mappings","text":"“greatest value picture forces us notice never expected see.” — John TukeyIn plot , one group points (highlighted red) seems fall outside linear trend.\ncars higher mileage might expect.\ncan explain cars?Let’s hypothesize cars hybrids.\nOne way test hypothesis look class value car.\nclass variable mpg dataset classifies cars groups compact, midsize, SUV.\noutlying points hybrids, classified compact cars , perhaps, subcompact cars (keep mind data collected hybrid trucks SUVs became popular).can add third variable, like class, two dimensional scatterplot mapping aesthetic.\naesthetic visual property objects plot.\nAesthetics include things like size, shape, color points.\ncan display point (like one ) different ways changing values aesthetic properties.\nSince already use word “value” describe data, let’s use word “level” describe aesthetic properties.\nchange levels point’s size, shape, color make point small, triangular, blue:can convey information data mapping aesthetics plot variables dataset.\nexample, can map colours points class variable reveal class car.(prefer British English, like Hadley, can use colour instead color.)map aesthetic variable, associate name aesthetic name variable inside aes().\nggplot2 automatically assign unique level aesthetic (unique color) unique value variable, process known scaling.\nggplot2 also add legend explains levels correspond values.colours reveal many unusual points (engine size greater 5 litres highway fuel efficiency greater 20 miles per gallon) two-seater cars.\ncars don’t seem like hybrids, , fact, sports cars!\nSports cars large engines like SUVs pickup trucks, small bodies like midsize compact cars, improves gas mileage.\nhindsight, cars unlikely hybrids since large engines.example, mapped class color aesthetic, mapped class size aesthetic way.\ncase, exact size point reveal class affiliation.\nget warning , mapping unordered variable (class) ordered aesthetic (size) good idea.mapped class alpha aesthetic, controls transparency points, shape aesthetic, controls shape points.happened SUVs?\nggplot2 use six shapes time.\ndefault, additional groups go unplotted use shape aesthetic.aesthetic, use aes() associate name aesthetic variable display.\naes() function gathers together aesthetic mappings used layer passes layer’s mapping argument.\nsyntax highlights useful insight x y: x y locations point aesthetics, visual properties can map variables display information data.map aesthetic, ggplot2 takes care rest.\nselects reasonable scale use aesthetic, constructs legend explains mapping levels values.\nx y aesthetics, ggplot2 create legend, creates axis line tick marks label.\naxis line acts legend; explains mapping locations values.can also set aesthetic properties geom manually.\nexample, can make points plot blue:, color doesn’t convey information variable, changes appearance plot.\nset aesthetic manually, set aesthetic name argument geom function; .e. goes outside aes().\n’ll need pick level makes sense aesthetic:name color character string.name color character string.size point mm.size point mm.shape point number, shown Figure 3.1.shape point number, shown Figure 3.1.\nFigure 3.1: R 25 built shapes identified numbers. seeming duplicates: example, 0, 15, 22 squares. difference comes interaction colour fill aesthetics. hollow shapes (0–14) border determined colour; solid shapes (15–20) filled colour; filled shapes (21–24) border colour filled fill.\n","code":"\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = class))\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, size = class))\n#> Warning: Using size for a discrete variable is not advised.\n# Left\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))\n\n# Right\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, shape = class))\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy), color = \"blue\")"},{"path":"data-visualisation.html","id":"exercises-1","chapter":"3 Data visualisation","heading":"3.3.1 Exercises","text":"’s gone wrong code?\npoints blue?\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = \"blue\"))\n’s gone wrong code?\npoints blue?variables mpg categorical?\nvariables continuous?\n(Hint: type ?mpg read documentation dataset).\ncan see information run mpg?variables mpg categorical?\nvariables continuous?\n(Hint: type ?mpg read documentation dataset).\ncan see information run mpg?Map continuous variable color, size, shape.\naesthetics behave differently categorical vs. continuous variables?Map continuous variable color, size, shape.\naesthetics behave differently categorical vs. continuous variables?happens map variable multiple aesthetics?happens map variable multiple aesthetics?stroke aesthetic ?\nshapes work ?\n(Hint: use ?geom_point)stroke aesthetic ?\nshapes work ?\n(Hint: use ?geom_point)happens map aesthetic something variable name, like aes(colour = displ < 5)?\nNote, ’ll also need specify x y.happens map aesthetic something variable name, like aes(colour = displ < 5)?\nNote, ’ll also need specify x y.","code":"\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = \"blue\"))"},{"path":"data-visualisation.html","id":"common-problems","chapter":"3 Data visualisation","heading":"3.4 Common problems","text":"start run R code, ’re likely run problems.\nDon’t worry — happens everyone.\nwriting R code years, every day still write code doesn’t work!Start carefully comparing code ’re running code book.\nR extremely picky, misplaced character can make difference.\nMake sure every ( matched ) every \" paired another \".\nSometimes ’ll run code nothing happens.\nCheck left-hand console: ’s +, means R doesn’t think ’ve typed complete expression ’s waiting finish .\ncase, ’s usually easy start scratch pressing ESCAPE abort processing current command.One common problem creating ggplot2 graphics put + wrong place: come end line, start.\nwords, make sure haven’t accidentally written code like :’re still stuck, try help.\ncan get help R function running ?function_name console, selecting function name pressing F1 RStudio.\nDon’t worry help doesn’t seem helpful - instead skip examples look code matches ’re trying .doesn’t help, carefully read error message.\nSometimes answer buried !\n’re new R, answer might error message don’t yet know understand .\nAnother great tool Google: try googling error message, ’s likely someone else problem, gotten help online.","code":"\nggplot(data = mpg) \n+ geom_point(mapping = aes(x = displ, y = hwy))"},{"path":"data-visualisation.html","id":"facets","chapter":"3 Data visualisation","heading":"3.5 Facets","text":"One way add additional variables aesthetics.\nAnother way, particularly useful categorical variables, split plot facets, subplots display one subset data.facet plot single variable, use facet_wrap().\nfirst argument facet_wrap() formula, create ~ followed variable name (, “formula” bane data structure R, synonym “equation”).\nvariable pass facet_wrap() discrete.facet plot combination two variables, add facet_grid() plot call.\nfirst argument facet_grid() also formula.\ntime formula contain two variable names separated ~.prefer facet rows columns dimension, use . instead variable name, e.g. + facet_grid(. ~ cyl).","code":"\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(drv ~ cyl)\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(drv ~ cyl)"},{"path":"data-visualisation.html","id":"exercises-2","chapter":"3 Data visualisation","heading":"3.5.1 Exercises","text":"happens facet continuous variable?happens facet continuous variable?empty cells plot facet_grid(drv ~ cyl) mean?\nrelate plot?\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = drv, y = cyl))\nempty cells plot facet_grid(drv ~ cyl) mean?\nrelate plot?plots following code make?\n. ?\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(. ~ cyl)plots following code make?\n. ?Take first faceted plot section:\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)\nadvantages using faceting instead colour aesthetic?\ndisadvantages?\nmight balance change larger dataset?Take first faceted plot section:advantages using faceting instead colour aesthetic?\ndisadvantages?\nmight balance change larger dataset?Read ?facet_wrap.\nnrow ?\nncol ?\noptions control layout individual panels?\ndoesn’t facet_grid() nrow ncol arguments?Read ?facet_wrap.\nnrow ?\nncol ?\noptions control layout individual panels?\ndoesn’t facet_grid() nrow ncol arguments?following two plots makes easier compare engine size (displ) across cars different drive trains?\nsay place faceting variable across rows columns?\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(drv ~ .)\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(. ~ drv)\nfollowing two plots makes easier compare engine size (displ) across cars different drive trains?\nsay place faceting variable across rows columns?Recreate plot using facet_wrap() instead facet_grid().\npositions facet labels change?\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\nRecreate plot using facet_wrap() instead facet_grid().\npositions facet labels change?","code":"\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = drv, y = cyl))\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(. ~ cyl)\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(drv ~ .)\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(. ~ drv)\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)"},{"path":"data-visualisation.html","id":"geometric-objects","chapter":"3 Data visualisation","heading":"3.6 Geometric objects","text":"two plots similar?plots contain x variable, y variable, describe data.\nplots identical.\nplot uses different visual object represent data.\nggplot2 syntax, say use different geoms.geom geometrical object plot uses represent data.\nPeople often describe plots type geom plot uses.\nexample, bar charts use bar geoms, line charts use line geoms, boxplots use boxplot geoms, .\nScatterplots break trend; use point geom.\nsee , can use different geoms plot data.\nplot left uses point geom, plot right uses smooth geom, smooth line fitted data.change geom plot, change geom function add ggplot().\ninstance, make plots , can use code:Every geom function ggplot2 takes mapping argument.\nHowever, every aesthetic works every geom.\nset shape point, couldn’t set “shape” line.\nhand, set linetype line.\ngeom_smooth() draw different line, different linetype, unique value variable map linetype.geom_smooth() separates cars three lines based drv value, describes car’s drive train.\nOne line describes points 4 value, one line describes points f value, one line describes points r value.\n, 4 stands four-wheel drive, f front-wheel drive, r rear-wheel drive.sounds strange, can make clear overlaying lines top raw data colouring everything according drv.Notice plot contains two geoms graph!\nmakes excited, buckle .\nlearn place multiple geoms plot soon.ggplot2 provides 40 geoms, extension packages provide even (see https://exts.ggplot2.tidyverse.org/gallery/ sampling).\nbest way get comprehensive overview ggplot2 cheatsheet, can find http://rstudio.com/resources/cheatsheets.\nlearn single geom, use help, e.g. ?geom_smooth.Many geoms, like geom_smooth(), use single geometric object display multiple rows data.\ngeoms, can set group aesthetic categorical variable draw multiple objects.\nggplot2 draw separate object unique value grouping variable.\npractice, ggplot2 automatically group data geoms whenever map aesthetic discrete variable (linetype example).\nconvenient rely feature group aesthetic add legend distinguishing features geoms.display multiple geoms plot, add multiple geom functions ggplot():, however, introduces duplication code.\nImagine wanted change y-axis display cty instead hwy.\n’d need change variable two places, might forget update one.\ncan avoid type repetition passing set mappings ggplot().\nggplot2 treat mappings global mappings apply geom graph.\nwords, code produce plot previous code:place mappings geom function, ggplot2 treat local mappings layer.\nuse mappings extend overwrite global mappings layer .\nmakes possible display different aesthetics different layers.can use idea specify different data layer.\n, smooth line displays just subset mpg dataset, subcompact cars.\nlocal data argument geom_smooth() overrides global data argument ggplot() layer .(’ll learn filter() works chapter data transformations: now, just know command selects subcompact cars.)","code":"\n# left\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\n\n# right\nggplot(data = mpg) + \n  geom_smooth(mapping = aes(x = displ, y = hwy))\nggplot(data = mpg) + \n  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))\nggplot(data = mpg) +\n  geom_smooth(mapping = aes(x = displ, y = hwy))\n              \nggplot(data = mpg) +\n  geom_smooth(mapping = aes(x = displ, y = hwy, group = drv))\n    \nggplot(data = mpg) +\n  geom_smooth(\n    mapping = aes(x = displ, y = hwy, color = drv),\n    show.legend = FALSE\n  )\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  geom_smooth(mapping = aes(x = displ, y = hwy))\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth()\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth()\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth(data = filter(mpg, class == \"subcompact\"), se = FALSE)"},{"path":"data-visualisation.html","id":"exercises-3","chapter":"3 Data visualisation","heading":"3.6.1 Exercises","text":"geom use draw line chart?\nboxplot?\nhistogram?\narea chart?geom use draw line chart?\nboxplot?\nhistogram?\narea chart?Run code head predict output look like.\n, run code R check predictions.\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + \n  geom_point() + \n  geom_smooth(se = FALSE)Run code head predict output look like.\n, run code R check predictions.show.legend = FALSE ?\nhappens remove ?\nthink used earlier chapter?show.legend = FALSE ?\nhappens remove ?\nthink used earlier chapter?se argument geom_smooth() ?se argument geom_smooth() ?two graphs look different?\n/?\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth()\n\nggplot() + \n  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))two graphs look different?\n/?Recreate R code necessary generate following graphs.\nNote wherever categorical variable used plot, ’s drv.\nRecreate R code necessary generate following graphs.\nNote wherever categorical variable used plot, ’s drv.","code":"\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth()\n\nggplot() + \n  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))"},{"path":"data-visualisation.html","id":"statistical-transformations","chapter":"3 Data visualisation","heading":"3.7 Statistical transformations","text":"Next, let’s take look bar chart.\nBar charts seem simple, interesting reveal something subtle plots.\nConsider basic bar chart, drawn geom_bar().\nfollowing chart displays total number diamonds diamonds dataset, grouped cut.\ndiamonds dataset ggplot2 package contains information ~54,000 diamonds, including price, carat, color, clarity, cut diamond.\nchart shows diamonds available high quality cuts low quality cuts.x-axis, chart displays cut, variable diamonds.\ny-axis, displays count, count variable diamonds!\ncount come ?\nMany graphs, like scatterplots, plot raw values dataset.\ngraphs, like bar charts, calculate new values plot:bar charts, histograms, frequency polygons bin data plot bin counts, number points fall bin.bar charts, histograms, frequency polygons bin data plot bin counts, number points fall bin.smoothers fit model data plot predictions model.smoothers fit model data plot predictions model.boxplots compute robust summary distribution display specially formatted box.boxplots compute robust summary distribution display specially formatted box.algorithm used calculate new values graph called stat, short statistical transformation.\nfigure describes process works geom_bar().can learn stat geom uses inspecting default value stat argument.\nexample, ?geom_bar shows default value stat “count”, means geom_bar() uses stat_count().\nstat_count() documented page geom_bar(), scroll can find section called “Computed variables”.\ndescribes computes two new variables: count prop.can generally use geoms stats interchangeably.\nexample, can recreate previous plot using stat_count() instead geom_bar():works every geom default stat; every stat default geom.\nmeans can typically use geoms without worrying underlying statistical transformation.\nthree reasons might need use stat explicitly:might want override default stat.\ncode , change stat geom_bar() count (default) identity.\nlets map height bars raw values \\(y\\) variable.\nUnfortunately people talk bar charts casually, might referring type bar chart, height bar already present data, previous bar chart height bar generated counting rows.\n\ndemo <- tribble(\n  ~cut,         ~freq,\n  \"Fair\",       1610,\n  \"Good\",       4906,\n  \"Good\",  12082,\n  \"Premium\",    13791,\n  \"Ideal\",      21551\n)\n\nggplot(data = demo) +\n  geom_bar(mapping = aes(x = cut, y = freq), stat = \"identity\")\n\n(Don’t worry haven’t seen <- tribble() .\nmight able guess meaning context, ’ll learn exactly soon!)might want override default stat.\ncode , change stat geom_bar() count (default) identity.\nlets map height bars raw values \\(y\\) variable.\nUnfortunately people talk bar charts casually, might referring type bar chart, height bar already present data, previous bar chart height bar generated counting rows.(Don’t worry haven’t seen <- tribble() .\nmight able guess meaning context, ’ll learn exactly soon!)might want override default mapping transformed variables aesthetics.\nexample, might want display bar chart proportions, rather counts:\n\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, y = after_stat(prop), group = 1))\n\nfind variables computed stat, look section titled “computed variables” help geom_bar().might want override default mapping transformed variables aesthetics.\nexample, might want display bar chart proportions, rather counts:find variables computed stat, look section titled “computed variables” help geom_bar().might want draw greater attention statistical transformation code.\nexample, might use stat_summary(), summarises y values unique x value, draw attention summary ’re computing:\n\nggplot(data = diamonds) + \n  stat_summary(\n    mapping = aes(x = cut, y = depth),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )\nmight want draw greater attention statistical transformation code.\nexample, might use stat_summary(), summarises y values unique x value, draw attention summary ’re computing:ggplot2 provides 20 stats use.\nstat function, can get help usual way, e.g. ?stat_bin.\nsee complete list stats, try ggplot2 cheatsheet.","code":"\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut))\nggplot(data = diamonds) + \n  stat_count(mapping = aes(x = cut))\ndemo <- tribble(\n  ~cut,         ~freq,\n  \"Fair\",       1610,\n  \"Good\",       4906,\n  \"Very Good\",  12082,\n  \"Premium\",    13791,\n  \"Ideal\",      21551\n)\n\nggplot(data = demo) +\n  geom_bar(mapping = aes(x = cut, y = freq), stat = \"identity\")\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, y = after_stat(prop), group = 1))\nggplot(data = diamonds) + \n  stat_summary(\n    mapping = aes(x = cut, y = depth),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )"},{"path":"data-visualisation.html","id":"exercises-4","chapter":"3 Data visualisation","heading":"3.7.1 Exercises","text":"default geom associated stat_summary()?\nrewrite previous plot use geom function instead stat function?default geom associated stat_summary()?\nrewrite previous plot use geom function instead stat function?geom_col() ?\ndifferent geom_bar()?geom_col() ?\ndifferent geom_bar()?geoms stats come pairs almost always used concert.\nRead documentation make list pairs.\ncommon?geoms stats come pairs almost always used concert.\nRead documentation make list pairs.\ncommon?variables stat_smooth() compute?\nparameters control behaviour?variables stat_smooth() compute?\nparameters control behaviour?proportion bar chart, need set group = 1.\n?\nwords problem two graphs?\n\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, y = after_stat(prop)))\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = color, y = after_stat(prop)))proportion bar chart, need set group = 1.\n?\nwords problem two graphs?","code":"\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, y = after_stat(prop)))\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = color, y = after_stat(prop)))"},{"path":"data-visualisation.html","id":"position-adjustments","chapter":"3 Data visualisation","heading":"3.8 Position adjustments","text":"’s one piece magic associated bar charts.\ncan colour bar chart using either colour aesthetic, , usefully, fill:Note happens map fill aesthetic another variable, like clarity: bars automatically stacked.\ncoloured rectangle represents combination cut clarity.stacking performed automatically position adjustment specified position argument.\ndon’t want stacked bar chart, can use one three options: \"identity\", \"dodge\" \"fill\".position = \"identity\" place object exactly falls context graph.\nuseful bars, overlaps .\nsee overlapping either need make bars slightly transparent setting alpha small value, completely transparent setting fill = NA.\n\nggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + \n  geom_bar(alpha = 1/5, position = \"identity\")\nggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + \n  geom_bar(fill = NA, position = \"identity\")\n\nidentity position adjustment useful 2d geoms, like points, default.position = \"identity\" place object exactly falls context graph.\nuseful bars, overlaps .\nsee overlapping either need make bars slightly transparent setting alpha small value, completely transparent setting fill = NA.identity position adjustment useful 2d geoms, like points, default.position = \"fill\" works like stacking, makes set stacked bars height.\nmakes easier compare proportions across groups.\n\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = clarity), position = \"fill\")\nposition = \"fill\" works like stacking, makes set stacked bars height.\nmakes easier compare proportions across groups.position = \"dodge\" places overlapping objects directly beside one another.\nmakes easier compare individual values.\n\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = clarity), position = \"dodge\")\nposition = \"dodge\" places overlapping objects directly beside one another.\nmakes easier compare individual values.’s one type adjustment ’s useful bar charts, can useful scatterplots.\nRecall first scatterplot.\nnotice plot displays 126 points, even though 234 observations dataset?underlying values hwy displ rounded points appear grid many points overlap .\nproblem known overplotting.\narrangement makes hard see mass data .\ndata points spread equally throughout graph, one special combination hwy displ contains 109 values?can avoid gridding setting position adjustment “jitter”.\nposition = \"jitter\" adds small amount random noise point.\nspreads points two points likely receive amount random noise.Adding randomness seems like strange way improve plot, makes graph less accurate small scales, makes graph revealing large scales.\nuseful operation, ggplot2 comes shorthand geom_point(position = \"jitter\"): geom_jitter().learn position adjustment, look help page associated adjustment: ?position_dodge, ?position_fill, ?position_identity, ?position_jitter, ?position_stack.","code":"\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, colour = cut))\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = cut))\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = clarity))\nggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + \n  geom_bar(alpha = 1/5, position = \"identity\")\nggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + \n  geom_bar(fill = NA, position = \"identity\")\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = clarity), position = \"fill\")\nggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = clarity), position = \"dodge\")\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy), position = \"jitter\")"},{"path":"data-visualisation.html","id":"exercises-5","chapter":"3 Data visualisation","heading":"3.8.1 Exercises","text":"problem plot?\nimprove ?\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + \n  geom_point()\nproblem plot?\nimprove ?parameters geom_jitter() control amount jittering?parameters geom_jitter() control amount jittering?Compare contrast geom_jitter() geom_count().Compare contrast geom_jitter() geom_count().’s default position adjustment geom_boxplot()?\nCreate visualisation mpg dataset demonstrates .’s default position adjustment geom_boxplot()?\nCreate visualisation mpg dataset demonstrates .","code":"\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + \n  geom_point()"},{"path":"data-visualisation.html","id":"coordinate-systems","chapter":"3 Data visualisation","heading":"3.9 Coordinate systems","text":"Coordinate systems probably complicated part ggplot2.\ndefault coordinate system Cartesian coordinate system x y positions act independently determine location point.\nnumber coordinate systems occasionally helpful.coord_flip() switches x y axes.\nuseful (example), want horizontal boxplots.\n’s also useful long labels: ’s hard get fit without overlapping x-axis.\n\nggplot(data = mpg, mapping = aes(x = class, y = hwy)) + \n  geom_boxplot()\nggplot(data = mpg, mapping = aes(x = class, y = hwy)) + \n  geom_boxplot() +\n  coord_flip()\n\nHowever, note can achieve result flipping aesthetic mappings two variables.\n\nggplot(data = mpg, mapping = aes(y = class, x = hwy)) + \n  geom_boxplot()\ncoord_flip() switches x y axes.\nuseful (example), want horizontal boxplots.\n’s also useful long labels: ’s hard get fit without overlapping x-axis.However, note can achieve result flipping aesthetic mappings two variables.coord_quickmap() sets aspect ratio correctly maps.\nimportant ’re plotting spatial data ggplot2 (unfortunately don’t space cover book).\n\nnz <- map_data(\"nz\")\n\nggplot(nz, aes(long, lat, group = group)) +\n  geom_polygon(fill = \"white\", colour = \"black\")\n\nggplot(nz, aes(long, lat, group = group)) +\n  geom_polygon(fill = \"white\", colour = \"black\") +\n  coord_quickmap()\ncoord_quickmap() sets aspect ratio correctly maps.\nimportant ’re plotting spatial data ggplot2 (unfortunately don’t space cover book).coord_polar() uses polar coordinates.\nPolar coordinates reveal interesting connection bar chart Coxcomb chart.\n\nbar <- ggplot(data = diamonds) + \n  geom_bar(\n    mapping = aes(x = cut, fill = cut), \n    show.legend = FALSE,\n    width = 1\n  ) + \n  theme(aspect.ratio = 1) +\n  labs(x = NULL, y = NULL)\n\nbar + coord_flip()\nbar + coord_polar()\ncoord_polar() uses polar coordinates.\nPolar coordinates reveal interesting connection bar chart Coxcomb chart.","code":"\nggplot(data = mpg, mapping = aes(x = class, y = hwy)) + \n  geom_boxplot()\nggplot(data = mpg, mapping = aes(x = class, y = hwy)) + \n  geom_boxplot() +\n  coord_flip()\nggplot(data = mpg, mapping = aes(y = class, x = hwy)) + \n  geom_boxplot()\nnz <- map_data(\"nz\")\n\nggplot(nz, aes(long, lat, group = group)) +\n  geom_polygon(fill = \"white\", colour = \"black\")\n\nggplot(nz, aes(long, lat, group = group)) +\n  geom_polygon(fill = \"white\", colour = \"black\") +\n  coord_quickmap()\nbar <- ggplot(data = diamonds) + \n  geom_bar(\n    mapping = aes(x = cut, fill = cut), \n    show.legend = FALSE,\n    width = 1\n  ) + \n  theme(aspect.ratio = 1) +\n  labs(x = NULL, y = NULL)\n\nbar + coord_flip()\nbar + coord_polar()"},{"path":"data-visualisation.html","id":"exercises-6","chapter":"3 Data visualisation","heading":"3.9.1 Exercises","text":"Turn stacked bar chart pie chart using coord_polar().Turn stacked bar chart pie chart using coord_polar().labs() ?\nRead documentation.labs() ?\nRead documentation.’s difference coord_quickmap() coord_map()?’s difference coord_quickmap() coord_map()?plot tell relationship city highway mpg?\ncoord_fixed() important?\ngeom_abline() ?\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +\n  geom_point() + \n  geom_abline() +\n  coord_fixed()\nplot tell relationship city highway mpg?\ncoord_fixed() important?\ngeom_abline() ?","code":"\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +\n  geom_point() + \n  geom_abline() +\n  coord_fixed()"},{"path":"data-visualisation.html","id":"the-layered-grammar-of-graphics","chapter":"3 Data visualisation","heading":"3.10 The layered grammar of graphics","text":"previous sections, learned much make scatterplots, bar charts, boxplots.\nlearned foundation can use make type plot ggplot2.\nsee , let’s add position adjustments, stats, coordinate systems, faceting code template:new template takes seven parameters, bracketed words appear template.\npractice, rarely need supply seven parameters make graph ggplot2 provide useful defaults everything except data, mappings, geom function.seven parameters template compose grammar graphics, formal system building plots.\ngrammar graphics based insight can uniquely describe plot combination dataset, geom, set mappings, stat, position adjustment, coordinate system, faceting scheme.see works, consider build basic plot scratch: start dataset transform information want display (stat).Next, choose geometric object represent observation transformed data.\nuse aesthetic properties geoms represent variables data.\nmap values variable levels aesthetic.’d select coordinate system place geoms .\n’d use location objects (aesthetic property) display values x y variables.\npoint, complete graph, adjust positions geoms within coordinate system (position adjustment) split graph subplots (faceting).\nalso extend plot adding one additional layers, additional layer uses dataset, geom, set mappings, stat, position adjustment.use method build plot imagine.\nwords, can use code template ’ve learned chapter build hundreds thousands unique plots.","code":"ggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(\n     mapping = aes(<MAPPINGS>),\n     stat = <STAT>, \n     position = <POSITION>\n  ) +\n  <COORDINATE_FUNCTION> +\n  <FACET_FUNCTION>"},{"path":"workflow-basics.html","id":"workflow-basics","chapter":"4 Workflow: basics","heading":"4 Workflow: basics","text":"now experience running R code.\ndidn’t give many details, ’ve obviously figured basics, ’ve thrown book away frustration!\nFrustration natural start programming R, stickler punctuation, even one character place cause complain.\nexpect little frustrated, take comfort ’s typical temporary: happens everyone, way get keep trying.go , let’s make sure ’ve got solid foundation running R code, know helpful RStudio features.","code":""},{"path":"workflow-basics.html","id":"coding-basics","chapter":"4 Workflow: basics","heading":"4.1 Coding basics","text":"Let’s review basics ’ve far omitted interests getting plotting quickly possible.\ncan use R calculator:can create new objects <-:R statements create objects, assignment statements, form:reading code say “object name gets value” head.make lots assignments <- pain type.\nDon’t lazy use =: work, cause confusion later.\nInstead, use RStudio’s keyboard shortcut: Alt + - (minus sign).\nNotice RStudio automagically surrounds <- spaces, good code formatting practice.\nCode miserable read good day, giveyoureyesabreak use spaces.","code":"\n1 / 200 * 30\n#> [1] 0.15\n(59 + 73 + 2) / 3\n#> [1] 44.66667\nsin(pi / 2)\n#> [1] 1\nx <- 3 * 4\nobject_name <- value"},{"path":"workflow-basics.html","id":"whats-in-a-name","chapter":"4 Workflow: basics","heading":"4.2 What’s in a name?","text":"Object names must start letter, can contain letters, numbers, _ ..\nwant object names descriptive, ’ll need convention multiple words.\nrecommend snake_case separate lowercase words _.’ll come back code style later, Chapter 34 functions.\n’re interested learning best practices code style, also recommend tidyverse style guide: https://style.tidyverse.org.can inspect object typing name:Make another assignment:inspect object, try RStudio’s completion facility: type “”, press TAB, add characters unique prefix, press return.Ooops, made mistake!\nthis_is_a_really_long_name value 3.5 2.5.\nUse another keyboard shortcut help fix .\nType “” press Cmd/Ctrl + ↑.\nlist commands ’ve typed start letters.\nUse arrow keys navigate, press enter retype command.\nChange 2.5 3.5 rerun.Make yet another assignment:Let’s try inspect :’s implied contract R: tedious computation , return, must completely precise instructions.\nTypos matter.\nCase matters.","code":"\ni_use_snake_case\notherPeopleUseCamelCase\nsome.people.use.periods\nAnd_aFew.People_RENOUNCEconvention\nx\n#> [1] 12\nthis_is_a_really_long_name <- 2.5\nr_rocks <- 2 ^ 3\nr_rock\n#> Error: object 'r_rock' not found\nR_rocks\n#> Error: object 'R_rocks' not found"},{"path":"workflow-basics.html","id":"calling-functions","chapter":"4 Workflow: basics","heading":"4.3 Calling functions","text":"R large collection built-functions called like :Let’s try using seq() makes regular sequences numbers , ’re , learn helpful features RStudio.\nType se hit TAB.\npopup shows possible completions.\nSpecify seq() typing (q) disambiguate, using ↑/↓ arrows select.\nNotice floating tooltip pops , reminding function’s arguments purpose.\nwant help, press F1 get details help tab lower right pane.Press TAB ’ve selected function want.\nRStudio add matching opening (() closing ()) parentheses .\nType arguments 1, 10 hit return.Type code notice get similar assistance paired quotation marks:Quotation marks parentheses must always come pair.\nRStudio best help , ’s still possible mess end mismatch.\nhappens, R show continuation character “+”:+ tells R waiting input; doesn’t think ’re done yet.\nUsually means ’ve forgotten either \" ). Either add missing pair, press ESCAPE abort expression try .make assignment, don’t get see value.\n’re tempted immediately double-check result:common action can shortened surrounding assignment parentheses, causes assignment “print screen” happen.Now look environment upper right pane:can see objects ’ve created.","code":"\nfunction_name(arg1 = val1, arg2 = val2, ...)\nseq(1, 10)\n#>  [1]  1  2  3  4  5  6  7  8  9 10\nx <- \"hello world\"> x <- \"hello\n+\ny <- seq(1, 10, length.out = 5)\ny\n#> [1]  1.00  3.25  5.50  7.75 10.00\n(y <- seq(1, 10, length.out = 5))\n#> [1]  1.00  3.25  5.50  7.75 10.00"},{"path":"workflow-basics.html","id":"exercises-7","chapter":"4 Workflow: basics","heading":"4.4 Exercises","text":"code work?\nmy_variable <- 10\nmy_varıable\n#> Error: <text>:2:14: unexpected '>'\n#> 1: my_variable <- 10\n#> 2: my_var<U+0131>\n#>                 ^\nLook carefully!\n(may seem like exercise pointlessness, training brain notice even tiniest difference pay programming.)code work?Look carefully!\n(may seem like exercise pointlessness, training brain notice even tiniest difference pay programming.)Tweak following R commands run correctly:\n\nlibary(tidyverse)\n\nggplot(dota = mpg) + \n  geom_point(maping = aes(x = displ, y = hwy))Tweak following R commands run correctly:Press Alt + Shift + K.\nhappens?\ncan get place using menus?Press Alt + Shift + K.\nhappens?\ncan get place using menus?","code":"my_variable <- 10\nmy_varıable\n#> Error: <text>:2:14: unexpected '>'\n#> 1: my_variable <- 10\n#> 2: my_var<U+0131>\n#>                 ^\nlibary(tidyverse)\n\nggplot(dota = mpg) + \n  geom_point(maping = aes(x = displ, y = hwy))"},{"path":"data-transform.html","id":"data-transform","chapter":"5 Data transformation","heading":"5 Data transformation","text":"reading work--progress second edition R Data Science. chapter currently undergoing heavy restructuring may confusing incomplete. can find polished first edition https://r4ds..co.nz.","code":""},{"path":"data-transform.html","id":"introduction-2","chapter":"5 Data transformation","heading":"5.1 Introduction","text":"Visualisation important tool insight generation, rare get data exactly right form need.\nOften ’ll need create new variables summaries, maybe just want rename variables reorder observations order make data little easier work .\n’ll learn (!) chapter, teach transform data using dplyr package new dataset flights departing New York City 2013.","code":""},{"path":"data-transform.html","id":"prerequisites-2","chapter":"5 Data transformation","heading":"5.1.1 Prerequisites","text":"chapter ’re going focus use dplyr package, another core member tidyverse.\n’ll illustrate key ideas using data nycflights13 package, use ggplot2 help us understand data.Take careful note conflicts message ’s printed load tidyverse.\ntells dplyr overwrites functions base R.\nwant use base version functions loading dplyr, ’ll need use full names: stats::filter() stats::lag().","code":"\nlibrary(nycflights13)\nlibrary(tidyverse)\n#> -- <U+2029>[1mAttaching packages<U+2029>[22m --------------------------------------- tidyverse 1.3.1 --NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mggplot2<U+2029>[39m 3.3.5          <U+2029>[32mv<U+2029>[39m <U+2029>[34mpurrr  <U+2029>[39m 0.3.4     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtibble <U+2029>[39m 3.1.2          <U+2029>[32mv<U+2029>[39m <U+2029>[34mdplyr  <U+2029>[39m 1.0.7     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtidyr  <U+2029>[39m 1.1.3          <U+2029>[32mv<U+2029>[39m <U+2029>[34mstringr<U+2029>[39m 1.4.0.<U+2029>[31m9000<U+2029>[39mNA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mreadr  <U+2029>[39m 2.0.1          <U+2029>[32mv<U+2029>[39m <U+2029>[34mforcats<U+2029>[39m 0.5.1NA#> -- <U+2029>[1mConflicts<U+2029>[22m ------------------------------------------ tidyverse_conflicts() --NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mfilter()<U+2029>[39m masks <U+2029>[34mstats<U+2029>[39m::filter()NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mlag()<U+2029>[39m    masks <U+2029>[34mstats<U+2029>[39m::lag()NA"},{"path":"data-transform.html","id":"nycflights13","chapter":"5 Data transformation","heading":"5.1.2 nycflights13","text":"explore basic dplyr verbs, ’re going look nycflights13::flights.\ndata frame contains 336,776 flights departed New York City 2013.\ndata comes US Bureau Transportation Statistics, documented ?flights.’ve used R , might notice data frame prints little differently data frames might’ve worked past.\n’s ’s tibble, special type data frame designed tidyverse team avoid common data.frame gotchas.\nimportant difference way prints: tibbles designed large datasets, show first rows columns fit one screen.\nwant see everything can use View(flights) open dataset RStudio viewer.\n’ll come back important differences Chapter 13.might also noticed row short abbreviations column names.\ndescribe type variable:int stands integer.int stands integer.dbl stands double, vector real numbers.dbl stands double, vector real numbers.chr stands character, vector strings.chr stands character, vector strings.dttm stands date-time (date + time).dttm stands date-time (date + time).three common types aren’t used ’ll encounter later book:lgl stands logical, vector contains TRUE FALSE.lgl stands logical, vector contains TRUE FALSE.fctr stands factor, R uses represent categorical variables fixed possible values.fctr stands factor, R uses represent categorical variables fixed possible values.date stands date.date stands date.","code":"\nflights\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... with 336,770 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA"},{"path":"data-transform.html","id":"dplyr-basics","chapter":"5 Data transformation","heading":"5.1.3 dplyr basics","text":"chapter going learn primary dplyr verbs allow solve vast majority data manipulation challenges.\norganised four camps:Functions operate rows: filter() subsets rows based values columns, slice() friends subsets rows based position, arrange() changes order rows.Functions operate rows: filter() subsets rows based values columns, slice() friends subsets rows based position, arrange() changes order rows.Functions operate columns: mutate() creates new columns, select() columns, rename() changes names, relocate() changes positions.Functions operate columns: mutate() creates new columns, select() columns, rename() changes names, relocate() changes positions.Functions operate groups: group_by() divides data groups analysis, summarise() reduces group single row.Functions operate groups: group_by() divides data groups analysis, summarise() reduces group single row.Later, Chapter 14, ’ll learn verbs work tables, like join functions set operations.dplyr verbs work way:first argument data frame.first argument data frame.subsequent arguments describe data frame, using variable names (without quotes).subsequent arguments describe data frame, using variable names (without quotes).result new data frame.result new data frame.Together properties make easy chain together multiple simple steps achieve complex result.\nLet’s dive see verbs work.","code":""},{"path":"data-transform.html","id":"rows","chapter":"5 Data transformation","heading":"5.2 Rows","text":"functions affect rows (observations), leaving columns (variables) unchanged.\nfilter() changes rows included without changing order, arrange() changes order without changing membership.","code":""},{"path":"data-transform.html","id":"filter","chapter":"5 Data transformation","heading":"5.2.1 filter()","text":"filter() allows choose rows based values1.\nfirst argument name data frame.\nsecond subsequent arguments expressions filter data frame.\nexample, can select flights January 1st :run line code, dplyr executes filtering operation returns new data frame.\ndplyr functions never modify inputs, want save result, ’ll need use assignment operator, <-:use filtering effectively, know select observations want using comparison operators.\nR provides standard suite: >, >=, <, <=, != (equal), == (equal).\nalso provides %%: filter(df, x %% c(, b, c)) return rows x , b, c.’re starting R, easiest mistake make use = instead == testing equality.\nfilter() let know happens:","code":"\nfilter(flights, month == 1, day == 1)\n#> <U+2029>[90m# A tibble: 842 x 19<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... with 836 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\njan1 <- filter(flights, month == 1, day == 1)\nfilter(flights, month = 1)\n#> Error: Problem with `filter()` input `..1`.\n#> <U+2029>[31mx<U+2029>[39m Input `..1` is named.NA#> <U+2029>[34mi<U+2029>[39m This usually means that you've used `=` instead of `==`.NA#> <U+2029>[34mi<U+2029>[39m Did you mean `month == 1`?NA"},{"path":"data-transform.html","id":"arrange","chapter":"5 Data transformation","heading":"5.2.2 arrange()","text":"arrange() works similarly filter() except instead selecting rows, changes order.\ntakes data frame set column names (complicated expressions) order .\nprovide one column name, additional column used break ties values preceding columns:can use desc() re-order column descending order:","code":"\narrange(flights, year, month, day)\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... with 336,770 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\narrange(flights, desc(dep_delay))\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     9      641            900      <U+2029>[4m1<U+2029>[24m301     <U+2029>[4m1<U+2029>[24m242           <U+2029>[4m1<U+2029>[24m530NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     6    15     <U+2029>[4m1<U+2029>[24m432           <U+2029>[4m1<U+2029>[24m935      <U+2029>[4m1<U+2029>[24m137     <U+2029>[4m1<U+2029>[24m607           <U+2029>[4m2<U+2029>[24m120NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1    10     <U+2029>[4m1<U+2029>[24m121           <U+2029>[4m1<U+2029>[24m635      <U+2029>[4m1<U+2029>[24m126     <U+2029>[4m1<U+2029>[24m239           <U+2029>[4m1<U+2029>[24m810NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     9    20     <U+2029>[4m1<U+2029>[24m139           <U+2029>[4m1<U+2029>[24m845      <U+2029>[4m1<U+2029>[24m014     <U+2029>[4m1<U+2029>[24m457           <U+2029>[4m2<U+2029>[24m210NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     7    22      845           <U+2029>[4m1<U+2029>[24m600      <U+2029>[4m1<U+2029>[24m005     <U+2029>[4m1<U+2029>[24m044           <U+2029>[4m1<U+2029>[24m815NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     4    10     <U+2029>[4m1<U+2029>[24m100           <U+2029>[4m1<U+2029>[24m900       960     <U+2029>[4m1<U+2029>[24m342           <U+2029>[4m2<U+2029>[24m211NA#> <U+2029>[90m# ... with 336,770 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA"},{"path":"data-transform.html","id":"exercises-8","chapter":"5 Data transformation","heading":"5.2.3 Exercises","text":"Find flights \narrival delay two hours\nFlew Houston (IAH HOU)\noperated United, American, Delta\nDeparted summer (July, August, September)\nArrived two hours late, didn’t leave late\ndelayed least hour, made 30 minutes flight\nDeparted midnight 6am (inclusive)\nFind flights thatHad arrival delay two hoursFlew Houston (IAH HOU)operated United, American, DeltaDeparted summer (July, August, September)Arrived two hours late, didn’t leave lateWere delayed least hour, made 30 minutes flightDeparted midnight 6am (inclusive)Sort flights find flights longest departure delays.\nFind flights left earliest.Sort flights find flights longest departure delays.\nFind flights left earliest.Sort flights find fastest (highest speed) flights.\n(Hint: try sorting calculation).Sort flights find fastest (highest speed) flights.\n(Hint: try sorting calculation).flights travelled farthest?\ntravelled shortest?flights travelled farthest?\ntravelled shortest?","code":""},{"path":"data-transform.html","id":"columns","chapter":"5 Data transformation","heading":"5.3 Columns","text":"functions affect columns (variables) without changing rows (observations).\nmutate() creates new variables functions existing variables; select(), rename(), relocate() changes variables present, names, positions.","code":""},{"path":"data-transform.html","id":"mutate","chapter":"5 Data transformation","heading":"5.3.1 mutate()","text":"job mutate() add new columns functions existing column.\nlater chapters, ’ll learn full set functions can use manipulate different types variables.\nnow, ’ll stick basic mathematical operators, allows us compute gain, much time delayed flight made air, speed miles per hour:default, mutate() adds new columns right hand side dataset, makes hard see ’s happening .\ncan use .argument instead add variables left hand side2:leading . sign .argument function, new variable created.\ncan also use .add variable, use variable name instead position:Alternatively, can control variables kept .keep argument:","code":"\nmutate(flights,\n  gain = dep_delay - arr_delay,\n  speed = distance / air_time * 60\n)\n#> <U+2029>[90m# A tibble: 336,776 x 21<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... with 336,770 more rows, and 13 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mgain<U+2029>[22m <dbl>, <U+2029>[1mspeed<U+2029>[22m <dbl><U+2029>[39mNA\nmutate(flights,\n  gain = dep_delay - arr_delay,\n  speed = distance / air_time * 60,\n  .before = 1\n)\n#> <U+2029>[90m# A tibble: 336,776 x 21<U+2029>[39mNA#>    <U+2029>[1mgain<U+2029>[22m <U+2029>[1mspeed<U+2029>[22m  <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m    -<U+2029>[31m9<U+2029>[39m  370.  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830NA#> <U+2029>[90m2<U+2029>[39m   -<U+2029>[31m16<U+2029>[39m  374.  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850NA#> <U+2029>[90m3<U+2029>[39m   -<U+2029>[31m31<U+2029>[39m  408.  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923NA#> <U+2029>[90m4<U+2029>[39m    17  517.  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004NA#> <U+2029>[90m5<U+2029>[39m    19  394.  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812NA#> <U+2029>[90m6<U+2029>[39m   -<U+2029>[31m16<U+2029>[39m  288.  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740NA#> <U+2029>[90m# ... with 336,770 more rows, and 12 more variables: <U+2029>[1msched_arr_time<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1marr_delay<U+2029>[22m <dbl>, <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mdest<U+2029>[22m <chr>, <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\nmutate(flights,\n  gain = dep_delay - arr_delay,\n  speed = distance / air_time * 60,\n  .after = day\n)\n#> <U+2029>[90m# A tibble: 336,776 x 21<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mgain<U+2029>[22m <U+2029>[1mspeed<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1    -<U+2029>[31m9<U+2029>[39m  370.      517            515         2      830NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1   -<U+2029>[31m16<U+2029>[39m  374.      533            529         4      850NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1   -<U+2029>[31m31<U+2029>[39m  408.      542            540         2      923NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1    17  517.      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1    19  394.      554            600        -<U+2029>[31m6<U+2029>[39m      812NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1   -<U+2029>[31m16<U+2029>[39m  288.      554            558        -<U+2029>[31m4<U+2029>[39m      740NA#> <U+2029>[90m# ... with 336,770 more rows, and 12 more variables: <U+2029>[1msched_arr_time<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1marr_delay<U+2029>[22m <dbl>, <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mdest<U+2029>[22m <chr>, <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\nmutate(flights,\n  gain = dep_delay - arr_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours,\n  .keep = \"none\"\n)\n#> <U+2029>[90m# A tibble: 336,776 x 3<U+2029>[39mNA#>    <U+2029>[1mgain<U+2029>[22m <U+2029>[1mhours<U+2029>[22m <U+2029>[1mgain_per_hour<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m         <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m    -<U+2029>[31m9<U+2029>[39m  3.78         -<U+2029>[31m2<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m38<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m   -<U+2029>[31m16<U+2029>[39m  3.78         -<U+2029>[31m4<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m23<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m   -<U+2029>[31m31<U+2029>[39m  2.67        -<U+2029>[31m11<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m6<U+2029>[39m NA#> <U+2029>[90m4<U+2029>[39m    17  3.05          5.57NA#> <U+2029>[90m5<U+2029>[39m    19  1.93          9.83NA#> <U+2029>[90m6<U+2029>[39m   -<U+2029>[31m16<U+2029>[39m  2.5          -<U+2029>[31m6<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m4<U+2029>[39m NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA"},{"path":"data-transform.html","id":"select","chapter":"5 Data transformation","heading":"5.3.2 select()","text":"’s uncommon get datasets hundreds even thousands variables.\ncase, first challenge often narrowing variables ’re actually interested .\nselect() allows rapidly zoom useful subset using operations based names variables.select() terribly useful flights data 19 variables, can still get general idea works:number helper functions can use within select():starts_with(\"abc\"): matches names begin “abc”.starts_with(\"abc\"): matches names begin “abc”.ends_with(\"xyz\"): matches names end “xyz”.ends_with(\"xyz\"): matches names end “xyz”.contains(\"ijk\"): matches names contain “ijk”.contains(\"ijk\"): matches names contain “ijk”.num_range(\"x\", 1:3): matches x1, x2 x3.num_range(\"x\", 1:3): matches x1, x2 x3.See ?select details.\nknow regular expressions (topic Chapter 19) ’ll also use matches() select variables match regexp.can rename variables select() using =.\nnew name appears left hand side =, old variable appears right hand side:","code":"\n# Select columns by name\nselect(flights, year, month, day)\n#> <U+2029>[90m# A tibble: 336,776 x 3<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA# Select all columns between year and day (inclusive)\nselect(flights, year:day)\n#> <U+2029>[90m# A tibble: 336,776 x 3<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA# Select all columns except those from year to day (inclusive)\nselect(flights, -(year:day))\n#> <U+2029>[90m# A tibble: 336,776 x 16<U+2029>[39mNA#>   <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22m <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22mNA#>      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  NA#> <U+2029>[90m1<U+2029>[39m      517            515         2      830            819        11 UA     NA#> <U+2029>[90m2<U+2029>[39m      533            529         4      850            830        20 UA     NA#> <U+2029>[90m3<U+2029>[39m      542            540         2      923            850        33 AA     NA#> <U+2029>[90m4<U+2029>[39m      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022       -<U+2029>[31m18<U+2029>[39m B6     NA#> <U+2029>[90m5<U+2029>[39m      554            600        -<U+2029>[31m6<U+2029>[39m      812            837       -<U+2029>[31m25<U+2029>[39m DL     NA#> <U+2029>[90m6<U+2029>[39m      554            558        -<U+2029>[31m4<U+2029>[39m      740            728        12 UA     NA#> <U+2029>[90m# ... with 336,770 more rows, and 9 more variables: <U+2029>[1mflight<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>, <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\nselect(flights, tail_num = tailnum)\n#> <U+2029>[90m# A tibble: 336,776 x 1<U+2029>[39mNA#>   <U+2029>[1mtail_num<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   NA#> <U+2029>[90m1<U+2029>[39m N14228  NA#> <U+2029>[90m2<U+2029>[39m N24211  NA#> <U+2029>[90m3<U+2029>[39m N619AA  NA#> <U+2029>[90m4<U+2029>[39m N804JB  NA#> <U+2029>[90m5<U+2029>[39m N668DN  NA#> <U+2029>[90m6<U+2029>[39m N39463  NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA"},{"path":"data-transform.html","id":"rename","chapter":"5 Data transformation","heading":"5.3.3 rename()","text":"just want keep existing variables just want rename , can use rename() instead select():works exactly way select(), keeps variables aren’t explicitly selected.","code":"\nrename(flights, tail_num = tailnum)\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... with 336,770 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtail_num<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA"},{"path":"data-transform.html","id":"relocate","chapter":"5 Data transformation","heading":"5.3.4 relocate()","text":"can move variables around relocate.\ndefault moves variables front:can use ..arguments choose place :work way ..arguments mutate() — can numeric position, name variable, functions can use select().","code":"\nrelocate(flights, time_hour, air_time)\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#>   <U+2029>[1mtime_hour<U+2029>[22m           <U+2029>[1mair_time<U+2029>[22m  <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m                 <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m 2013-01-01 <U+2029>[90m05:00:00<U+2029>[39m      227  <U+2029>[4m2<U+2029>[24m013     1     1      517            515NA#> <U+2029>[90m2<U+2029>[39m 2013-01-01 <U+2029>[90m05:00:00<U+2029>[39m      227  <U+2029>[4m2<U+2029>[24m013     1     1      533            529NA#> <U+2029>[90m3<U+2029>[39m 2013-01-01 <U+2029>[90m05:00:00<U+2029>[39m      160  <U+2029>[4m2<U+2029>[24m013     1     1      542            540NA#> <U+2029>[90m4<U+2029>[39m 2013-01-01 <U+2029>[90m05:00:00<U+2029>[39m      183  <U+2029>[4m2<U+2029>[24m013     1     1      544            545NA#> <U+2029>[90m5<U+2029>[39m 2013-01-01 <U+2029>[90m06:00:00<U+2029>[39m      116  <U+2029>[4m2<U+2029>[24m013     1     1      554            600NA#> <U+2029>[90m6<U+2029>[39m 2013-01-01 <U+2029>[90m05:00:00<U+2029>[39m      150  <U+2029>[4m2<U+2029>[24m013     1     1      554            558NA#> <U+2029>[90m# ... with 336,770 more rows, and 12 more variables: <U+2029>[1mdep_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1marr_time<U+2029>[22m <int>, <U+2029>[1msched_arr_time<U+2029>[22m <int>, <U+2029>[1marr_delay<U+2029>[22m <dbl>, <U+2029>[1mcarrier<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>, <U+2029>[1mdistance<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl><U+2029>[39mNA\nrelocate(flights, year:dep_time, .after = time_hour)\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#>   <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22m <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mflight<U+2029>[22mNA#>            <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m            515         2      830            819        11 UA        <U+2029>[4m1<U+2029>[24m545NA#> <U+2029>[90m2<U+2029>[39m            529         4      850            830        20 UA        <U+2029>[4m1<U+2029>[24m714NA#> <U+2029>[90m3<U+2029>[39m            540         2      923            850        33 AA        <U+2029>[4m1<U+2029>[24m141NA#> <U+2029>[90m4<U+2029>[39m            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022       -<U+2029>[31m18<U+2029>[39m B6         725NA#> <U+2029>[90m5<U+2029>[39m            600        -<U+2029>[31m6<U+2029>[39m      812            837       -<U+2029>[31m25<U+2029>[39m DL         461NA#> <U+2029>[90m6<U+2029>[39m            558        -<U+2029>[31m4<U+2029>[39m      740            728        12 UA        <U+2029>[4m1<U+2029>[24m696NA#> <U+2029>[90m# ... with 336,770 more rows, and 12 more variables: <U+2029>[1mtailnum<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>, <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm>, <U+2029>[1myear<U+2029>[22m <int>, <U+2029>[1mmonth<U+2029>[22m <int>, <U+2029>[1mday<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mdep_time<U+2029>[22m <int><U+2029>[39mNArelocate(flights, starts_with(\"arr\"), .before = dep_time)\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      830        11      517            515         2NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      850        20      533            529         4NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      923        33      542            540         2NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     <U+2029>[4m1<U+2029>[24m004       -<U+2029>[31m18<U+2029>[39m      544            545        -<U+2029>[31m1<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      812       -<U+2029>[31m25<U+2029>[39m      554            600        -<U+2029>[31m6<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      740        12      554            558        -<U+2029>[31m4<U+2029>[39mNA#> <U+2029>[90m# ... with 336,770 more rows, and 11 more variables: <U+2029>[1msched_arr_time<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA"},{"path":"data-transform.html","id":"exercises-9","chapter":"5 Data transformation","heading":"5.3.5 Exercises","text":"Currently dep_time sched_dep_time convenient look , hard compute ’re really continuous numbers.\nConvert convenient representation number minutes since midnight.Currently dep_time sched_dep_time convenient look , hard compute ’re really continuous numbers.\nConvert convenient representation number minutes since midnight.Compare air_time arr_time - dep_time.\nexpect see?\nsee?\nneed fix ?Compare air_time arr_time - dep_time.\nexpect see?\nsee?\nneed fix ?Compare dep_time, sched_dep_time, dep_delay.\nexpect three numbers related?Compare dep_time, sched_dep_time, dep_delay.\nexpect three numbers related?Brainstorm many ways possible select dep_time, dep_delay, arr_time, arr_delay flights.Brainstorm many ways possible select dep_time, dep_delay, arr_time, arr_delay flights.happens include name variable multiple times select() call?happens include name variable multiple times select() call?any_of() function ?\nmight helpful conjunction vector?\n\nvariables <- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")any_of() function ?\nmight helpful conjunction vector?result running following code surprise ?\nselect helpers deal case default?\ncan change default?\n\nselect(flights, contains(\"TIME\"))result running following code surprise ?\nselect helpers deal case default?\ncan change default?","code":"\nvariables <- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\nselect(flights, contains(\"TIME\"))"},{"path":"data-transform.html","id":"groups","chapter":"5 Data transformation","heading":"5.4 Groups","text":"real power dplyr comes add grouping mix.\ntwo key functions group_by() summarise(), ’ll learn group_by() affects many dplyr verbs interesting ways.","code":""},{"path":"data-transform.html","id":"group_by","chapter":"5 Data transformation","heading":"5.4.1 group_by()","text":"Use group_by() divide dataset groups meaningful analysis:group_by() doesn’t change data , look closely, ’ll notice ’s now “grouped ” month.\nreason group data changes operation subsequent verbs.","code":"\nby_month <- group_by(flights, month)\nby_month\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#> <U+2029>[90m# Groups:   month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... with 336,770 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA"},{"path":"data-transform.html","id":"summarise","chapter":"5 Data transformation","heading":"5.4.2 summarise()","text":"important operation might apply grouped data summary.\ncollapses group single row3.\ncompute average departure delay month:can create number summaries single call summarise().\n’ll learn various useful summaries upcoming chapters individual data types, one useful summary n(), returns number rows group:(fact, count(), ’ve used bunch previous chapters, just shorthand group_by() + summarise(n = n()).)’ll come back discuss missing values Chapter 17.\nnow, know can drop summary functions using na.rm = TRUE remove filter using !.na():","code":"\nsummarise(by_month, delay = mean(dep_delay, na.rm = TRUE))\n#> <U+2029>[90m# A tibble: 12 x 2<U+2029>[39mNA#>   <U+2029>[1mmonth<U+2029>[22m <U+2029>[1mdelay<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1  10.0NA#> <U+2029>[90m2<U+2029>[39m     2  10.8NA#> <U+2029>[90m3<U+2029>[39m     3  13.2NA#> <U+2029>[90m4<U+2029>[39m     4  13.9NA#> <U+2029>[90m5<U+2029>[39m     5  13.0NA#> <U+2029>[90m6<U+2029>[39m     6  20.8NA#> <U+2029>[90m# ... with 6 more rows<U+2029>[39mNA\nsummarise(by_month, delay = mean(dep_delay, na.rm = TRUE), n = n())\n#> <U+2029>[90m# A tibble: 12 x 3<U+2029>[39mNA#>   <U+2029>[1mmonth<U+2029>[22m <U+2029>[1mdelay<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1  10.0 <U+2029>[4m2<U+2029>[24m<U+2029>[4m7<U+2029>[24m004NA#> <U+2029>[90m2<U+2029>[39m     2  10.8 <U+2029>[4m2<U+2029>[24m<U+2029>[4m4<U+2029>[24m951NA#> <U+2029>[90m3<U+2029>[39m     3  13.2 <U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m834NA#> <U+2029>[90m4<U+2029>[39m     4  13.9 <U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m330NA#> <U+2029>[90m5<U+2029>[39m     5  13.0 <U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m796NA#> <U+2029>[90m6<U+2029>[39m     6  20.8 <U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m243NA#> <U+2029>[90m# ... with 6 more rows<U+2029>[39mNA\nnot_cancelled <- filter(flights, !is.na(dep_delay))\nby_month <- group_by(not_cancelled, month)\nsummarise(by_month, delay = mean(dep_delay))\n#> <U+2029>[90m# A tibble: 12 x 2<U+2029>[39mNA#>   <U+2029>[1mmonth<U+2029>[22m <U+2029>[1mdelay<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1  10.0NA#> <U+2029>[90m2<U+2029>[39m     2  10.8NA#> <U+2029>[90m3<U+2029>[39m     3  13.2NA#> <U+2029>[90m4<U+2029>[39m     4  13.9NA#> <U+2029>[90m5<U+2029>[39m     5  13.0NA#> <U+2029>[90m6<U+2029>[39m     6  20.8NA#> <U+2029>[90m# ... with 6 more rows<U+2029>[39mNA"},{"path":"data-transform.html","id":"combining-multiple-operations","chapter":"5 Data transformation","heading":"5.4.3 Combining multiple operations","text":"code starting get little frustrating write intermediate data frame given name, even though don’t care .\nNaming things hard, slows analysis.\n’s another way tackle problem pipe, %>%:see %>% code, good way “pronounce” head “”.\nway can read code series imperative statements: take flights dataset, filter remove rows missing dep_delay, group month, summarise average dep_delay number observations.Behind scenes, x %>% f(y) turns f(x, y), x %>% f(y) %>% g(z) turns g(f(x, y), z) .\ncan use pipe rewrite multiple operations way can read left--right, top--bottom.\n’ll use piping frequently now considerably improves readability code, ’ll come back detail Chapter 7.","code":"\nflights %>% \n  filter(!is.na(dep_delay)) %>% \n  group_by(month) %>%\n  summarise(delay = mean(dep_delay), n = n())\n#> <U+2029>[90m# A tibble: 12 x 3<U+2029>[39mNA#>   <U+2029>[1mmonth<U+2029>[22m <U+2029>[1mdelay<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1  10.0 <U+2029>[4m2<U+2029>[24m<U+2029>[4m6<U+2029>[24m483NA#> <U+2029>[90m2<U+2029>[39m     2  10.8 <U+2029>[4m2<U+2029>[24m<U+2029>[4m3<U+2029>[24m690NA#> <U+2029>[90m3<U+2029>[39m     3  13.2 <U+2029>[4m2<U+2029>[24m<U+2029>[4m7<U+2029>[24m973NA#> <U+2029>[90m4<U+2029>[39m     4  13.9 <U+2029>[4m2<U+2029>[24m<U+2029>[4m7<U+2029>[24m662NA#> <U+2029>[90m5<U+2029>[39m     5  13.0 <U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m233NA#> <U+2029>[90m6<U+2029>[39m     6  20.8 <U+2029>[4m2<U+2029>[24m<U+2029>[4m7<U+2029>[24m234NA#> <U+2029>[90m# ... with 6 more rows<U+2029>[39mNA"},{"path":"data-transform.html","id":"grouping-by-multiple-variables","chapter":"5 Data transformation","heading":"5.4.4 Grouping by multiple variables","text":"can group data frame multiple variables:group multiple variables, summary peels one level grouping default, message printed tells can change behaviour.’re happy behaviour, can explicitly define order suppress message:Alternatively, can change default behaviour setting different value, e.g. \"drop\" dropping levels grouping \"keep\" grouping structure daily:","code":"\ndaily <- flights %>% group_by(year, month, day)\ndaily\n#> <U+2029>[90m# A tibble: 336,776 x 19<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month, day [365]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... with 336,770 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\ndaily %>% summarise(n = n())\n#> `summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.\n#> <U+2029>[90m# A tibble: 365 x 4<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1   842NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2   943NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3   914NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4   915NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5   720NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6   832NA#> <U+2029>[90m# ... with 359 more rows<U+2029>[39mNA\ndaily %>% summarise(n = n(), .groups = \"drop_last\")\ndaily %>% summarise(n = n(), .groups = \"drop\")\ndaily %>% summarise(n = n(), .groups = \"keep\")"},{"path":"data-transform.html","id":"ungrouping","chapter":"5 Data transformation","heading":"5.4.5 Ungrouping","text":"might also want remove grouping outside summarise().\ncan return operations ungrouped data using ungroup().purposes summarising, ungrouped data treated data single group, get one row back.","code":"\ndaily %>% \n  ungroup() %>%\n  summarise(\n    delay = mean(dep_delay, na.rm = TRUE), \n    flights = n()\n  )\n#> <U+2029>[90m# A tibble: 1 x 2<U+2029>[39mNA#>   <U+2029>[1mdelay<U+2029>[22m <U+2029>[1mflights<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  12.6  <U+2029>[4m3<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m6<U+2029>[24m776NA"},{"path":"data-transform.html","id":"selecting-rows","chapter":"5 Data transformation","heading":"5.4.6 Selecting rows","text":"arrange() filter() mostly unaffected grouping.\nslice functions super useful:slice_head() slice_tail() select first last rows group.slice_head() slice_tail() select first last rows group.slice_max() slice_min() select rows group highest lowest values.slice_max() slice_min() select rows group highest lowest values.slice_sample() random selects rows group.slice_sample() random selects rows group.verbs takes either n prop argument depending whether want select fixed number rows, number rows proportional group size.","code":""},{"path":"data-transform.html","id":"other-verbs","chapter":"5 Data transformation","heading":"5.4.7 Other verbs","text":"select(), rename(), relocate(): grouping affectselect(), rename(), relocate(): grouping affectfilter(), mutate(): computation happens per group.\ndoesn’t affect functions currently know useful learn window functions, Section 15.3.filter(), mutate(): computation happens per group.\ndoesn’t affect functions currently know useful learn window functions, Section 15.3.","code":""},{"path":"data-transform.html","id":"exercises-10","chapter":"5 Data transformation","heading":"5.4.8 Exercises","text":"carrier worst delays?\nChallenge: can disentangle effects bad airports vs. bad carriers?\n/?\n(Hint: think flights %>% group_by(carrier, dest) %>% summarise(n()))carrier worst delays?\nChallenge: can disentangle effects bad airports vs. bad carriers?\n/?\n(Hint: think flights %>% group_by(carrier, dest) %>% summarise(n()))sort argument count() .\nCan explain terms dplyr verbs ’ve learned far?sort argument count() .\nCan explain terms dplyr verbs ’ve learned far?","code":""},{"path":"data-transform.html","id":"case-study-aggregates-and-sample-size","chapter":"5 Data transformation","heading":"5.5 Case study: aggregates and sample size","text":"Whenever aggregation, ’s always good idea include either count (n()), count non-missing values (sum(!.na(x))).\nway can check ’re drawing conclusions based small amounts data.\nexample, let’s look planes (identified tail number) highest average delays:Wow, planes average delay 5 hours (300 minutes)!story actually little nuanced.\ncan get insight draw scatterplot number flights vs. average delay:surprisingly, much greater variation average delay flights.\nshape plot characteristic: whenever plot mean (summary) vs. group size, ’ll see variation decreases sample size increases.looking sort plot, ’s often useful filter groups smallest numbers observations, can see pattern less extreme variation smallest groups.\nfollowing code , well showing handy pattern integrating ggplot2 dplyr flows.\n’s bit painful switch %>% +, get hang , ’s quite convenient.’s another common variation type pattern.\nLet’s look average performance batters baseball related number times ’re bat.\nuse data Lahman package compute batting average (number hits / number attempts) every major league baseball player.plot skill batter (measured batting average, ba) number opportunities hit ball (measured bat, ab), see two patterns:, variation aggregate decreases get data points., variation aggregate decreases get data points.’s positive correlation skill (ba) opportunities hit ball (ab).\nteams control gets play, obviously ’ll pick best players.’s positive correlation skill (ba) opportunities hit ball (ab).\nteams control gets play, obviously ’ll pick best players.also important implications ranking.\nnaively sort desc(ba), people best batting averages clearly lucky, skilled:can find good explanation problem http://varianceexplained.org/r/empirical_bayes_baseball/ http://www.evanmiller.org/---sort--average-rating.html.","code":"\ndelays <- not_cancelled %>% \n  group_by(tailnum) %>% \n  summarise(\n    delay = mean(arr_delay)\n  )\n\nggplot(data = delays, mapping = aes(x = delay)) + \n  geom_freqpoly(binwidth = 10)\n#> Warning: Removed 874 rows containing non-finite values (stat_bin).\ndelays <- not_cancelled %>% \n  group_by(tailnum) %>% \n  summarise(\n    delay = mean(arr_delay),\n    n = n()\n  )\n\nggplot(data = delays, mapping = aes(x = n, y = delay)) + \n  geom_point(alpha = 1/10)\n#> Warning: Removed 874 rows containing missing values (geom_point).\ndelays %>% \n  filter(n > 25) %>% \n  ggplot(mapping = aes(x = n, y = delay)) + \n  geom_point(alpha = 1/10)\n#> Warning: Removed 828 rows containing missing values (geom_point).\n# Convert to a tibble so it prints nicely\nbatting <- as_tibble(Lahman::Batting)\n\nbatters <- batting %>% \n  group_by(playerID) %>% \n  summarise(\n    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),\n    ab = sum(AB, na.rm = TRUE)\n  )\n\nbatters %>% \n  filter(ab > 100) %>% \n  ggplot(mapping = aes(x = ab, y = ba)) +\n    geom_point() + \n    geom_smooth(se = FALSE)\n#> `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\nbatters %>% \n  arrange(desc(ba))\n#> <U+2029>[90m# A tibble: 19,898 x 3<U+2029>[39mNA#>   <U+2029>[1mplayerID<U+2029>[22m     <U+2029>[1mba<U+2029>[22m    <U+2029>[1mab<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m abramge01     1     1NA#> <U+2029>[90m2<U+2029>[39m alanirj01     1     1NA#> <U+2029>[90m3<U+2029>[39m alberan01     1     1NA#> <U+2029>[90m4<U+2029>[39m banisje01     1     1NA#> <U+2029>[90m5<U+2029>[39m bartocl01     1     1NA#> <U+2029>[90m6<U+2029>[39m bassdo01      1     1NA#> <U+2029>[90m# ... with 19,892 more rows<U+2029>[39mNA"},{"path":"data-tidy.html","id":"data-tidy","chapter":"6 Data tidying","heading":"6 Data tidying","text":"","code":""},{"path":"data-tidy.html","id":"introduction-3","chapter":"6 Data tidying","heading":"6.1 Introduction","text":"“Happy families alike; every unhappy family unhappy way.” —- Leo Tolstoy“Tidy datasets alike, every messy dataset messy way.” —- Hadley WickhamIn chapter, learn consistent way organise data R, organisation called tidy data.\nGetting data format requires upfront work, work pays long term.\ntidy data tidy tools provided packages tidyverse, spend much less time munging data one representation another, allowing spend time analytic questions hand.chapter give practical introduction tidy data accompanying tools tidyr package.\n’d like learn underlying theory, might enjoy Tidy Data paper published Journal Statistical Software, http://www.jstatsoft.org/v59/i10/paper.","code":""},{"path":"data-tidy.html","id":"prerequisites-3","chapter":"6 Data tidying","heading":"6.1.1 Prerequisites","text":"chapter ’ll focus tidyr, package provides bunch tools help tidy messy datasets.\ntidyr member core tidyverse.","code":"\nlibrary(tidyverse)"},{"path":"data-tidy.html","id":"tidy-data","chapter":"6 Data tidying","heading":"6.2 Tidy data","text":"can represent underlying data multiple ways.\nexample shows data organised four different ways.\ndataset shows values four variables country, year, population, cases, dataset organises values different way.representations underlying data, equally easy use.\nOne dataset, tidy dataset, much easier work inside tidyverse.three interrelated rules make dataset tidy:variable must column.observation must row.value must cell.Figure 6.1 shows rules visually.\nFigure 6.1: Following three rules makes dataset tidy: variables columns, observations rows, values cells.\nthree rules interrelated ’s impossible satisfy two three.\ninterrelationship leads even simpler set practical instructions:Put dataset tibble.Put variable column.example, table1 tidy.\n’s representation column variable.ensure data tidy?\ntwo main advantages:’s general advantage picking one consistent way storing data.\nconsistent data structure, ’s easier learn tools work underlying uniformity.’s general advantage picking one consistent way storing data.\nconsistent data structure, ’s easier learn tools work underlying uniformity.’s specific advantage placing variables columns allows R’s vectorised nature shine.\nlearned Sections ?? ??, built-R functions work vectors values.\nmakes transforming tidy data feel particularly natural.’s specific advantage placing variables columns allows R’s vectorised nature shine.\nlearned Sections ?? ??, built-R functions work vectors values.\nmakes transforming tidy data feel particularly natural.dplyr, ggplot2, packages tidyverse designed work tidy data.\ncouple small examples showing might work table1.","code":"\ntable1\n#> <U+2029>[90m# A tibble: 6 x 4<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m  <U+2029>[1mcases<U+2029>[22m <U+2029>[1mpopulation<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999    745   19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000   <U+2029>[4m2<U+2029>[24m666   20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999  <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737  172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000  <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488  174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258 <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766 <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583NAtable2\n#> <U+2029>[90m# A tibble: 12 x 4<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m <U+2029>[1mtype<U+2029>[22m           <U+2029>[1mcount<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999 cases            745NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999 population  19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071NA#> <U+2029>[90m3<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000 cases           <U+2029>[4m2<U+2029>[24m666NA#> <U+2029>[90m4<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000 population  20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360NA#> <U+2029>[90m5<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999 cases          <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737NA#> <U+2029>[90m6<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999 population 172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362NA#> <U+2029>[90m# ... with 6 more rows<U+2029>[39mNAtable3\n#> <U+2029>[90m# A tibble: 6 x 3<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m <U+2029>[1mrate<U+2029>[22m             NA#> <U+2029>[90m*<U+2029>[39m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m            NA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999 745/19987071     NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000 2666/20595360    NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999 37737/172006362  NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000 80488/174504898  NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 212258/1272915272NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 213766/1280428583NA# Spread across two tibbles\ntable4a # cases\n#> <U+2029>[90m# A tibble: 3 x 3<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1m`1999`<U+2029>[22m <U+2029>[1m`2000`<U+2029>[22mNA#> <U+2029>[90m*<U+2029>[39m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m        <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan    745   <U+2029>[4m2<U+2029>[24m666NA#> <U+2029>[90m2<U+2029>[39m Brazil       <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737  <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488NA#> <U+2029>[90m3<U+2029>[39m China       <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766NAtable4b # population\n#> <U+2029>[90m# A tibble: 3 x 3<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m         <U+2029>[1m`1999`<U+2029>[22m     <U+2029>[1m`2000`<U+2029>[22mNA#> <U+2029>[90m*<U+2029>[39m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m            <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan   19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071   20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360NA#> <U+2029>[90m2<U+2029>[39m Brazil       172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362  174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898NA#> <U+2029>[90m3<U+2029>[39m China       <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272 <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583NA\n# Compute rate per 10,000\ntable1 %>%\n  mutate(rate = cases / population * 10000)\n#> <U+2029>[90m# A tibble: 6 x 5<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m  <U+2029>[1mcases<U+2029>[22m <U+2029>[1mpopulation<U+2029>[22m  <U+2029>[1mrate<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999    745   19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071 0.373NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000   <U+2029>[4m2<U+2029>[24m666   20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360 1.29 NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999  <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737  172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362 2.19 NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000  <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488  174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898 4.61 NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258 <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272 1.67 NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766 <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583 1.67NA# Compute cases per year\ntable1 %>%\n  count(year, wt = cases)\n#> <U+2029>[90m# A tibble: 2 x 2<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m1<U+2029>[24m999 <U+2029>[4m2<U+2029>[24m<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m740NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m000 <U+2029>[4m2<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m6<U+2029>[24m920NA# Visualise changes over time\nggplot(table1, aes(year, cases)) +\n  geom_line(aes(group = country), colour = \"grey50\") +\n  geom_point(aes(colour = country, shape = country)) +\n  scale_x_continuous(breaks = c(1999, 2000))"},{"path":"data-tidy.html","id":"exercises-11","chapter":"6 Data tidying","heading":"6.2.1 Exercises","text":"Using prose, describe variables observations organised sample tables.Using prose, describe variables observations organised sample tables.Compute rate table2, table4a + table4b.\nneed perform four operations:\nExtract number TB cases per country per year.\nExtract matching population per country per year.\nDivide cases population, multiply 10000.\nStore back appropriate place.\nrepresentation easiest work ?\nhardest?\n?Compute rate table2, table4a + table4b.\nneed perform four operations:Extract number TB cases per country per year.Extract matching population per country per year.Divide cases population, multiply 10000.Store back appropriate place.representation easiest work ?\nhardest?\n?Recreate plot showing change cases time using table2 instead table1.\nneed first?Recreate plot showing change cases time using table2 instead table1.\nneed first?","code":""},{"path":"data-tidy.html","id":"pivoting","chapter":"6 Data tidying","heading":"6.3 Pivoting","text":"principles tidy data seem obvious might wonder ’ll ever encounter dataset isn’t tidy.\nUnfortunately, however, data encounter untidy.\ntwo main reasons:people aren’t familiar principles tidy data, ’s hard derive unless spend lot time working data.people aren’t familiar principles tidy data, ’s hard derive unless spend lot time working data.Data often organised facilitate use analysis.\nexample, data often organised make entry easy possible.Data often organised facilitate use analysis.\nexample, data often organised make entry easy possible.means real analyses, ’ll need tidying.\nfirst step always figure variables observations .\nSometimes easy; times ’ll need consult people originally generated data.\nsecond step resolve one two common problems:One variable might spread across multiple columns.One variable might spread across multiple columns.One observation might scattered across multiple rows.One observation might scattered across multiple rows.Typically dataset suffer one problems; ’ll suffer ’re really unlucky!\nfix problems, ’ll need two important functions tidyr: pivot_longer() pivot_wider().","code":""},{"path":"data-tidy.html","id":"longer","chapter":"6 Data tidying","heading":"6.3.1 Longer","text":"common problem dataset column names names variables, values variable.\nSuppose data following format.want create following visualisation line represents country, year x-axis, cases y-axis, automatically get legend indicates line represents country.\nFigure 6.2: Number cases years country.\n’s straight-forward starting data frame country, year, cases columns row represents record country particular year.However table4a column names 1999 2000 represent values year variable, values 1999 2000 columns represent values cases variable, row represents two observations, one.tidy dataset like , need pivot offending columns new pair variables.\ndescribe operation need three parameters:set columns whose names values, variables.\nexample, columns 1999 2000.set columns whose names values, variables.\nexample, columns 1999 2000.name variable move column names : year.name variable move column names : year.name variable move column values : cases.name variable move column values : cases.Together parameters generate call pivot_longer():columns pivot specified dplyr::select() style notation cols argument.\ntwo columns, list individually.\nNote 1999 2000 non-syntactic names (don’t start letter) surround backticks.\nrefresh memory ways select columns, see Section 5.3.2.year cases exist table4a put names quotes names_to values_to arguments, respectively.final result, pivoted columns dropped, get new year cases columns.\nOtherwise, relationships original variables preserved.\nVisually, shown Figure 6.3.\nFigure 6.3: Pivoting table4a “longer”, tidy form.\nstill one issue though.\nTake peek type year variable.\nexpect year numeric (specifically, expect integer), however ’s showing character.\nvalues year variable came column headings table4a.\ncan add new step pipeline using dplyr::mutate() parse variable integer readr::parse_integer().\ncan refer back Section 8.3 functions parsing types vectors.data longer format, can create visualisation motivated tidying exercise follows.pivot_longer() makes datasets longer increasing number rows decreasing number columns.\ndon’t believe makes sense describe dataset “long form”.\nLength relative term, can say (e.g.) dataset longer dataset B.can use pivot_longer() tidy table4b similar fashion.\ndifference variable stored cell values:combine tidied versions table4a table4b single tibble, need use dplyr::left_join(), ’ll learn Chapter 14.","code":"\ntable4a\n#> <U+2029>[90m# A tibble: 3 x 3<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1m`1999`<U+2029>[22m <U+2029>[1m`2000`<U+2029>[22mNA#> <U+2029>[90m*<U+2029>[39m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m        <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan    745   <U+2029>[4m2<U+2029>[24m666NA#> <U+2029>[90m2<U+2029>[39m Brazil       <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737  <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488NA#> <U+2029>[90m3<U+2029>[39m China       <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766NA#>  [90m# A tibble: 6 x 3 [39m\n#>    [1mcountry [22m       [1myear [22m   [1mcases [22m\n#>    [3m [90m<chr> [39m [23m        [3m [90m<int> [39m [23m   [3m [90m<int> [39m [23m\n#>  [90m1 [39m Afghanistan   [4m1 [24m999    745\n#>  [90m2 [39m Afghanistan   [4m2 [24m000    [4m2 [24m666\n#>  [90m3 [39m Brazil        [4m1 [24m999   [4m3 [24m [4m7 [24m737\n#>  [90m4 [39m Brazil        [4m2 [24m000   [4m8 [24m [4m0 [24m488\n#>  [90m5 [39m China         [4m1 [24m999  [4m2 [24m [4m1 [24m [4m2 [24m258\n#>  [90m6 [39m China         [4m2 [24m000  [4m2 [24m [4m1 [24m [4m3 [24m766\ntable4a %>%\n  pivot_longer(\n    cols = c(`1999`, `2000`),\n    names_to = \"year\",\n    values_to = \"cases\"\n  )\n#> <U+2029>[90m# A tibble: 6 x 3<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1myear<U+2029>[22m   <U+2029>[1mcases<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan 1999     745NA#> <U+2029>[90m2<U+2029>[39m Afghanistan 2000    <U+2029>[4m2<U+2029>[24m666NA#> <U+2029>[90m3<U+2029>[39m Brazil      1999   <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737NA#> <U+2029>[90m4<U+2029>[39m Brazil      2000   <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488NA#> <U+2029>[90m5<U+2029>[39m China       1999  <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258NA#> <U+2029>[90m6<U+2029>[39m China       2000  <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766NA\ntable4a %>%\n  pivot_longer(\n    cols = c(`1999`, `2000`),\n    names_to = \"year\",\n    values_to = \"cases\"\n  ) %>%\n  mutate(year = parse_integer(year))\n#> <U+2029>[90m# A tibble: 6 x 3<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m  <U+2029>[1mcases<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999    745NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000   <U+2029>[4m2<U+2029>[24m666NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999  <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000  <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766NA\ntable4a %>%\n  pivot_longer(\n    cols = c(`1999`, `2000`),\n    names_to = \"year\",\n    values_to = \"cases\",\n  ) %>%\n  mutate(year = parse_integer(year)) %>%\n  ggplot(aes(x = year, y = cases)) +\n  geom_line(aes(group = country), colour = \"grey50\") +\n  geom_point(aes(colour = country, shape = country)) +\n  scale_x_continuous(breaks = c(1999, 2000))\ntable4b %>%\n  pivot_longer(\n    cols = c(`1999`, `2000`),\n    names_to = \"year\",\n    values_to = \"population\"\n  ) %>%\n  mutate(year = parse_integer(year))\n#> <U+2029>[90m# A tibble: 6 x 3<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m <U+2029>[1mpopulation<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999   19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000   20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999  172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000  174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583NA\ntidy4a <- table4b %>%\n  pivot_longer(\n    cols = c(`1999`, `2000`),\n    names_to = \"year\",\n    values_to = \"cases\"\n  ) %>%\n  mutate(year = parse_integer(year))\ntidy4b <- table4b %>%\n  pivot_longer(\n    cols = c(`1999`, `2000`),\n    names_to = \"year\",\n    values_to = \"population\"\n  ) %>%\n  mutate(year = parse_integer(year))\nleft_join(tidy4a, tidy4b)\n#> Joining, by = c(\"country\", \"year\")\n#> <U+2029>[90m# A tibble: 6 x 4<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m      <U+2029>[1mcases<U+2029>[22m <U+2029>[1mpopulation<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999   19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071   19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000   20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360   20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999  172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362  172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000  174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898  174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272 <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583 <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583NA"},{"path":"data-tidy.html","id":"wider","chapter":"6 Data tidying","heading":"6.3.2 Wider","text":"pivot_wider() opposite pivot_longer().\nuse observation scattered across multiple rows.\nexample, take table2: observation country year, observation spread across two rows.Suppose ’d like calculate rate (number cases divided population) country given year, record new column, resulting following data frame.means need data frame cases population separate columns, columns, cell hold values relevant counts.\nLet’s analyse representation similar way pivot_longer().\ntime, however, need two parameters:column take variable names : type.column take variable names : type.column take values : count.column take values : count.can use pivot_wider(), shown programmatically , visually Figure 6.4.\nFigure 6.4: Pivoting table2 “wider”, tidy form.\ndata wider format, can create data frame motivated tidying exercise follows.Earlier visualised case counts years, representation can useful visualising case rates, example.Now let’s go one step widen data record cases, population, rate 1999 2000 separate columns, following.representation rarely useful data analysis might useful basis table communication results data analysis report.achieve need add year information column headings cases, population, rate well distribute values currently three columns six columns (two columns year data ).\nrepresented Figure 6.5.\nFigure 6.5: Pivoting table2 even “wider” form. Arrows cases rate values omitted clarity.\n, ’ll take advantage fact pivot functions can operate multiple columns .\nfirst three lines following code chunk ’ve already done previous step add pipeline another pivot_wider() step values added columns come cases, population, rate column names automatically suffixed values year variable.last step achieving goal relocate columns resulting data frame columns 1999 data come 2000.\ncan use relocate() function move 1999 columns ahead 2000 columns.might guessed names, pivot_wider() pivot_longer() complements.\npivot_longer() makes wide tables narrower longer; pivot_wider() makes long tables shorter wider.","code":"\ntable2\n#> <U+2029>[90m# A tibble: 12 x 4<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m <U+2029>[1mtype<U+2029>[22m           <U+2029>[1mcount<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999 cases            745NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999 population  19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071NA#> <U+2029>[90m3<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000 cases           <U+2029>[4m2<U+2029>[24m666NA#> <U+2029>[90m4<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000 population  20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360NA#> <U+2029>[90m5<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999 cases          <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737NA#> <U+2029>[90m6<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999 population 172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362NA#> <U+2029>[90m# ... with 6 more rows<U+2029>[39mNA#>  [90m# A tibble: 6 x 5 [39m\n#>    [1mcountry [22m       [1myear [22m   [1mcases [22m  [1mpopulation [22m       [1mrate [22m\n#>    [3m [90m<chr> [39m [23m        [3m [90m<int> [39m [23m   [3m [90m<int> [39m [23m       [3m [90m<int> [39m [23m      [3m [90m<dbl> [39m [23m\n#>  [90m1 [39m Afghanistan   [4m1 [24m999    745   19 [4m9 [24m [4m8 [24m [4m7 [24m071 0.000 [4m0 [24m [4m3 [24m [4m7 [24m3\n#>  [90m2 [39m Afghanistan   [4m2 [24m000    [4m2 [24m666   20 [4m5 [24m [4m9 [24m [4m5 [24m360 0.000 [4m1 [24m [4m2 [24m [4m9 [24m \n#>  [90m3 [39m Brazil        [4m1 [24m999   [4m3 [24m [4m7 [24m737  172 [4m0 [24m [4m0 [24m [4m6 [24m362 0.000 [4m2 [24m [4m1 [24m [4m9 [24m \n#>  [90m4 [39m Brazil        [4m2 [24m000   [4m8 [24m [4m0 [24m488  174 [4m5 [24m [4m0 [24m [4m4 [24m898 0.000 [4m4 [24m [4m6 [24m [4m1 [24m \n#>  [90m5 [39m China         [4m1 [24m999  [4m2 [24m [4m1 [24m [4m2 [24m258  [4m1 [24m272 [4m9 [24m [4m1 [24m [4m5 [24m272 0.000 [4m1 [24m [4m6 [24m [4m7 [24m \n#>  [90m6 [39m China         [4m2 [24m000  [4m2 [24m [4m1 [24m [4m3 [24m766  [4m1 [24m280 [4m4 [24m [4m2 [24m [4m8 [24m583 0.000 [4m1 [24m [4m6 [24m [4m7 [24m\ntable2 %>%\n  pivot_wider(names_from = type, values_from = count)\n#> <U+2029>[90m# A tibble: 6 x 4<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m  <U+2029>[1mcases<U+2029>[22m <U+2029>[1mpopulation<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999    745   19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000   <U+2029>[4m2<U+2029>[24m666   20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999  <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737  172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000  <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488  174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258 <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766 <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583NA\ntable2 %>%\n  pivot_wider(names_from = type, values_from = count) %>%\n  mutate(rate = cases / population)\n#> <U+2029>[90m# A tibble: 6 x 5<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m  <U+2029>[1mcases<U+2029>[22m <U+2029>[1mpopulation<U+2029>[22m      <U+2029>[1mrate<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999    745   19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071 0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m3NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000   <U+2029>[4m2<U+2029>[24m666   20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360 0.000<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m9<U+2029>[24m NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999  <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737  172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362 0.000<U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m9<U+2029>[24m NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000  <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488  174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898 0.000<U+2029>[4m4<U+2029>[24m<U+2029>[4m6<U+2029>[24m<U+2029>[4m1<U+2029>[24m NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258 <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272 0.000<U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m<U+2029>[4m7<U+2029>[24m NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766 <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583 0.000<U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m<U+2029>[4m7<U+2029>[24mNA\ntable2 %>%\n  pivot_wider(names_from = type, values_from = count) %>%\n  mutate(rate = cases / population) %>%\n  ggplot(aes(x = year, y = rate)) +\n  geom_line(aes(group = country), colour = \"grey50\") +\n  geom_point(aes(colour = country, shape = country)) +\n  scale_x_continuous(breaks = c(1999, 2000))#>  [90m# A tibble: 3 x 7 [39m\n#>    [1mcountry [22m      [1mcases_1999 [22m  [1mpopulation_1999 [22m  [1mrate_1999 [22m  [1mcases_2000 [22m  [1mpopulation_2000 [22m\n#>    [3m [90m<chr> [39m [23m             [3m [90m<int> [39m [23m            [3m [90m<int> [39m [23m      [3m [90m<dbl> [39m [23m       [3m [90m<int> [39m [23m            [3m [90m<int> [39m [23m\n#>  [90m1 [39m Afghanistan        745        19 [4m9 [24m [4m8 [24m [4m7 [24m071 0.000 [4m0 [24m [4m3 [24m [4m7 [24m3        [4m2 [24m666        20 [4m5 [24m [4m9 [24m [4m5 [24m360\n#>  [90m2 [39m Brazil            [4m3 [24m [4m7 [24m737       172 [4m0 [24m [4m0 [24m [4m6 [24m362 0.000 [4m2 [24m [4m1 [24m [4m9 [24m        [4m8 [24m [4m0 [24m488       174 [4m5 [24m [4m0 [24m [4m4 [24m898\n#>  [90m3 [39m China            [4m2 [24m [4m1 [24m [4m2 [24m258       [4m1 [24m272 [4m9 [24m [4m1 [24m [4m5 [24m272 0.000 [4m1 [24m [4m6 [24m [4m7 [24m       [4m2 [24m [4m1 [24m [4m3 [24m766       [4m1 [24m280 [4m4 [24m [4m2 [24m [4m8 [24m583\n#>  [90m# ... with 1 more variable:  [1mrate_2000 [22m <dbl> [39m\ntable2 %>%\n  pivot_wider(names_from = type, values_from = count) %>%\n  mutate(rate = cases / population) %>%\n  pivot_wider(\n    names_from = year,\n    values_from = c(cases, population, rate)\n  )\n#> <U+2029>[90m# A tibble: 3 x 7<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1mcases_1999<U+2029>[22m <U+2029>[1mcases_2000<U+2029>[22m <U+2029>[1mpopulation_1999<U+2029>[22m <U+2029>[1mpopulation_2000<U+2029>[22m <U+2029>[1mrate_1999<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m            <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m           <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m           <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan        745       <U+2029>[4m2<U+2029>[24m666        19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071        20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360 0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m3NA#> <U+2029>[90m2<U+2029>[39m Brazil           <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737      <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488       172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362       174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898 0.000<U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m9<U+2029>[24m NA#> <U+2029>[90m3<U+2029>[39m China           <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258     <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766      <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272      <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583 0.000<U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m<U+2029>[4m7<U+2029>[24m NA#> <U+2029>[90m# ... with 1 more variable: <U+2029>[1mrate_2000<U+2029>[22m <dbl><U+2029>[39mNA\ntable2 %>%\n  pivot_wider(names_from = type, values_from = count) %>%\n  mutate(rate = cases / population) %>%\n  pivot_wider(\n    names_from = year,\n    values_from = c(cases, population, rate)\n  ) %>%\n  relocate(country, contains(\"1999\"))\n#> <U+2029>[90m# A tibble: 3 x 7<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1mcases_1999<U+2029>[22m <U+2029>[1mpopulation_1999<U+2029>[22m <U+2029>[1mrate_1999<U+2029>[22m <U+2029>[1mcases_2000<U+2029>[22m <U+2029>[1mpopulation_2000<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m            <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m           <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m           <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan        745        19<U+2029>[4m9<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m7<U+2029>[24m071 0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m3       <U+2029>[4m2<U+2029>[24m666        20<U+2029>[4m5<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m5<U+2029>[24m360NA#> <U+2029>[90m2<U+2029>[39m Brazil           <U+2029>[4m3<U+2029>[24m<U+2029>[4m7<U+2029>[24m737       172<U+2029>[4m0<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m362 0.000<U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m9<U+2029>[24m       <U+2029>[4m8<U+2029>[24m<U+2029>[4m0<U+2029>[24m488       174<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m898NA#> <U+2029>[90m3<U+2029>[39m China           <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m258      <U+2029>[4m1<U+2029>[24m272<U+2029>[4m9<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m272 0.000<U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m<U+2029>[4m7<U+2029>[24m      <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m766      <U+2029>[4m1<U+2029>[24m280<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m583NA#> <U+2029>[90m# ... with 1 more variable: <U+2029>[1mrate_2000<U+2029>[22m <dbl><U+2029>[39mNA"},{"path":"data-tidy.html","id":"exercises-12","chapter":"6 Data tidying","heading":"6.3.3 Exercises","text":"pivot_longer() pivot_wider() perfectly symmetrical?\nCarefully consider following example:\n\nstocks <- tibble(\n  year   = c(2015, 2015, 2016, 2016),\n  half   = c(   1,    2,    1,    2),\n  return = c(1.88, 0.59, 0.92, 0.17)\n)\nstocks %>%\n  pivot_wider(names_from = year, values_from = return) %>%\n  pivot_longer(`2015`:`2016`, names_to = \"year\", values_to = \"return\")\n(Hint: look variable types think column names.)\npivot_longer() names_ptypes argument, e.g. names_ptypes = list(year = double()).\n?pivot_longer() pivot_wider() perfectly symmetrical?\nCarefully consider following example:(Hint: look variable types think column names.)pivot_longer() names_ptypes argument, e.g. names_ptypes = list(year = double()).\n?code fail?\n\ntable4a %>%\n  pivot_longer(c(1999, 2000), names_to = \"year\", values_to = \"cases\")\n#> Error: subset columns exist.\n#> <U+2029>[31mx<U+2029>[39m Locations 1999 2000 exist.NA#> <U+2029>[34mi<U+2029>[39m 3 columns.NAWhy code fail?happen widen table?\n?\nadd new column uniquely identify value?\n\npeople <- tribble(\n  ~name,             ~names,  ~values,\n  #-----------------|--------|-------\n  \"Phillip Woods\",   \"age\",        45,\n  \"Phillip Woods\",   \"height\",    186,\n  \"Phillip Woods\",   \"age\",        50,\n  \"Jessica Cordero\", \"age\",        37,\n  \"Jessica Cordero\", \"height\",    156\n)happen widen table?\n?\nadd new column uniquely identify value?simple tibble summarizes information whether employees small company know drive whether prefer position need drive daily sales calls.\nTidy table get format observation employee.\nneed make wider longer?\nvariables?\n\nemployees <- tribble(\n  ~know_drive, ~prefer, ~not_prefer,\n  \"yes\",       20,      10,\n  \"\",        NA,      12\n)simple tibble summarizes information whether employees small company know drive whether prefer position need drive daily sales calls.\nTidy table get format observation employee.\nneed make wider longer?\nvariables?One way summarising distribution one categorical variable based levels another using dplyr::count(), e.g. following gives distribution drv (type drive train) level cyl (number cylinders) cars mpg dataset.\n\nmpg %>%\n  count(cyl, drv)\n#> <U+2029>[90m# tibble: 9 x 3<U+2029>[39mNA#>     <U+2029>[1mcyl<U+2029>[22m <U+2029>[1mdrv<U+2029>[22m       <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     4 4        23NA#> <U+2029>[90m2<U+2029>[39m     4 f        58NA#> <U+2029>[90m3<U+2029>[39m     5 f         4NA#> <U+2029>[90m4<U+2029>[39m     6 4        32NA#> <U+2029>[90m5<U+2029>[39m     6 f        43NA#> <U+2029>[90m6<U+2029>[39m     6 r         4NA#> <U+2029>[90m# ... 3 rows<U+2029>[39mNA\ncontingency table another way commonly used way summarising information.\nUse one pivoting functions construct contingency table shown based output .\n#>  [90m# tibble: 4 x 4 [39m\n#>      [1mcyl [22m    [1m`4` [22m      [1mf [22m      [1mr [22m\n#>    [3m [90m<int> [39m [23m  [3m [90m<int> [39m [23m  [3m [90m<int> [39m [23m  [3m [90m<int> [39m [23m\n#>  [90m1 [39m     4    23    58     [31mNA [39m\n#>  [90m2 [39m     5     [31mNA [39m     4     [31mNA [39m\n#>  [90m3 [39m     6    32    43     4\n#>  [90m4 [39m     8    48     1    21One way summarising distribution one categorical variable based levels another using dplyr::count(), e.g. following gives distribution drv (type drive train) level cyl (number cylinders) cars mpg dataset.contingency table another way commonly used way summarising information.\nUse one pivoting functions construct contingency table shown based output .","code":"\nstocks <- tibble(\n  year   = c(2015, 2015, 2016, 2016),\n  half   = c(   1,    2,    1,    2),\n  return = c(1.88, 0.59, 0.92, 0.17)\n)\nstocks %>%\n  pivot_wider(names_from = year, values_from = return) %>%\n  pivot_longer(`2015`:`2016`, names_to = \"year\", values_to = \"return\")\ntable4a %>%\n  pivot_longer(c(1999, 2000), names_to = \"year\", values_to = \"cases\")\n#> Error: Can't subset columns that don't exist.\n#> <U+2029>[31mx<U+2029>[39m Locations 1999 and 2000 don't exist.NA#> <U+2029>[34mi<U+2029>[39m There are only 3 columns.NA\npeople <- tribble(\n  ~name,             ~names,  ~values,\n  #-----------------|--------|-------\n  \"Phillip Woods\",   \"age\",        45,\n  \"Phillip Woods\",   \"height\",    186,\n  \"Phillip Woods\",   \"age\",        50,\n  \"Jessica Cordero\", \"age\",        37,\n  \"Jessica Cordero\", \"height\",    156\n)\nemployees <- tribble(\n  ~know_drive, ~prefer, ~not_prefer,\n  \"yes\",       20,      10,\n  \"no\",        NA,      12\n)\nmpg %>%\n  count(cyl, drv)\n#> <U+2029>[90m# A tibble: 9 x 3<U+2029>[39mNA#>     <U+2029>[1mcyl<U+2029>[22m <U+2029>[1mdrv<U+2029>[22m       <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     4 4        23NA#> <U+2029>[90m2<U+2029>[39m     4 f        58NA#> <U+2029>[90m3<U+2029>[39m     5 f         4NA#> <U+2029>[90m4<U+2029>[39m     6 4        32NA#> <U+2029>[90m5<U+2029>[39m     6 f        43NA#> <U+2029>[90m6<U+2029>[39m     6 r         4NA#> <U+2029>[90m# ... with 3 more rows<U+2029>[39mNA#>  [90m# A tibble: 4 x 4 [39m\n#>      [1mcyl [22m    [1m`4` [22m      [1mf [22m      [1mr [22m\n#>    [3m [90m<int> [39m [23m  [3m [90m<int> [39m [23m  [3m [90m<int> [39m [23m  [3m [90m<int> [39m [23m\n#>  [90m1 [39m     4    23    58     [31mNA [39m\n#>  [90m2 [39m     5     [31mNA [39m     4     [31mNA [39m\n#>  [90m3 [39m     6    32    43     4\n#>  [90m4 [39m     8    48     1    21"},{"path":"data-tidy.html","id":"case-study","chapter":"6 Data tidying","heading":"6.4 Case study","text":"finish chapter, let’s pull together everything ’ve learned tackle realistic data tidying problem.\ntidyr::dataset contains tuberculosis (TB) cases broken year, country, age, gender, diagnosis method.\ndata comes 2014 World Health Organization Global Tuberculosis Report, available http://www..int/tb/country/data/download/en.’s wealth epidemiological information dataset, ’s challenging work data form ’s provided:typical real-life example dataset.\ncontains redundant columns, odd variable names, many missing values.\nshort, dataset messy, ’ll need methodical tidy .\nfunctions like pivot_wider() pivot_longer() generally means iterative approach work well – aim accomplish one goal time, run function examine resulting data frame, go back set arguments function needed resulting data frame exactly need.best place start take good look variable names determine whether actually variables contain information captured values new column.looks like country, iso2, iso3 three variables redundantly specify country.looks like country, iso2, iso3 three variables redundantly specify country.year also variable.year also variable.first three letters variables new_sp_m014 newrel_f65 denote whether column contains new old cases TB.\ndataset, column contains new cases, don’t really need information captured variable.\nremaining characters encode three variables names.\nmight able parse little thought experimentation, luckily data dictionary handy.\ntells us:\nnext two three letters describe diagnosis TB:\nrel stands cases relapse\nep stands cases extrapulmonary TB\nsn stands cases pulmonary TB diagnosed pulmonary smear (smear negative)\nsp stands cases pulmonary TB diagnosed pulmonary smear (smear positive)\n\nnext letter gives sex TB patients.\ndataset groups cases males (m) females (f).\nremaining numbers give age group.\ndataset groups cases seven age groups:\n014 = 0 – 14 years old\n1524 = 15 – 24 years old\n2534 = 25 – 34 years old\n3544 = 35 – 44 years old\n4554 = 45 – 54 years old\n5564 = 55 – 64 years old\n65 = 65 older\n\nfirst three letters variables new_sp_m014 newrel_f65 denote whether column contains new old cases TB.\ndataset, column contains new cases, don’t really need information captured variable.\nremaining characters encode three variables names.\nmight able parse little thought experimentation, luckily data dictionary handy.\ntells us:next two three letters describe diagnosis TB:\nrel stands cases relapse\nep stands cases extrapulmonary TB\nsn stands cases pulmonary TB diagnosed pulmonary smear (smear negative)\nsp stands cases pulmonary TB diagnosed pulmonary smear (smear positive)\nnext two three letters describe diagnosis TB:rel stands cases relapseep stands cases extrapulmonary TBsn stands cases pulmonary TB diagnosed pulmonary smear (smear negative)sp stands cases pulmonary TB diagnosed pulmonary smear (smear positive)next letter gives sex TB patients.\ndataset groups cases males (m) females (f).next letter gives sex TB patients.\ndataset groups cases males (m) females (f).remaining numbers give age group.\ndataset groups cases seven age groups:\n014 = 0 – 14 years old\n1524 = 15 – 24 years old\n2534 = 25 – 34 years old\n3544 = 35 – 44 years old\n4554 = 45 – 54 years old\n5564 = 55 – 64 years old\n65 = 65 older\nremaining numbers give age group.\ndataset groups cases seven age groups:014 = 0 – 14 years old1524 = 15 – 24 years old2534 = 25 – 34 years old3544 = 35 – 44 years old4554 = 45 – 54 years old5564 = 55 – 64 years old65 = 65 olderWe can break variables specifying multiple column names names_to either providing names_pattern specify want break regular expression containing groups (defined ()) puts group column.\n’ll learn regular expressions Chapter 18, basic idea variable name like new_sp_m014, want capture sp, m, 014 separate groups, can think variable’s name new_(sp)_(m)(014).\nconstructing appropriate regular expression need keep mind messy features variable names:variables start new_ start new without underscore separating diagnosis.diagnoses age groups indicated varying numbers characters (e.g. sp vs. rel 014 vs. 4554.)regular expression capture inconsistencies extract three groups information need new_?(.*)_(.)(.*).looks pretty good first pass, improvements can make.\nFirst, ’re seeing lots NAs cases column.\ncan drop observations setting values_drop_na TRUE.Second, diagnosis gender characters default, however ’s good idea convert factors since categorical variables known set values.\n’ll use parse_factor() function readr make conversion mutate() step add pipeline.Finally, might want recode age variable level names bit easier read bit informative.\n’ll within mutate() step pipeline using forcats::fct_recode() ’ll learn Chapter 20.tidy data frame allows us explore data ease original dataset.\nexample, can easily filter particular type TB given country sum number cases see case numbers type TB evolved years.","code":"\nwho\n#> <U+2029>[90m# A tibble: 7,240 x 60<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1miso2<U+2029>[22m  <U+2029>[1miso3<U+2029>[22m   <U+2029>[1myear<U+2029>[22m <U+2029>[1mnew_sp_m014<U+2029>[22m <U+2029>[1mnew_sp_m1524<U+2029>[22m <U+2029>[1mnew_sp_m2534<U+2029>[22m <U+2029>[1mnew_sp_m3544<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m        <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m        <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m        <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m980          <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m981          <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m982          <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m983          <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m984          <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m985          <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39m           <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m# ... with 7,234 more rows, and 52 more variables: <U+2029>[1mnew_sp_m4554<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mnew_sp_m5564<U+2029>[22m <int>, <U+2029>[1mnew_sp_m65<U+2029>[22m <int>, <U+2029>[1mnew_sp_f014<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mnew_sp_f1524<U+2029>[22m <int>, <U+2029>[1mnew_sp_f2534<U+2029>[22m <int>, <U+2029>[1mnew_sp_f3544<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mnew_sp_f4554<U+2029>[22m <int>, <U+2029>[1mnew_sp_f5564<U+2029>[22m <int>, <U+2029>[1mnew_sp_f65<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mnew_sn_m014<U+2029>[22m <int>, <U+2029>[1mnew_sn_m1524<U+2029>[22m <int>, <U+2029>[1mnew_sn_m2534<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mnew_sn_m3544<U+2029>[22m <int>, <U+2029>[1mnew_sn_m4554<U+2029>[22m <int>, <U+2029>[1mnew_sn_m5564<U+2029>[22m <int>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mnew_sn_m65<U+2029>[22m <int>, <U+2029>[1mnew_sn_f014<U+2029>[22m <int>, <U+2029>[1mnew_sn_f1524<U+2029>[22m <int>, ...<U+2029>[39mNA\nnames(who)\n#>  [1] \"country\"      \"iso2\"         \"iso3\"         \"year\"         \"new_sp_m014\" \n#>  [6] \"new_sp_m1524\" \"new_sp_m2534\" \"new_sp_m3544\" \"new_sp_m4554\" \"new_sp_m5564\"\n#> [11] \"new_sp_m65\"   \"new_sp_f014\"  \"new_sp_f1524\" \"new_sp_f2534\" \"new_sp_f3544\"\n#> [16] \"new_sp_f4554\" \"new_sp_f5564\" \"new_sp_f65\"   \"new_sn_m014\"  \"new_sn_m1524\"\n#> [21] \"new_sn_m2534\" \"new_sn_m3544\" \"new_sn_m4554\" \"new_sn_m5564\" \"new_sn_m65\"  \n#> [26] \"new_sn_f014\"  \"new_sn_f1524\" \"new_sn_f2534\" \"new_sn_f3544\" \"new_sn_f4554\"\n#> [31] \"new_sn_f5564\" \"new_sn_f65\"   \"new_ep_m014\"  \"new_ep_m1524\" \"new_ep_m2534\"\n#> [36] \"new_ep_m3544\" \"new_ep_m4554\" \"new_ep_m5564\" \"new_ep_m65\"   \"new_ep_f014\" \n#> [41] \"new_ep_f1524\" \"new_ep_f2534\" \"new_ep_f3544\" \"new_ep_f4554\" \"new_ep_f5564\"\n#> [46] \"new_ep_f65\"   \"newrel_m014\"  \"newrel_m1524\" \"newrel_m2534\" \"newrel_m3544\"\n#> [51] \"newrel_m4554\" \"newrel_m5564\" \"newrel_m65\"   \"newrel_f014\"  \"newrel_f1524\"\n#> [56] \"newrel_f2534\" \"newrel_f3544\" \"newrel_f4554\" \"newrel_f5564\" \"newrel_f65\"\nwho %>%\n  pivot_longer(\n    cols = new_sp_m014:newrel_f65,\n    names_to = c(\"diagnosis\", \"gender\", \"age\"),\n    names_pattern = \"new_?(.*)_(.)(.*)\",\n    values_to = \"cases\"\n  )\n#> <U+2029>[90m# A tibble: 405,440 x 8<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1miso2<U+2029>[22m  <U+2029>[1miso3<U+2029>[22m   <U+2029>[1myear<U+2029>[22m <U+2029>[1mdiagnosis<U+2029>[22m <U+2029>[1mgender<U+2029>[22m <U+2029>[1mage<U+2029>[22m   <U+2029>[1mcases<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m980 sp        m      014      <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m980 sp        m      1524     <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m980 sp        m      2534     <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m980 sp        m      3544     <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m980 sp        m      4554     <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m980 sp        m      5564     <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m# ... with 405,434 more rows<U+2029>[39mNA\nwho %>%\n  pivot_longer(\n    cols = new_sp_m014:newrel_f65,\n    names_to = c(\"diagnosis\", \"gender\", \"age\"),\n    names_pattern = \"new_?(.*)_(.)(.*)\",\n    values_to = \"cases\",\n    values_drop_na = TRUE\n  )\n#> <U+2029>[90m# A tibble: 76,046 x 8<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1miso2<U+2029>[22m  <U+2029>[1miso3<U+2029>[22m   <U+2029>[1myear<U+2029>[22m <U+2029>[1mdiagnosis<U+2029>[22m <U+2029>[1mgender<U+2029>[22m <U+2029>[1mage<U+2029>[22m   <U+2029>[1mcases<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      014       0NA#> <U+2029>[90m2<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      1524     10NA#> <U+2029>[90m3<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      2534      6NA#> <U+2029>[90m4<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      3544      3NA#> <U+2029>[90m5<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      4554      5NA#> <U+2029>[90m6<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      5564      2NA#> <U+2029>[90m# ... with 76,040 more rows<U+2029>[39mNA\nwho %>%\n  pivot_longer(\n    cols = new_sp_m014:newrel_f65,\n    names_to = c(\"diagnosis\", \"gender\", \"age\"),\n    names_pattern = \"new_?(.*)_(.)(.*)\",\n    values_to = \"cases\",\n    values_drop_na = TRUE\n  ) %>%\n  mutate(\n    gender = parse_factor(gender, levels = c(\"f\", \"m\")),\n    age = parse_factor(\n      age,\n      levels = c(\"014\", \"1524\", \"2534\", \"3544\", \"4554\", \"5564\", \"65\"),\n      ordered = TRUE\n    )\n  )\n#> <U+2029>[90m# A tibble: 76,046 x 8<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1miso2<U+2029>[22m  <U+2029>[1miso3<U+2029>[22m   <U+2029>[1myear<U+2029>[22m <U+2029>[1mdiagnosis<U+2029>[22m <U+2029>[1mgender<U+2029>[22m <U+2029>[1mage<U+2029>[22m   <U+2029>[1mcases<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<ord><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      014       0NA#> <U+2029>[90m2<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      1524     10NA#> <U+2029>[90m3<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      2534      6NA#> <U+2029>[90m4<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      3544      3NA#> <U+2029>[90m5<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      4554      5NA#> <U+2029>[90m6<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      5564      2NA#> <U+2029>[90m# ... with 76,040 more rows<U+2029>[39mNA\nwho_tidy <- who %>%\n  pivot_longer(\n    cols = new_sp_m014:newrel_f65,\n    names_to = c(\"diagnosis\", \"gender\", \"age\"),\n    names_pattern = \"new_?(.*)_(.)(.*)\",\n    values_to = \"cases\",\n    values_drop_na = TRUE\n  ) %>%\n  mutate(\n    gender = parse_factor(gender, levels = c(\"f\", \"m\")),\n    age = parse_factor(\n      age,\n      levels = c(\"014\", \"1524\", \"2534\", \"3544\", \"4554\", \"5564\", \"65\"),\n      ordered = TRUE\n    ),\n    age = fct_recode(\n      age,\n      \"0-14\"  = \"014\",\n      \"15-24\" = \"1524\",\n      \"25-34\" = \"2534\",\n      \"35-44\" = \"3544\",\n      \"45-54\" = \"4554\",\n      \"55-64\" = \"5564\",\n      \"65+\"   = \"65\"\n    )\n  )\nwho_tidy\n#> <U+2029>[90m# A tibble: 76,046 x 8<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m     <U+2029>[1miso2<U+2029>[22m  <U+2029>[1miso3<U+2029>[22m   <U+2029>[1myear<U+2029>[22m <U+2029>[1mdiagnosis<U+2029>[22m <U+2029>[1mgender<U+2029>[22m <U+2029>[1mage<U+2029>[22m   <U+2029>[1mcases<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<ord><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      0-14      0NA#> <U+2029>[90m2<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      15-24    10NA#> <U+2029>[90m3<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      25-34     6NA#> <U+2029>[90m4<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      35-44     3NA#> <U+2029>[90m5<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      45-54     5NA#> <U+2029>[90m6<U+2029>[39m Afghanistan AF    AFG    <U+2029>[4m1<U+2029>[24m997 sp        m      55-64     2NA#> <U+2029>[90m# ... with 76,040 more rows<U+2029>[39mNA\nwho_tidy %>%\n  filter(diagnosis == \"sp\", country == \"United States of America\") %>%\n  group_by(year) %>%\n  summarise(cases_total = sum(cases)) %>%\n  ggplot(aes(x = year, y = cases_total)) +\n  geom_point() +\n  geom_smooth() +\n  labs(title = \"Number of smear positive pulmonary TB cases in the US\")\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"data-tidy.html","id":"exercises-13","chapter":"6 Data tidying","heading":"6.4.1 Exercises","text":"case study set values_drop_na = TRUE just make easier check correct values.\nreasonable?\nThink missing values represented dataset.\nimplicit missing values?\n’s difference NA zero?case study set values_drop_na = TRUE just make easier check correct values.\nreasonable?\nThink missing values represented dataset.\nimplicit missing values?\n’s difference NA zero?claimed iso2 iso3 redundant country.\nConfirm claim think situations might want keep information data frame might choose discard redundant columns.claimed iso2 iso3 redundant country.\nConfirm claim think situations might want keep information data frame might choose discard redundant columns.country, year, sex compute total number cases TB.\nMake informative visualisation data.country, year, sex compute total number cases TB.\nMake informative visualisation data.","code":""},{"path":"data-tidy.html","id":"non-tidy-data","chapter":"6 Data tidying","heading":"6.5 Non-tidy data","text":"continue topics, ’s worth talking briefly non-tidy data.\nEarlier chapter, used pejorative term “messy” refer non-tidy data.\n’s oversimplification: lots useful well-founded data structures tidy data.\ntwo main reasons use data structures:Alternative representations may substantial performance space advantages.Alternative representations may substantial performance space advantages.Specialised fields evolved conventions storing data may quite different conventions tidy data.Specialised fields evolved conventions storing data may quite different conventions tidy data.Either reasons means ’ll need something tibble (data frame).\ndata fit naturally rectangular structure composed observations variables, think tidy data default choice.\ngood reasons use structures; tidy data way.’d like learn non-tidy data, ’d highly recommend thoughtful blog post Jeff Leek: http://simplystatistics.org/2016/02/17/non-tidy-data.","code":""},{"path":"workflow-pipes.html","id":"workflow-pipes","chapter":"7 Workflow: pipes","heading":"7 Workflow: pipes","text":"Indenting line breaks\n\ndf %>% mutate(y = x + 1)\n# vs\ndf %>%\n  mutate(\n    y = x + 1\n  )Indenting line breaksmutate(df, y = x + 1) vs df %>% mutate(df, y = x + 1)mutate(df, y = x + 1) vs df %>% mutate(df, y = x + 1)ggplot2\n\ndf %>% \n  ggplot(aes()) \nDon’t forget switch plus!ggplot2Don’t forget switch plus!long pipes ?\nlong vs shortHow long pipes ?\nlong vs shortRestyling style.Restyling style.","code":"\ndf %>% mutate(y = x + 1)\n# vs\ndf %>%\n  mutate(\n    y = x + 1\n  )\ndf %>% \n  ggplot(aes()) "},{"path":"data-import.html","id":"data-import","chapter":"8 Data import","heading":"8 Data import","text":"reading work--progress second edition R Data Science. chapter currently undergoing heavy restructuring may confusing incomplete. can find polished first edition https://r4ds..co.nz.","code":""},{"path":"data-import.html","id":"introduction-4","chapter":"8 Data import","heading":"8.1 Introduction","text":"Working data provided R packages great way learn tools data science, point want stop learning start working data.\nchapter, ’ll learn read plain-text rectangular files R.\n, ’ll scratch surface data import, many principles translate forms data.\n’ll finish pointers packages useful types data.","code":""},{"path":"data-import.html","id":"prerequisites-4","chapter":"8 Data import","heading":"8.1.1 Prerequisites","text":"chapter, ’ll learn load flat files R readr package, part core tidyverse.","code":"\nlibrary(tidyverse)"},{"path":"data-import.html","id":"getting-started","chapter":"8 Data import","heading":"8.2 Getting started","text":"readr’s functions concerned turning flat files data frames:read_csv() reads comma delimited files, read_csv2() reads semicolon separated files (common countries , used decimal place), read_tsv() reads tab delimited files, read_delim() reads files delimiter.read_csv() reads comma delimited files, read_csv2() reads semicolon separated files (common countries , used decimal place), read_tsv() reads tab delimited files, read_delim() reads files delimiter.read_fwf() reads fixed width files.\ncan specify fields either widths fwf_widths() position fwf_positions().\nread_table() reads common variation fixed width files columns separated white space.read_fwf() reads fixed width files.\ncan specify fields either widths fwf_widths() position fwf_positions().\nread_table() reads common variation fixed width files columns separated white space.read_log() reads Apache style log files.\n(also check webreadr built top read_log() provides many helpful tools.)read_log() reads Apache style log files.\n(also check webreadr built top read_log() provides many helpful tools.)functions similar syntax: ’ve mastered one, can use others ease.\nrest chapter ’ll focus read_csv().\ncsv files one common forms data storage, understand read_csv(), can easily apply knowledge functions readr.first argument read_csv() important: ’s path file read.run read_csv() prints column specification gives name type column.\n’s important part readr, ’ll come back parsing file.can also supply inline csv file.\nuseful experimenting readr creating reproducible examples share others:cases read_csv() uses first line data column names, common convention.\ntwo cases might want tweak behaviour:Sometimes lines metadata top file.\ncan use skip = n skip first n lines; use comment = \"#\" drop lines start (e.g.) #.\n\nread_csv(\"first line metadata\n  second line metadata\n  x,y,z\n  1,2,3\", skip = 2)\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m1<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): x, y, zNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m retrieve full column specification data.NA#> <U+2029>[36mi<U+2029>[39m Specify column types set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m quiet message.NA#> <U+2029>[90m# tibble: 1 x 3<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NAread_csv(\"# comment want skip\n  x,y,z\n  1,2,3\", comment = \"#\")\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m1<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): x, y, zNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m retrieve full column specification data.NA#> <U+2029>[36mi<U+2029>[39m Specify column types set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m quiet message.NA#> <U+2029>[90m# tibble: 1 x 3<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NASometimes lines metadata top file.\ncan use skip = n skip first n lines; use comment = \"#\" drop lines start (e.g.) #.data might column names.\ncan use col_names = FALSE tell read_csv() treat first row headings, instead label sequentially X1 Xn:\n\nread_csv(\"1,2,3\\n4,5,6\", col_names = FALSE)\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): X1, X2, X3NA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m retrieve full column specification data.NA#> <U+2029>[36mi<U+2029>[39m Specify column types set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m quiet message.NA#> <U+2029>[90m# tibble: 2 x 3<U+2029>[39mNA#>      <U+2029>[1mX1<U+2029>[22m    <U+2029>[1mX2<U+2029>[22m    <U+2029>[1mX3<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NA#> <U+2029>[90m2<U+2029>[39m     4     5     6NA\n(\"\\n\" convenient shortcut adding new line. ’ll learn types string escape [string basics].)\nAlternatively can pass col_names character vector used column names:\n\nread_csv(\"1,2,3\\n4,5,6\", col_names = c(\"x\", \"y\", \"z\"))\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): x, y, zNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m retrieve full column specification data.NA#> <U+2029>[36mi<U+2029>[39m Specify column types set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m quiet message.NA#> <U+2029>[90m# tibble: 2 x 3<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NA#> <U+2029>[90m2<U+2029>[39m     4     5     6NAThe data might column names.\ncan use col_names = FALSE tell read_csv() treat first row headings, instead label sequentially X1 Xn:(\"\\n\" convenient shortcut adding new line. ’ll learn types string escape [string basics].)Alternatively can pass col_names character vector used column names:Another option commonly needs tweaking na: specifies value (values) used represent missing values file:need know read ~75% CSV files ’ll encounter practice.\ncan also easily adapt ’ve learned read tab separated files read_tsv() fixed width files read_fwf().\nread challenging files, ’ll need learn readr parses column, turning R vectors.","code":"\nheights <- read_csv(\"data/heights.csv\")\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m1192<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m6<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[31mchr<U+2029>[39m (2): sex, raceNA#> <U+2029>[32mdbl<U+2029>[39m (4): earn, height, ed, ageNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA\nread_csv(\"a,b,c\n1,2,3\n4,5,6\")\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): a, b, cNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA#> <U+2029>[90m# A tibble: 2 x 3<U+2029>[39mNA#>       <U+2029>[1ma<U+2029>[22m     <U+2029>[1mb<U+2029>[22m     <U+2029>[1mc<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NA#> <U+2029>[90m2<U+2029>[39m     4     5     6NA\nread_csv(\"The first line of metadata\n  The second line of metadata\n  x,y,z\n  1,2,3\", skip = 2)\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m1<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): x, y, zNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA#> <U+2029>[90m# A tibble: 1 x 3<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NAread_csv(\"# A comment I want to skip\n  x,y,z\n  1,2,3\", comment = \"#\")\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m1<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): x, y, zNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA#> <U+2029>[90m# A tibble: 1 x 3<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NA\nread_csv(\"1,2,3\\n4,5,6\", col_names = FALSE)\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): X1, X2, X3NA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA#> <U+2029>[90m# A tibble: 2 x 3<U+2029>[39mNA#>      <U+2029>[1mX1<U+2029>[22m    <U+2029>[1mX2<U+2029>[22m    <U+2029>[1mX3<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NA#> <U+2029>[90m2<U+2029>[39m     4     5     6NA\nread_csv(\"1,2,3\\n4,5,6\", col_names = c(\"x\", \"y\", \"z\"))\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (3): x, y, zNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA#> <U+2029>[90m# A tibble: 2 x 3<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2     3NA#> <U+2029>[90m2<U+2029>[39m     4     5     6NA\nread_csv(\"a,b,c\\n1,2,.\", na = \".\")\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m1<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m3<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m (2): a, bNA#> <U+2029>[33mlgl<U+2029>[39m (1): cNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA#> <U+2029>[90m# A tibble: 1 x 3<U+2029>[39mNA#>       <U+2029>[1ma<U+2029>[22m     <U+2029>[1mb<U+2029>[22m <U+2029>[1mc<U+2029>[22m    NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<lgl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2 <U+2029>[31mNA<U+2029>[39mNA"},{"path":"data-import.html","id":"compared-to-base-r","chapter":"8 Data import","heading":"8.2.1 Compared to base R","text":"’ve used R , might wonder ’re using read.csv().\ngood reasons favour readr functions base equivalents:typically much faster (~10x) base equivalents.\nLong running jobs progress bar, can see ’s happening.\n’re looking raw speed, try data.table::fread().\ndoesn’t fit quite well tidyverse, can quite bit faster.typically much faster (~10x) base equivalents.\nLong running jobs progress bar, can see ’s happening.\n’re looking raw speed, try data.table::fread().\ndoesn’t fit quite well tidyverse, can quite bit faster.produce tibbles, don’t convert character vectors factors, use row names, munge column names.\ncommon sources frustration base R functions.produce tibbles, don’t convert character vectors factors, use row names, munge column names.\ncommon sources frustration base R functions.reproducible.\nBase R functions inherit behaviour operating system environment variables, import code works computer might work someone else’s.reproducible.\nBase R functions inherit behaviour operating system environment variables, import code works computer might work someone else’s.","code":""},{"path":"data-import.html","id":"exercises-14","chapter":"8 Data import","heading":"8.2.2 Exercises","text":"function use read file fields separated \n“|”?function use read file fields separated \n“|”?Apart file, skip, comment, arguments read_csv() read_tsv() common?Apart file, skip, comment, arguments read_csv() read_tsv() common?important arguments read_fwf()?important arguments read_fwf()?Sometimes strings CSV file contain commas.\nprevent causing problems need surrounded quoting character, like \" '. default, read_csv() assumes quoting character \".\nargument read_csv() need specify read following text data frame?\n\n\"x,y\\n1,',b'\"Sometimes strings CSV file contain commas.\nprevent causing problems need surrounded quoting character, like \" '. default, read_csv() assumes quoting character \".\nargument read_csv() need specify read following text data frame?Identify wrong following inline CSV files.\nhappens run code?\n\nread_csv(\",b\\n1,2,3\\n4,5,6\")\nread_csv(\",b,c\\n1,2\\n1,2,3,4\")\nread_csv(\",b\\n\\\"1\")\nread_csv(\",b\\n1,2\\na,b\")\nread_csv(\";b\\n1;3\")Identify wrong following inline CSV files.\nhappens run code?","code":"\n\"x,y\\n1,'a,b'\"\nread_csv(\"a,b\\n1,2,3\\n4,5,6\")\nread_csv(\"a,b,c\\n1,2\\n1,2,3,4\")\nread_csv(\"a,b\\n\\\"1\")\nread_csv(\"a,b\\n1,2\\na,b\")\nread_csv(\"a;b\\n1;3\")"},{"path":"data-import.html","id":"parsing-a-vector","chapter":"8 Data import","heading":"8.3 Parsing a vector","text":"get details readr reads files disk, need take little detour talk parse_*() functions.\nfunctions take character vector return specialised vector like logical, integer, date:functions useful right, also important building block readr.\n’ve learned individual parsers work section, ’ll circle back see fit together parse complete file next section.Like functions tidyverse, parse_*() functions uniform: first argument character vector parse, na argument specifies strings treated missing:parsing fails, ’ll get warning:failures missing output:many parsing failures, ’ll need use problems() get complete set.\nreturns tibble, can manipulate dplyr.Using parsers mostly matter understanding ’s available deal different types input.\neight particularly important parsers:parse_logical() parse_integer() parse logicals integers respectively.\n’s basically nothing can go wrong parsers won’t describe .parse_logical() parse_integer() parse logicals integers respectively.\n’s basically nothing can go wrong parsers won’t describe .parse_double() strict numeric parser, parse_number() flexible numeric parser.\ncomplicated might expect different parts world write numbers different ways.parse_double() strict numeric parser, parse_number() flexible numeric parser.\ncomplicated might expect different parts world write numbers different ways.parse_character() seems simple shouldn’t necessary.\none complication makes quite important: character encodings.parse_character() seems simple shouldn’t necessary.\none complication makes quite important: character encodings.parse_factor() create factors, data structure R uses represent categorical variables fixed known values.parse_factor() create factors, data structure R uses represent categorical variables fixed known values.parse_datetime(), parse_date(), parse_time() allow parse various date & time specifications.\ncomplicated many different ways writing dates.parse_datetime(), parse_date(), parse_time() allow parse various date & time specifications.\ncomplicated many different ways writing dates.following sections describe parsers detail.","code":"\nstr(parse_logical(c(\"TRUE\", \"FALSE\", \"NA\")))\n#>  logi [1:3] TRUE FALSE NA\nstr(parse_integer(c(\"1\", \"2\", \"3\")))\n#>  int [1:3] 1 2 3\nstr(parse_date(c(\"2010-01-01\", \"1979-10-14\")))\n#>  Date[1:2], format: \"2010-01-01\" \"1979-10-14\"\nparse_integer(c(\"1\", \"231\", \".\", \"456\"), na = \".\")\n#> [1]   1 231  NA 456\nx <- parse_integer(c(\"123\", \"345\", \"abc\", \"123.45\"))\n#> Warning: 2 parsing failures.\n#> row col               expected actual\n#>   3  -- no trailing characters abc   \n#>   4  -- no trailing characters 123.45\nx\n#> [1] 123 345  NA  NA\n#> attr(,\"problems\")\n#> <U+2029>[90m# A tibble: 2 x 4<U+2029>[39mNA#>     <U+2029>[1mrow<U+2029>[22m   <U+2029>[1mcol<U+2029>[22m <U+2029>[1mexpected<U+2029>[22m               <U+2029>[1mactual<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m NA#> <U+2029>[90m1<U+2029>[39m     3    <U+2029>[31mNA<U+2029>[39m no trailing characters abc   NA#> <U+2029>[90m2<U+2029>[39m     4    <U+2029>[31mNA<U+2029>[39m no trailing characters 123.45NA\nproblems(x)\n#> <U+2029>[90m# A tibble: 2 x 4<U+2029>[39mNA#>     <U+2029>[1mrow<U+2029>[22m   <U+2029>[1mcol<U+2029>[22m <U+2029>[1mexpected<U+2029>[22m               <U+2029>[1mactual<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m NA#> <U+2029>[90m1<U+2029>[39m     3    <U+2029>[31mNA<U+2029>[39m no trailing characters abc   NA#> <U+2029>[90m2<U+2029>[39m     4    <U+2029>[31mNA<U+2029>[39m no trailing characters 123.45NA"},{"path":"data-import.html","id":"numbers","chapter":"8 Data import","heading":"8.3.1 Numbers","text":"seems like straightforward parse number, three problems make tricky:People write numbers differently different parts world.\nexample, countries use . integer fractional parts real number, others use ,.People write numbers differently different parts world.\nexample, countries use . integer fractional parts real number, others use ,.Numbers often surrounded characters provide context, like “$1000” “10%”.Numbers often surrounded characters provide context, like “$1000” “10%”.Numbers often contain “grouping” characters make easier read, like “1,000,000”, grouping characters vary around world.Numbers often contain “grouping” characters make easier read, like “1,000,000”, grouping characters vary around world.address first problem, readr notion “locale”, object specifies parsing options differ place place.\nparsing numbers, important option character use decimal mark.\ncan override default value . creating new locale setting decimal_mark argument:readr’s default locale US-centric, generally R US-centric (.e. documentation base R written American English).\nalternative approach try guess defaults operating system.\nhard well, , importantly, makes code fragile: even works computer, might fail email colleague another country.parse_number() addresses second problem: ignores non-numeric characters number.\nparticularly useful currencies percentages, also works extract numbers embedded text.final problem addressed combination parse_number() locale parse_number() ignore “grouping mark”:","code":"\nparse_double(\"1.23\")\n#> [1] 1.23\nparse_double(\"1,23\", locale = locale(decimal_mark = \",\"))\n#> [1] 1.23\nparse_number(\"$100\")\n#> [1] 100\nparse_number(\"20%\")\n#> [1] 20\nparse_number(\"It cost $123.45\")\n#> [1] 123.45\n# Used in America\nparse_number(\"$123,456,789\")\n#> [1] 123456789\n\n# Used in many parts of Europe\nparse_number(\"123.456.789\", locale = locale(grouping_mark = \".\"))\n#> [1] 123456789\n\n# Used in Switzerland\nparse_number(\"123'456'789\", locale = locale(grouping_mark = \"'\"))\n#> [1] 123456789"},{"path":"data-import.html","id":"readr-strings","chapter":"8 Data import","heading":"8.3.2 Strings","text":"seems like parse_character() really simple — just return input.\nUnfortunately life isn’t simple, multiple ways represent string.\nunderstand ’s going , need dive details computers represent strings.\nR, can get underlying representation string using charToRaw():hexadecimal number represents byte information: 48 H, 61 , .\nmapping hexadecimal number character called encoding, case encoding called ASCII.\nASCII great job representing English characters, ’s American Standard Code Information Interchange.Things get complicated languages English.\nearly days computing many competing standards encoding non-English characters, correctly interpret string needed know values encoding.\nexample, two common encodings Latin1 (aka ISO-8859-1, used Western European languages) Latin2 (aka ISO-8859-2, used Eastern European languages).\nLatin1, byte b1 “±”, Latin2, ’s “ą”!\nFortunately, today one standard supported almost everywhere: UTF-8.\nUTF-8 can encode just every character used humans today, well many extra symbols (like emoji!).readr uses UTF-8 everywhere: assumes data UTF-8 encoded read , always uses writing.\ngood default, fail data produced older systems don’t understand UTF-8.\nhappens , strings look weird print .\nSometimes just one two characters might messed ; times ’ll get complete gibberish.\nexample:fix problem need specify encoding parse_character():find correct encoding?\n’re lucky, ’ll included somewhere data documentation.\nUnfortunately, ’s rarely case, readr provides guess_encoding() help figure .\n’s foolproof, works better lots text (unlike ), ’s reasonable place start.\nExpect try different encodings find right one.first argument guess_encoding() can either path file, , case, raw vector (useful strings already R).Encodings rich complex topic, ’ve scratched surface .\n’d like learn ’d recommend reading detailed explanation http://kunststube.net/encoding/.","code":"\ncharToRaw(\"Hadley\")\n#> [1] 48 61 64 6c 65 79\nx1 <- \"El Ni\\xf1o was particularly bad this year\"\nx2 <- \"\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd\"\n\nx1\n#> [1] \"El Ni駉 was particularly bad this year\"x2\n#> [1] \"偙傫偵偪偼\"NA\nparse_character(x1, locale = locale(encoding = \"Latin1\"))\n#> [1] \"El Ni<U+00F1>o was particularly bad this year\"\nparse_character(x2, locale = locale(encoding = \"Shift-JIS\"))\n#> [1] \"こんにちは\"NA\nguess_encoding(charToRaw(x1))\n#> <U+2029>[90m# A tibble: 2 x 2<U+2029>[39mNA#>   <U+2029>[1mencoding<U+2029>[22m   <U+2029>[1mconfidence<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m           <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m ISO-8859-1       0.46NA#> <U+2029>[90m2<U+2029>[39m ISO-8859-9       0.23NAguess_encoding(charToRaw(x2))\n#> <U+2029>[90m# A tibble: 1 x 2<U+2029>[39mNA#>   <U+2029>[1mencoding<U+2029>[22m <U+2029>[1mconfidence<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m         <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m KOI8-R         0.42NA"},{"path":"data-import.html","id":"readr-factors","chapter":"8 Data import","heading":"8.3.3 Factors","text":"R uses factors represent categorical variables known set possible values.\nGive parse_factor() vector known levels generate warning whenever unexpected value present:many problematic entries, ’s often easier leave character vectors use tools ’ll learn strings factors clean .","code":"\nfruit <- c(\"apple\", \"banana\")\nparse_factor(c(\"apple\", \"banana\", \"bananana\"), levels = fruit)\n#> Warning: 1 parsing failure.\n#> row col           expected   actual\n#>   3  -- value in level set bananana\n#> [1] apple  banana <NA>  \n#> attr(,\"problems\")\n#> <U+2029>[90m# A tibble: 1 x 4<U+2029>[39mNA#>     <U+2029>[1mrow<U+2029>[22m   <U+2029>[1mcol<U+2029>[22m <U+2029>[1mexpected<U+2029>[22m           <U+2029>[1mactual<U+2029>[22m  NA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m              <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   NA#> <U+2029>[90m1<U+2029>[39m     3    <U+2029>[31mNA<U+2029>[39m value in level set banananaNA#> Levels: apple banana"},{"path":"data-import.html","id":"readr-datetimes","chapter":"8 Data import","heading":"8.3.4 Dates, date-times, and times","text":"pick three parsers depending whether want date (number days since 1970-01-01), date-time (number seconds since midnight 1970-01-01), time (number seconds since midnight).\ncalled without additional arguments:parse_datetime() expects ISO8601 date-time.\nISO8601 international standard components date organised biggest smallest: year, month, day, hour, minute, second.\n\nparse_datetime(\"2010-10-01T2010\")\n#> [1] \"2010-10-01 20:10:00 UTC\"\n# time omitted, set midnight\nparse_datetime(\"20101010\")\n#> [1] \"2010-10-10 UTC\"\nimportant date/time standard, work dates times frequently, recommend reading https://en.wikipedia.org/wiki/ISO_8601parse_datetime() expects ISO8601 date-time.\nISO8601 international standard components date organised biggest smallest: year, month, day, hour, minute, second.important date/time standard, work dates times frequently, recommend reading https://en.wikipedia.org/wiki/ISO_8601parse_date() expects four digit year, - /, month, - /, day:\n\nparse_date(\"2010-10-01\")\n#> [1] \"2010-10-01\"parse_date() expects four digit year, - /, month, - /, day:parse_time() expects hour, :, minutes, optionally : seconds, optional /pm specifier:\n\nlibrary(hms)\nparse_time(\"01:10 \")\n#> 01:10:00\nparse_time(\"20:10:01\")\n#> 20:10:01\nBase R doesn’t great built class time data, use one provided hms package.parse_time() expects hour, :, minutes, optionally : seconds, optional /pm specifier:Base R doesn’t great built class time data, use one provided hms package.defaults don’t work data can supply date-time format, built following pieces:Year%Y (4 digits).\n%Y (4 digits).%y (2 digits); 00-69 -> 2000-2069, 70-99 -> 1970-1999.\n%y (2 digits); 00-69 -> 2000-2069, 70-99 -> 1970-1999.Month%m (2 digits).\n%m (2 digits).%b (abbreviated name, like “Jan”).\n%b (abbreviated name, like “Jan”).%B (full name, “January”).\n%B (full name, “January”).Day%d (2 digits).\n%d (2 digits).%e (optional leading space).\n%e (optional leading space).Time%H 0-23 hour.\n%H 0-23 hour.%0-12, must used %p.\n%0-12, must used %p.%p /PM indicator.\n%p /PM indicator.%M minutes.\n%M minutes.%S integer seconds.\n%S integer seconds.%OS real seconds.\n%OS real seconds.%Z Time zone (name, e.g. America/Chicago).\nBeware abbreviations: ’re American, note “EST” Canadian time zone daylight savings time.\nEastern Standard Time!\n’ll come back time zones.\n%Z Time zone (name, e.g. America/Chicago).\nBeware abbreviations: ’re American, note “EST” Canadian time zone daylight savings time.\nEastern Standard Time!\n’ll come back time zones.%z (offset UTC, e.g. +0800).\n%z (offset UTC, e.g. +0800).Non-digits%. skips one non-digit character.\n%. skips one non-digit character.%* skips number non-digits.\n%* skips number non-digits.best way figure correct format create examples character vector, test one parsing functions.\nexample:’re using %b %B non-English month names, ’ll need set lang argument locale().\nSee list built-languages date_names_langs(), language already included, create date_names().","code":"\nparse_datetime(\"2010-10-01T2010\")\n#> [1] \"2010-10-01 20:10:00 UTC\"\n# If time is omitted, it will be set to midnight\nparse_datetime(\"20101010\")\n#> [1] \"2010-10-10 UTC\"\nparse_date(\"2010-10-01\")\n#> [1] \"2010-10-01\"\nlibrary(hms)\nparse_time(\"01:10 am\")\n#> 01:10:00\nparse_time(\"20:10:01\")\n#> 20:10:01\nparse_date(\"01/02/15\", \"%m/%d/%y\")\n#> [1] \"2015-01-02\"\nparse_date(\"01/02/15\", \"%d/%m/%y\")\n#> [1] \"2015-02-01\"\nparse_date(\"01/02/15\", \"%y/%m/%d\")\n#> [1] \"2001-02-15\"\nparse_date(\"1 janvier 2015\", \"%d %B %Y\", locale = locale(\"fr\"))\n#> [1] \"2015-01-01\""},{"path":"data-import.html","id":"exercises-15","chapter":"8 Data import","heading":"8.3.5 Exercises","text":"important arguments locale()?important arguments locale()?happens try set decimal_mark grouping_mark character?\nhappens default value grouping_mark set decimal_mark “,”?\nhappens default value decimal_mark set grouping_mark “.”?happens try set decimal_mark grouping_mark character?\nhappens default value grouping_mark set decimal_mark “,”?\nhappens default value decimal_mark set grouping_mark “.”?didn’t discuss date_format time_format options locale().\n?\nConstruct example shows might useful.didn’t discuss date_format time_format options locale().\n?\nConstruct example shows might useful.live outside US, create new locale object encapsulates settings types file read commonly.live outside US, create new locale object encapsulates settings types file read commonly.’s difference read_csv() read_csv2()?’s difference read_csv() read_csv2()?common encodings used Europe?\ncommon encodings used Asia?\ngoogling find .common encodings used Europe?\ncommon encodings used Asia?\ngoogling find .Generate correct format string parse following dates times:\n\nd1 <- \"January 1, 2010\"\nd2 <- \"2015-Mar-07\"\nd3 <- \"06-Jun-2017\"\nd4 <- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 <- \"12/30/14\" # Dec 30, 2014\nt1 <- \"1705\"\nt2 <- \"11:15:10.12 PM\"Generate correct format string parse following dates times:","code":"\nd1 <- \"January 1, 2010\"\nd2 <- \"2015-Mar-07\"\nd3 <- \"06-Jun-2017\"\nd4 <- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 <- \"12/30/14\" # Dec 30, 2014\nt1 <- \"1705\"\nt2 <- \"11:15:10.12 PM\""},{"path":"data-import.html","id":"parsing-a-file","chapter":"8 Data import","heading":"8.4 Parsing a file","text":"Now ’ve learned parse individual vector, ’s time return beginning explore readr parses file.\ntwo new things ’ll learn section:readr automatically guesses type column.override default specification.","code":""},{"path":"data-import.html","id":"strategy","chapter":"8 Data import","heading":"8.4.1 Strategy","text":"readr uses heuristic figure type column: reads first 1000 rows uses (moderately conservative) heuristics figure type column.\ncan emulate process character vector using guess_parser(), returns readr’s best guess, parse_guess() uses guess parse column:heuristic tries following types, stopping finds match:logical: contains “F”, “T”, “FALSE”, “TRUE”.integer: contains numeric characters (-).double: contains valid doubles (including numbers like 4.5e-5).number: contains valid doubles grouping mark inside.time: matches default time_format.date: matches default date_format.date-time: ISO8601 date.none rules apply, column stay vector strings.","code":"\nguess_parser(\"2010-10-01\")\n#> [1] \"date\"\nguess_parser(\"15:01\")\n#> [1] \"time\"\nguess_parser(c(\"TRUE\", \"FALSE\"))\n#> [1] \"logical\"\nguess_parser(c(\"1\", \"5\", \"9\"))\n#> [1] \"double\"\nguess_parser(c(\"12,352,561\"))\n#> [1] \"number\"\n\nstr(parse_guess(\"2010-10-10\"))\n#>  Date[1:1], format: \"2010-10-10\""},{"path":"data-import.html","id":"problems","chapter":"8 Data import","heading":"8.4.2 Problems","text":"defaults don’t always work larger files.\ntwo basic problems:first thousand rows might special case, readr guesses type sufficiently general.\nexample, might column doubles contains integers first 1000 rows.first thousand rows might special case, readr guesses type sufficiently general.\nexample, might column doubles contains integers first 1000 rows.column might contain lot missing values.\nfirst 1000 rows contain NAs, readr guess ’s logical vector, whereas probably want parse something specific.column might contain lot missing values.\nfirst 1000 rows contain NAs, readr guess ’s logical vector, whereas probably want parse something specific.readr contains challenging CSV illustrates problems:(Note use readr_example() finds path one files included package.)two printed outputs: column specification generated looking first 1000 rows, first five parsing failures.\n’s always good idea explicitly pull problems(), can explore depth:good strategy work column column problems remaining.\ncan see lot parsing problems y column.\nlook last rows, ’ll see ’re dates stored character vector:suggests need use date parser instead.\nfix call, start copying pasting column specification original call:can fix type y column specifying y date column:Every parse_xyz() function corresponding col_xyz() function.\nuse parse_xyz() data character vector R already; use col_xyz() want tell readr load data.highly recommend always supplying col_types, building print-provided readr.\nensures consistent reproducible data import script.\nrely default guesses data changes, readr continue read .\nwant really strict, use stop_for_problems(): throw error stop script parsing problems.","code":"\nchallenge <- read_csv(readr_example(\"challenge.csv\"))\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2000<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m  (1): xNA#> <U+2029>[34mdate<U+2029>[39m (1): yNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA\nproblems(challenge)\n#> <U+2029>[90m# A tibble: 0 x 5<U+2029>[39mNA#> <U+2029>[90m# ... with 5 variables: <U+2029>[1mrow<U+2029>[22m <int>, <U+2029>[1mcol<U+2029>[22m <int>, <U+2029>[1mexpected<U+2029>[22m <chr>, <U+2029>[1mactual<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mfile<U+2029>[22m <chr><U+2029>[39mNA\ntail(challenge)\n#> <U+2029>[90m# A tibble: 6 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m <U+2029>[1my<U+2029>[22m         NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23m    NA#> <U+2029>[90m1<U+2029>[39m 0.805 2019-11-21NA#> <U+2029>[90m2<U+2029>[39m 0.164 2018-03-29NA#> <U+2029>[90m3<U+2029>[39m 0.472 2014-08-04NA#> <U+2029>[90m4<U+2029>[39m 0.718 2015-08-16NA#> <U+2029>[90m5<U+2029>[39m 0.270 2020-02-04NA#> <U+2029>[90m6<U+2029>[39m 0.608 2019-01-06NA\nchallenge <- read_csv(\n  readr_example(\"challenge.csv\"), \n  col_types = cols(\n    x = col_double(),\n    y = col_logical()\n  )\n)\nchallenge <- read_csv(\n  readr_example(\"challenge.csv\"), \n  col_types = cols(\n    x = col_double(),\n    y = col_date()\n  )\n)\ntail(challenge)\n#> <U+2029>[90m# A tibble: 6 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m <U+2029>[1my<U+2029>[22m         NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23m    NA#> <U+2029>[90m1<U+2029>[39m 0.805 2019-11-21NA#> <U+2029>[90m2<U+2029>[39m 0.164 2018-03-29NA#> <U+2029>[90m3<U+2029>[39m 0.472 2014-08-04NA#> <U+2029>[90m4<U+2029>[39m 0.718 2015-08-16NA#> <U+2029>[90m5<U+2029>[39m 0.270 2020-02-04NA#> <U+2029>[90m6<U+2029>[39m 0.608 2019-01-06NA"},{"path":"data-import.html","id":"other-strategies","chapter":"8 Data import","heading":"8.4.3 Other strategies","text":"general strategies help parse files:previous example, just got unlucky: look just one row default, can correctly parse one shot:\n\nchallenge2 <- read_csv(readr_example(\"challenge.csv\"), guess_max = 1001)\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2000<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m  (1): xNA#> <U+2029>[34mdate<U+2029>[39m (1): yNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m retrieve full column specification data.NA#> <U+2029>[36mi<U+2029>[39m Specify column types set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m quiet message.NAchallenge2\n#> <U+2029>[90m# tibble: 2,000 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m <U+2029>[1my<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m   404 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m4<U+2029>[24m172 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m3<U+2029>[24m004 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m4<U+2029>[39m   787 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m5<U+2029>[39m    37 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m332 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m# ... 1,994 rows<U+2029>[39mNAIn previous example, just got unlucky: look just one row default, can correctly parse one shot:Sometimes ’s easier diagnose problems just read columns character vectors:\n\nchallenge2 <- read_csv(readr_example(\"challenge.csv\"), \n  col_types = cols(.default = col_character())\n)\nparticularly useful conjunction type_convert(), applies parsing heuristics character columns data frame.\n\ndf <- tribble(\n  ~x,  ~y,\n  \"1\", \"1.21\",\n  \"2\", \"2.32\",\n  \"3\", \"4.56\"\n)\ndf\n#> <U+2029>[90m# tibble: 3 x 2<U+2029>[39mNA#>   <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m    NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m 1     1.21 NA#> <U+2029>[90m2<U+2029>[39m 2     2.32 NA#> <U+2029>[90m3<U+2029>[39m 3     4.56NA# Note column types\ntype_convert(df)\n#> \n#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> cols(\n#>   x = <U+2029>[32mcol_double()<U+2029>[39m,NA#>   y = <U+2029>[32mcol_double()<U+2029>[39mNA#> )\n#> <U+2029>[90m# tibble: 3 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1  1.21NA#> <U+2029>[90m2<U+2029>[39m     2  2.32NA#> <U+2029>[90m3<U+2029>[39m     3  4.56NASometimes ’s easier diagnose problems just read columns character vectors:particularly useful conjunction type_convert(), applies parsing heuristics character columns data frame.’re reading large file, might want set n_max smallish number like 10,000 100,000.\naccelerate iterations eliminate common problems.’re reading large file, might want set n_max smallish number like 10,000 100,000.\naccelerate iterations eliminate common problems.’re major parsing problems, sometimes ’s easier just read character vector lines read_lines(), even character vector length 1 read_file().\ncan use string parsing skills ’ll learn later parse exotic formats.’re major parsing problems, sometimes ’s easier just read character vector lines read_lines(), even character vector length 1 read_file().\ncan use string parsing skills ’ll learn later parse exotic formats.","code":"\nchallenge2 <- read_csv(readr_example(\"challenge.csv\"), guess_max = 1001)\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2000<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m  (1): xNA#> <U+2029>[34mdate<U+2029>[39m (1): yNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NAchallenge2\n#> <U+2029>[90m# A tibble: 2,000 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m <U+2029>[1my<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m   404 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m4<U+2029>[24m172 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m3<U+2029>[24m004 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m4<U+2029>[39m   787 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m5<U+2029>[39m    37 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m332 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m# ... with 1,994 more rows<U+2029>[39mNA\nchallenge2 <- read_csv(readr_example(\"challenge.csv\"), \n  col_types = cols(.default = col_character())\n)\ndf <- tribble(\n  ~x,  ~y,\n  \"1\", \"1.21\",\n  \"2\", \"2.32\",\n  \"3\", \"4.56\"\n)\ndf\n#> <U+2029>[90m# A tibble: 3 x 2<U+2029>[39mNA#>   <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m    NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m 1     1.21 NA#> <U+2029>[90m2<U+2029>[39m 2     2.32 NA#> <U+2029>[90m3<U+2029>[39m 3     4.56NA# Note the column types\ntype_convert(df)\n#> \n#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> cols(\n#>   x = <U+2029>[32mcol_double()<U+2029>[39m,NA#>   y = <U+2029>[32mcol_double()<U+2029>[39mNA#> )\n#> <U+2029>[90m# A tibble: 3 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1  1.21NA#> <U+2029>[90m2<U+2029>[39m     2  2.32NA#> <U+2029>[90m3<U+2029>[39m     3  4.56NA"},{"path":"data-import.html","id":"writing-to-a-file","chapter":"8 Data import","heading":"8.5 Writing to a file","text":"readr also comes two useful functions writing data back disk: write_csv() write_tsv().\nfunctions increase chances output file read back correctly :Always encoding strings UTF-8.Always encoding strings UTF-8.Saving dates date-times ISO8601 format easily parsed elsewhere.Saving dates date-times ISO8601 format easily parsed elsewhere.want export csv file Excel, use write_excel_csv() — writes special character (“byte order mark”) start file tells Excel ’re using UTF-8 encoding.important arguments x (data frame save), path (location save ).\ncan also specify missing values written na, want append existing file.Note type information lost save csv:makes CSVs little unreliable caching interim results—need recreate column specification every time load .\ntwo alternatives:write_rds() read_rds() uniform wrappers around base functions readRDS() saveRDS().\nstore data R’s custom binary format called RDS:\n\nwrite_rds(challenge, \"challenge.rds\")\nread_rds(\"challenge.rds\")\n#> <U+2029>[90m# tibble: 2,000 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m <U+2029>[1my<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m   404 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m4<U+2029>[24m172 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m3<U+2029>[24m004 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m4<U+2029>[39m   787 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m5<U+2029>[39m    37 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m332 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m# ... 1,994 rows<U+2029>[39mNAwrite_rds() read_rds() uniform wrappers around base functions readRDS() saveRDS().\nstore data R’s custom binary format called RDS:feather package implements fast binary file format can shared across programming languages:\n\nlibrary(feather)\nwrite_feather(challenge, \"challenge.feather\")\nread_feather(\"challenge.feather\")\n#> # tibble: 2,000 x 2\n#>       x      y\n#>   <dbl> <date>\n#> 1   404   <NA>\n#> 2  4172   <NA>\n#> 3  3004   <NA>\n#> 4   787   <NA>\n#> 5    37   <NA>\n#> 6  2332   <NA>\n#> # ... 1,994 rowsThe feather package implements fast binary file format can shared across programming languages:Feather tends faster RDS usable outside R.\nRDS supports list-columns (’ll learn Chapter 30; feather currently .","code":"\nwrite_csv(challenge, \"challenge.csv\")\nchallenge\n#> <U+2029>[90m# A tibble: 2,000 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m <U+2029>[1my<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m   404 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m4<U+2029>[24m172 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m3<U+2029>[24m004 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m4<U+2029>[39m   787 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m5<U+2029>[39m    37 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m332 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m# ... with 1,994 more rows<U+2029>[39mNAwrite_csv(challenge, \"challenge-2.csv\")\nread_csv(\"challenge-2.csv\")\n#> <U+2029>[1m<U+2029>[1mRows: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2000<U+2029>[34m<U+2029>[39m <U+2029>[1m<U+2029>[1mColumns: <U+2029>[1m<U+2029>[22m<U+2029>[34m<U+2029>[34m2<U+2029>[34m<U+2029>[39mNA#> <U+2029>[36m--<U+2029>[39m <U+2029>[1m<U+2029>[1mColumn specification<U+2029>[1m<U+2029>[22m <U+2029>[36m--------------------------------------------------------<U+2029>[39mNA#> <U+2029>[1mDelimiter:<U+2029>[22m \",\"NA#> <U+2029>[32mdbl<U+2029>[39m  (1): xNA#> <U+2029>[34mdate<U+2029>[39m (1): yNA#> \n#> <U+2029>[36mi<U+2029>[39m Use <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`spec()`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to retrieve the full column specification for this data.NA#> <U+2029>[36mi<U+2029>[39m Specify the column types or set <U+2029>[30m<U+2029>[47m<U+2029>[30m<U+2029>[47m`show_col_types = FALSE`<U+2029>[47m<U+2029>[30m<U+2029>[49m<U+2029>[39m to quiet this message.NA#> <U+2029>[90m# A tibble: 2,000 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m <U+2029>[1my<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m   404 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m4<U+2029>[24m172 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m3<U+2029>[24m004 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m4<U+2029>[39m   787 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m5<U+2029>[39m    37 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m332 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m# ... with 1,994 more rows<U+2029>[39mNA\nwrite_rds(challenge, \"challenge.rds\")\nread_rds(\"challenge.rds\")\n#> <U+2029>[90m# A tibble: 2,000 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m <U+2029>[1my<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m   404 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m4<U+2029>[24m172 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m3<U+2029>[24m004 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m4<U+2029>[39m   787 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m5<U+2029>[39m    37 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m332 <U+2029>[31mNA<U+2029>[39m    NA#> <U+2029>[90m# ... with 1,994 more rows<U+2029>[39mNA\nlibrary(feather)\nwrite_feather(challenge, \"challenge.feather\")\nread_feather(\"challenge.feather\")\n#> # A tibble: 2,000 x 2\n#>       x      y\n#>   <dbl> <date>\n#> 1   404   <NA>\n#> 2  4172   <NA>\n#> 3  3004   <NA>\n#> 4   787   <NA>\n#> 5    37   <NA>\n#> 6  2332   <NA>\n#> # ... with 1,994 more rows"},{"path":"data-import.html","id":"other-types-of-data","chapter":"8 Data import","heading":"8.6 Other types of data","text":"get types data R, recommend starting tidyverse packages listed .\n’re certainly perfect, good place start.\nrectangular data:haven reads SPSS, Stata, SAS files.haven reads SPSS, Stata, SAS files.readxl reads excel files (.xls .xlsx).readxl reads excel files (.xls .xlsx).DBI, along database specific backend (e.g. RMySQL, RSQLite, RPostgreSQL etc) allows run SQL queries database return data frame.DBI, along database specific backend (e.g. RMySQL, RSQLite, RPostgreSQL etc) allows run SQL queries database return data frame.hierarchical data: use jsonlite (Jeroen Ooms) json, xml2 XML.\nJenny Bryan excellent worked examples https://jennybc.github.io/purrr-tutorial/.file types, try R data import/export manual rio package.","code":""},{"path":"workflow-scripts.html","id":"workflow-scripts","chapter":"9 Workflow: scripts","heading":"9 Workflow: scripts","text":"far ’ve using console run code.\n’s great place start, ’ll find gets cramped pretty quickly create complex ggplot2 graphics dplyr pipes.\ngive room work, ’s great idea use script editor.\nOpen either clicking File menu, selecting New File, R script, using keyboard shortcut Cmd/Ctrl + Shift + N.\nNow ’ll see four panes:script editor great place put code care .\nKeep experimenting console, written code works want, put script editor.\nRStudio automatically save contents editor quit RStudio, automatically load re-open.\nNevertheless, ’s good idea save scripts regularly back .","code":""},{"path":"workflow-scripts.html","id":"running-code","chapter":"9 Workflow: scripts","heading":"9.1 Running code","text":"script editor also great place build complex ggplot2 plots long sequences dplyr manipulations.\nkey using script editor effectively memorise one important keyboard shortcuts: Cmd/Ctrl + Enter.\nexecutes current R expression console.\nexample, take code .\ncursor █, pressing Cmd/Ctrl + Enter run complete command generates not_cancelled.\nalso move cursor next statement (beginning not_cancelled %>%).\nmakes easy run complete script repeatedly pressing Cmd/Ctrl + Enter.Instead running expression--expression, can also execute complete script one step: Cmd/Ctrl + Shift + S.\nregularly great way check ’ve captured important parts code script.recommend always start script packages need.\nway, share code others, can easily see packages need install.\nNote, however, never include install.packages() setwd() script share.\n’s antisocial change settings someone else’s computer!working future chapters, highly recommend starting editor practicing keyboard shortcuts.\ntime, sending code console way become natural won’t even think .","code":"library(dplyr)\nlibrary(nycflights13)\n\nnot_cancelled <- flights %>% \n  filter(!is.na(dep_delay)█, !is.na(arr_delay))\n\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(mean = mean(dep_delay))"},{"path":"workflow-scripts.html","id":"rstudio-diagnostics","chapter":"9 Workflow: scripts","heading":"9.2 RStudio diagnostics","text":"script editor also highlight syntax errors red squiggly line cross sidebar:Hover cross see problem :RStudio also let know potential problems:","code":""},{"path":"workflow-scripts.html","id":"exercises-16","chapter":"9 Workflow: scripts","heading":"9.3 Exercises","text":"Go RStudio Tips Twitter account, https://twitter.com/rstudiotips find one tip looks interesting.\nPractice using !Go RStudio Tips Twitter account, https://twitter.com/rstudiotips find one tip looks interesting.\nPractice using !common mistakes RStudio diagnostics report?\nRead https://support.rstudio.com/hc/en-us/articles/205753617-Code-Diagnostics find .common mistakes RStudio diagnostics report?\nRead https://support.rstudio.com/hc/en-us/articles/205753617-Code-Diagnostics find .","code":""},{"path":"exploratory-data-analysis.html","id":"exploratory-data-analysis","chapter":"10 Exploratory Data Analysis","heading":"10 Exploratory Data Analysis","text":"","code":""},{"path":"exploratory-data-analysis.html","id":"introduction-5","chapter":"10 Exploratory Data Analysis","heading":"10.1 Introduction","text":"chapter show use visualisation transformation explore data systematic way, task statisticians call exploratory data analysis, EDA short.\nEDA iterative cycle.\n:Generate questions data.Generate questions data.Search answers visualising, transforming, modelling data.Search answers visualising, transforming, modelling data.Use learn refine questions /generate new questions.Use learn refine questions /generate new questions.EDA formal process strict set rules.\nanything, EDA state mind.\ninitial phases EDA feel free investigate every idea occurs .\nideas pan , dead ends.\nexploration continues, home particularly productive areas ’ll eventually write communicate others.EDA important part data analysis, even questions handed platter, always need investigate quality data.\nData cleaning just one application EDA: ask questions whether data meets expectations .\ndata cleaning, ’ll need deploy tools EDA: visualisation, transformation, modelling.","code":""},{"path":"exploratory-data-analysis.html","id":"prerequisites-5","chapter":"10 Exploratory Data Analysis","heading":"10.1.1 Prerequisites","text":"chapter ’ll combine ’ve learned dplyr ggplot2 interactively ask questions, answer data, ask new questions.","code":"\nlibrary(tidyverse)"},{"path":"exploratory-data-analysis.html","id":"questions","chapter":"10 Exploratory Data Analysis","heading":"10.2 Questions","text":"“routine statistical questions, questionable statistical routines.” — Sir David Cox“Far better approximate answer right question, often vague, exact answer wrong question, can always made precise.” — John TukeyYour goal EDA develop understanding data.\neasiest way use questions tools guide investigation.\nask question, question focuses attention specific part dataset helps decide graphs, models, transformations make.EDA fundamentally creative process.\nlike creative processes, key asking quality questions generate large quantity questions.\ndifficult ask revealing questions start analysis know insights contained dataset.\nhand, new question ask expose new aspect data increase chance making discovery.\ncan quickly drill interesting parts data—develop set thought-provoking questions—follow question new question based find.rule questions ask guide research.\nHowever, two types questions always useful making discoveries within data.\ncan loosely word questions :type variation occurs within variables?type variation occurs within variables?type covariation occurs variables?type covariation occurs variables?rest chapter look two questions.\n’ll explain variation covariation , ’ll show several ways answer question.\nmake discussion easier, let’s define terms:variable quantity, quality, property can measure.variable quantity, quality, property can measure.value state variable measure .\nvalue variable may change measurement measurement.value state variable measure .\nvalue variable may change measurement measurement.observation set measurements made similar conditions (usually make measurements observation time object).\nobservation contain several values, associated different variable.\n’ll sometimes refer observation data point.observation set measurements made similar conditions (usually make measurements observation time object).\nobservation contain several values, associated different variable.\n’ll sometimes refer observation data point.Tabular data set values, associated variable observation.\nTabular data tidy value placed “cell”, variable column, observation row.Tabular data set values, associated variable observation.\nTabular data tidy value placed “cell”, variable column, observation row.far, data ’ve seen tidy.\nreal-life, data isn’t tidy, ’ll come back ideas tidy data.","code":""},{"path":"exploratory-data-analysis.html","id":"variation","chapter":"10 Exploratory Data Analysis","heading":"10.3 Variation","text":"Variation tendency values variable change measurement measurement.\ncan see variation easily real life; measure continuous variable twice, get two different results.\ntrue even measure quantities constant, like speed light.\nmeasurements include small amount error varies measurement measurement.\nCategorical variables can also vary measure across different subjects (e.g. eye colors different people), different times (e.g. energy levels electron different moments).\nEvery variable pattern variation, can reveal interesting information.\nbest way understand pattern visualise distribution variable’s values.","code":""},{"path":"exploratory-data-analysis.html","id":"visualising-distributions","chapter":"10 Exploratory Data Analysis","heading":"10.3.1 Visualising distributions","text":"visualise distribution variable depend whether variable categorical continuous.\nvariable categorical can take one small set values.\nR, categorical variables usually saved factors character vectors.\nexamine distribution categorical variable, use bar chart:height bars displays many observations occurred x value.\ncan compute values manually dplyr::count():variable continuous can take infinite set ordered values.\nNumbers date-times two examples continuous variables.\nexamine distribution continuous variable, use histogram:can compute hand combining dplyr::count() ggplot2::cut_width():histogram divides x-axis equally spaced bins uses height bar display number observations fall bin.\ngraph , tallest bar shows almost 30,000 observations carat value 0.25 0.75, left right edges bar.can set width intervals histogram binwidth argument, measured units x variable.\nalways explore variety binwidths working histograms, different binwidths can reveal different patterns.\nexample, graph looks zoom just diamonds size less three carats choose smaller binwidth.wish overlay multiple histograms plot, recommend using geom_freqpoly() instead geom_histogram().\ngeom_freqpoly() performs calculation geom_histogram(), instead displaying counts bars, uses lines instead.\n’s much easier understand overlapping lines bars.challenges type plot, come back visualising categorical continuous variable.Now can visualise variation, look plots?\ntype follow-questions ask?\n’ve put together list useful types information find graphs, along follow-questions type information.\nkey asking good follow-questions rely curiosity (want learn ?) well skepticism (misleading?).","code":"\nggplot(data = diamonds) +\n  geom_bar(mapping = aes(x = cut))\ndiamonds %>% \n  count(cut)\n#> <U+2029>[90m# A tibble: 5 x 2<U+2029>[39mNA#>   <U+2029>[1mcut<U+2029>[22m           <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<ord><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Fair       <U+2029>[4m1<U+2029>[24m610NA#> <U+2029>[90m2<U+2029>[39m Good       <U+2029>[4m4<U+2029>[24m906NA#> <U+2029>[90m3<U+2029>[39m Very Good <U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m082NA#> <U+2029>[90m4<U+2029>[39m Premium   <U+2029>[4m1<U+2029>[24m<U+2029>[4m3<U+2029>[24m791NA#> <U+2029>[90m5<U+2029>[39m Ideal     <U+2029>[4m2<U+2029>[24m<U+2029>[4m1<U+2029>[24m551NA\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = carat), binwidth = 0.5)\ndiamonds %>% \n  count(cut_width(carat, 0.5))\n#> <U+2029>[90m# A tibble: 11 x 2<U+2029>[39mNA#>   <U+2029>[1m`cut_width(carat, 0.5)`<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m                   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m [-0.25,0.25]              785NA#> <U+2029>[90m2<U+2029>[39m (0.25,0.75]             <U+2029>[4m2<U+2029>[24m<U+2029>[4m9<U+2029>[24m498NA#> <U+2029>[90m3<U+2029>[39m (0.75,1.25]             <U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m977NA#> <U+2029>[90m4<U+2029>[39m (1.25,1.75]              <U+2029>[4m5<U+2029>[24m313NA#> <U+2029>[90m5<U+2029>[39m (1.75,2.25]              <U+2029>[4m2<U+2029>[24m002NA#> <U+2029>[90m6<U+2029>[39m (2.25,2.75]               322NA#> <U+2029>[90m# ... with 5 more rows<U+2029>[39mNA\nsmaller <- diamonds %>% \n  filter(carat < 3)\n  \nggplot(data = smaller, mapping = aes(x = carat)) +\n  geom_histogram(binwidth = 0.1)\nggplot(data = smaller, mapping = aes(x = carat, colour = cut)) +\n  geom_freqpoly(binwidth = 0.1)"},{"path":"exploratory-data-analysis.html","id":"typical-values","chapter":"10 Exploratory Data Analysis","heading":"10.3.2 Typical values","text":"bar charts histograms, tall bars show common values variable, shorter bars show less-common values.\nPlaces bars reveal values seen data.\nturn information useful questions, look anything unexpected:values common?\n?values common?\n?values rare?\n?\nmatch expectations?values rare?\n?\nmatch expectations?Can see unusual patterns?\nmight explain ?Can see unusual patterns?\nmight explain ?example, histogram suggests several interesting questions:diamonds whole carats common fractions carats?diamonds whole carats common fractions carats?diamonds slightly right peak slightly left peak?diamonds slightly right peak slightly left peak?Clusters similar values suggest subgroups exist data.\nunderstand subgroups, ask:observations within cluster similar ?observations within cluster similar ?observations separate clusters different ?observations separate clusters different ?can explain describe clusters?can explain describe clusters?might appearance clusters misleading?might appearance clusters misleading?histogram shows length (minutes) 272 eruptions Old Faithful Geyser Yellowstone National Park.\nEruption times appear clustered two groups: short eruptions (around 2 minutes) long eruptions (4-5 minutes), little .Many questions prompt explore relationship variables, example, see values one variable can explain behavior another variable.\n’ll get shortly.","code":"\nggplot(data = smaller, mapping = aes(x = carat)) +\n  geom_histogram(binwidth = 0.01)\nggplot(data = faithful, mapping = aes(x = eruptions)) + \n  geom_histogram(binwidth = 0.25)"},{"path":"exploratory-data-analysis.html","id":"unusual-values","chapter":"10 Exploratory Data Analysis","heading":"10.3.3 Unusual values","text":"Outliers observations unusual; data points don’t seem fit pattern.\nSometimes outliers data entry errors; times outliers suggest important new science.\nlot data, outliers sometimes difficult see histogram.\nexample, take distribution y variable diamonds dataset.\nevidence outliers unusually wide limits x-axis.many observations common bins rare bins short can’t see (although maybe stare intently 0 ’ll spot something).\nmake easy see unusual values, need zoom small values y-axis coord_cartesian():(coord_cartesian() also xlim() argument need zoom x-axis.\nggplot2 also xlim() ylim() functions work slightly differently: throw away data outside limits.)allows us see three unusual values: 0, ~30, ~60.\npluck dplyr:y variable measures one three dimensions diamonds, mm.\nknow diamonds can’t width 0mm, values must incorrect.\nmight also suspect measurements 32mm 59mm implausible: diamonds inch long, don’t cost hundreds thousands dollars!’s good practice repeat analysis without outliers.\nminimal effect results, can’t figure ’re , ’s reasonable replace missing values, move .\nHowever, substantial effect results, shouldn’t drop without justification.\n’ll need figure caused (e.g. data entry error) disclose removed write-.","code":"\nggplot(diamonds) + \n  geom_histogram(mapping = aes(x = y), binwidth = 0.5)\nggplot(diamonds) + \n  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +\n  coord_cartesian(ylim = c(0, 50))\nunusual <- diamonds %>% \n  filter(y < 3 | y > 20) %>% \n  select(price, x, y, z) %>%\n  arrange(y)\nunusual\n#> <U+2029>[90m# A tibble: 9 x 4<U+2029>[39mNA#>   <U+2029>[1mprice<U+2029>[22m     <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m5<U+2029>[24m139  0      0    0   NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m6<U+2029>[24m381  0      0    0   NA#> <U+2029>[90m3<U+2029>[39m <U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m800  0      0    0   NA#> <U+2029>[90m4<U+2029>[39m <U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m686  0      0    0   NA#> <U+2029>[90m5<U+2029>[39m <U+2029>[4m1<U+2029>[24m<U+2029>[4m8<U+2029>[24m034  0      0    0   NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m130  0      0    0   NA#> <U+2029>[90m7<U+2029>[39m  <U+2029>[4m2<U+2029>[24m130  0      0    0   NA#> <U+2029>[90m8<U+2029>[39m  <U+2029>[4m2<U+2029>[24m075  5.15  31.8  5.12NA#> <U+2029>[90m9<U+2029>[39m <U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m210  8.09  58.9  8.06NA"},{"path":"exploratory-data-analysis.html","id":"exercises-17","chapter":"10 Exploratory Data Analysis","heading":"10.3.4 Exercises","text":"Explore distribution x, y, z variables diamonds.\nlearn?\nThink diamond might decide dimension length, width, depth.Explore distribution x, y, z variables diamonds.\nlearn?\nThink diamond might decide dimension length, width, depth.Explore distribution price.\ndiscover anything unusual surprising?\n(Hint: Carefully think binwidth make sure try wide range values.)Explore distribution price.\ndiscover anything unusual surprising?\n(Hint: Carefully think binwidth make sure try wide range values.)many diamonds 0.99 carat?\nmany 1 carat?\nthink cause difference?many diamonds 0.99 carat?\nmany 1 carat?\nthink cause difference?Compare contrast coord_cartesian() vs xlim() ylim() zooming histogram.\nhappens leave binwidth unset?\nhappens try zoom half bar shows?Compare contrast coord_cartesian() vs xlim() ylim() zooming histogram.\nhappens leave binwidth unset?\nhappens try zoom half bar shows?","code":""},{"path":"exploratory-data-analysis.html","id":"missing-values-eda","chapter":"10 Exploratory Data Analysis","heading":"10.4 Missing values","text":"’ve encountered unusual values dataset, simply want move rest analysis, two options.Drop entire row strange values:\n\ndiamonds2 <- diamonds %>% \n  filter((y, 3, 20))\ndon’t recommend option just one measurement invalid, doesn’t mean measurements .\nAdditionally, low quality data, time ’ve applied approach every variable might find don’t data left!Drop entire row strange values:don’t recommend option just one measurement invalid, doesn’t mean measurements .\nAdditionally, low quality data, time ’ve applied approach every variable might find don’t data left!Instead, recommend replacing unusual values missing values.\neasiest way use mutate() replace variable modified copy.\ncan use ifelse() function replace unusual values NA:\n\ndiamonds2 <- diamonds %>% \n  mutate(y = ifelse(y < 3 | y > 20, NA, y))Instead, recommend replacing unusual values missing values.\neasiest way use mutate() replace variable modified copy.\ncan use ifelse() function replace unusual values NA:ifelse() three arguments.\nfirst argument test logical vector.\nresult contain value second argument, yes, test TRUE, value third argument, , false.\nAlternatively ifelse, use dplyr::case_when().\ncase_when() particularly useful inside mutate want create new variable relies complex combination existing variables.Like R, ggplot2 subscribes philosophy missing values never silently go missing.\n’s obvious plot missing values, ggplot2 doesn’t include plot, warn ’ve removed:suppress warning, set na.rm = TRUE:times want understand makes observations missing values different observations recorded values.\nexample, nycflights13::flights, missing values dep_time variable indicate flight cancelled.\nmight want compare scheduled departure times cancelled non-cancelled times.\ncan making new variable .na().However plot isn’t great many non-cancelled flights cancelled flights.\nnext section ’ll explore techniques improving comparison.","code":"\ndiamonds2 <- diamonds %>% \n  filter(between(y, 3, 20))\ndiamonds2 <- diamonds %>% \n  mutate(y = ifelse(y < 3 | y > 20, NA, y))\nggplot(data = diamonds2, mapping = aes(x = x, y = y)) + \n  geom_point()\n#> Warning: Removed 9 rows containing missing values (geom_point).\nggplot(data = diamonds2, mapping = aes(x = x, y = y)) + \n  geom_point(na.rm = TRUE)\nnycflights13::flights %>% \n  mutate(\n    cancelled = is.na(dep_time),\n    sched_hour = sched_dep_time %/% 100,\n    sched_min = sched_dep_time %% 100,\n    sched_dep_time = sched_hour + sched_min / 60\n  ) %>% \n  ggplot(mapping = aes(sched_dep_time)) + \n    geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/4)"},{"path":"exploratory-data-analysis.html","id":"exercises-18","chapter":"10 Exploratory Data Analysis","heading":"10.4.1 Exercises","text":"happens missing values histogram?\nhappens missing values bar chart?\ndifference?happens missing values histogram?\nhappens missing values bar chart?\ndifference?na.rm = TRUE mean() sum()?na.rm = TRUE mean() sum()?","code":""},{"path":"exploratory-data-analysis.html","id":"covariation","chapter":"10 Exploratory Data Analysis","heading":"10.5 Covariation","text":"variation describes behavior within variable, covariation describes behavior variables.\nCovariation tendency values two variables vary together related way.\nbest way spot covariation visualise relationship two variables.\ndepend type variables involved.","code":""},{"path":"exploratory-data-analysis.html","id":"cat-cont","chapter":"10 Exploratory Data Analysis","heading":"10.5.1 A categorical and continuous variable","text":"’s common want explore distribution continuous variable broken categorical variable, previous frequency polygon.\ndefault appearance geom_freqpoly() useful sort comparison height given count.\nmeans one groups much smaller others, ’s hard see differences shape.\nexample, let’s explore price diamond varies quality:’s hard see difference distribution overall counts differ much:make comparison easier need swap displayed y-axis.\nInstead displaying count, ’ll display density, count standardised area frequency polygon one.’s something rather surprising plot - appears fair diamonds (lowest quality) highest average price!\nmaybe ’s frequency polygons little hard interpret - ’s lot going plot.Another alternative display distribution continuous variable broken categorical variable boxplot.\nboxplot type visual shorthand distribution values popular among statisticians.\nboxplot consists :box stretches 25th percentile distribution 75th percentile, distance known interquartile range (IQR).\nmiddle box line displays median, .e. 50th percentile, distribution.\nthree lines give sense spread distribution whether distribution symmetric median skewed one side.box stretches 25th percentile distribution 75th percentile, distance known interquartile range (IQR).\nmiddle box line displays median, .e. 50th percentile, distribution.\nthree lines give sense spread distribution whether distribution symmetric median skewed one side.Visual points display observations fall 1.5 times IQR either edge box.\noutlying points unusual plotted individually.Visual points display observations fall 1.5 times IQR either edge box.\noutlying points unusual plotted individually.line (whisker) extends end box goes \nfarthest non-outlier point distribution.line (whisker) extends end box goes \nfarthest non-outlier point distribution.Let’s take look distribution price cut using geom_boxplot():see much less information distribution, boxplots much compact can easily compare (fit one plot).\nsupports counterintuitive finding better quality diamonds cheaper average!\nexercises, ’ll challenged figure .cut ordered factor: fair worse good, worse good .\nMany categorical variables don’t intrinsic order, might want reorder make informative display.\nOne way reorder() function.example, take class variable mpg dataset.\nmight interested know highway mileage varies across classes:make trend easier see, can reorder class based median value hwy:long variable names, geom_boxplot() work better flip 90°.\ncan coord_flip().","code":"\nggplot(data = diamonds, mapping = aes(x = price)) + \n  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)\nggplot(diamonds) + \n  geom_bar(mapping = aes(x = cut))\nggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + \n  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)\nggplot(data = diamonds, mapping = aes(x = cut, y = price)) +\n  geom_boxplot()\nggplot(data = mpg, mapping = aes(x = class, y = hwy)) +\n  geom_boxplot()\nggplot(data = mpg) +\n  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy))\nggplot(data = mpg) +\n  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) +\n  coord_flip()"},{"path":"exploratory-data-analysis.html","id":"exercises-19","chapter":"10 Exploratory Data Analysis","heading":"10.5.1.1 Exercises","text":"Use ’ve learned improve visualisation departure times cancelled vs. non-cancelled flights.Use ’ve learned improve visualisation departure times cancelled vs. non-cancelled flights.variable diamonds dataset important predicting price diamond?\nvariable correlated cut?\ncombination two relationships lead lower quality diamonds expensive?variable diamonds dataset important predicting price diamond?\nvariable correlated cut?\ncombination two relationships lead lower quality diamonds expensive?Exchange x variable y variable vertical boxplot, create horizontal boxplot.\ncompare using coord_flip()?Exchange x variable y variable vertical boxplot, create horizontal boxplot.\ncompare using coord_flip()?One problem boxplots developed era much smaller datasets tend display prohibitively large number “outlying values”.\nOne approach remedy problem letter value plot.\nInstall lvplot package, try using geom_lv() display distribution price vs cut.\nlearn?\ninterpret plots?One problem boxplots developed era much smaller datasets tend display prohibitively large number “outlying values”.\nOne approach remedy problem letter value plot.\nInstall lvplot package, try using geom_lv() display distribution price vs cut.\nlearn?\ninterpret plots?Compare contrast geom_violin() facetted geom_histogram(), coloured geom_freqpoly().\npros cons method?Compare contrast geom_violin() facetted geom_histogram(), coloured geom_freqpoly().\npros cons method?small dataset, ’s sometimes useful use geom_jitter() see relationship continuous categorical variable.\nggbeeswarm package provides number methods similar geom_jitter().\nList briefly describe one .small dataset, ’s sometimes useful use geom_jitter() see relationship continuous categorical variable.\nggbeeswarm package provides number methods similar geom_jitter().\nList briefly describe one .","code":""},{"path":"exploratory-data-analysis.html","id":"two-categorical-variables","chapter":"10 Exploratory Data Analysis","heading":"10.5.2 Two categorical variables","text":"visualise covariation categorical variables, ’ll need count number observations combination.\nOne way rely built-geom_count():size circle plot displays many observations occurred combination values.\nCovariation appear strong correlation specific x values specific y values.Another approach compute count dplyr:visualise geom_tile() fill aesthetic:categorical variables unordered, might want use seriation package simultaneously reorder rows columns order clearly reveal interesting patterns.\nlarger plots, might want try heatmaply package, creates interactive plots.","code":"\nggplot(data = diamonds) +\n  geom_count(mapping = aes(x = cut, y = color))\ndiamonds %>% \n  count(color, cut)\n#> <U+2029>[90m# A tibble: 35 x 3<U+2029>[39mNA#>   <U+2029>[1mcolor<U+2029>[22m <U+2029>[1mcut<U+2029>[22m           <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<ord><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<ord><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m D     Fair        163NA#> <U+2029>[90m2<U+2029>[39m D     Good        662NA#> <U+2029>[90m3<U+2029>[39m D     Very Good  <U+2029>[4m1<U+2029>[24m513NA#> <U+2029>[90m4<U+2029>[39m D     Premium    <U+2029>[4m1<U+2029>[24m603NA#> <U+2029>[90m5<U+2029>[39m D     Ideal      <U+2029>[4m2<U+2029>[24m834NA#> <U+2029>[90m6<U+2029>[39m E     Fair        224NA#> <U+2029>[90m# ... with 29 more rows<U+2029>[39mNA\ndiamonds %>% \n  count(color, cut) %>%  \n  ggplot(mapping = aes(x = color, y = cut)) +\n    geom_tile(mapping = aes(fill = n))"},{"path":"exploratory-data-analysis.html","id":"exercises-20","chapter":"10 Exploratory Data Analysis","heading":"10.5.2.1 Exercises","text":"rescale count dataset clearly show distribution cut within colour, colour within cut?rescale count dataset clearly show distribution cut within colour, colour within cut?Use geom_tile() together dplyr explore average flight delays vary destination month year.\nmakes plot difficult read?\nimprove ?Use geom_tile() together dplyr explore average flight delays vary destination month year.\nmakes plot difficult read?\nimprove ?slightly better use aes(x = color, y = cut) rather aes(x = cut, y = color) example ?slightly better use aes(x = color, y = cut) rather aes(x = cut, y = color) example ?","code":""},{"path":"exploratory-data-analysis.html","id":"two-continuous-variables","chapter":"10 Exploratory Data Analysis","heading":"10.5.3 Two continuous variables","text":"’ve already seen one great way visualise covariation two continuous variables: draw scatterplot geom_point().\ncan see covariation pattern points.\nexample, can see exponential relationship carat size price diamond.Scatterplots become less useful size dataset grows, points begin overplot, pile areas uniform black ().\n’ve already seen one way fix problem: using alpha aesthetic add transparency.using transparency can challenging large datasets.\nAnother solution use bin.\nPreviously used geom_histogram() geom_freqpoly() bin one dimension.\nNow ’ll learn use geom_bin2d() geom_hex() bin two dimensions.geom_bin2d() geom_hex() divide coordinate plane 2d bins use fill color display many points fall bin.\ngeom_bin2d() creates rectangular bins.\ngeom_hex() creates hexagonal bins.\nneed install hexbin package use geom_hex().Another option bin one continuous variable acts like categorical variable.\ncan use one techniques visualising combination categorical continuous variable learned .\nexample, bin carat group, display boxplot:cut_width(x, width), used , divides x bins width width.\ndefault, boxplots look roughly (apart number outliers) regardless many observations , ’s difficult tell boxplot summarises different number points.\nOne way show make width boxplot proportional number points varwidth = TRUE.Another approach display approximately number points bin.\n’s job cut_number():","code":"\nggplot(data = diamonds) +\n  geom_point(mapping = aes(x = carat, y = price))\nggplot(data = diamonds) + \n  geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100)\nggplot(data = smaller) +\n  geom_bin2d(mapping = aes(x = carat, y = price))\n\n# install.packages(\"hexbin\")\nggplot(data = smaller) +\n  geom_hex(mapping = aes(x = carat, y = price))\nggplot(data = smaller, mapping = aes(x = carat, y = price)) + \n  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))\nggplot(data = smaller, mapping = aes(x = carat, y = price)) + \n  geom_boxplot(mapping = aes(group = cut_number(carat, 20)))"},{"path":"exploratory-data-analysis.html","id":"exercises-21","chapter":"10 Exploratory Data Analysis","heading":"10.5.3.1 Exercises","text":"Instead summarising conditional distribution boxplot, use frequency polygon.\nneed consider using cut_width() vs cut_number()?\nimpact visualisation 2d distribution carat price?Instead summarising conditional distribution boxplot, use frequency polygon.\nneed consider using cut_width() vs cut_number()?\nimpact visualisation 2d distribution carat price?Visualise distribution carat, partitioned price.Visualise distribution carat, partitioned price.price distribution large diamonds compare small diamonds?\nexpect, surprise ?price distribution large diamonds compare small diamonds?\nexpect, surprise ?Combine two techniques ’ve learned visualise combined distribution cut, carat, price.Combine two techniques ’ve learned visualise combined distribution cut, carat, price.Two dimensional plots reveal outliers visible one dimensional plots.\nexample, points plot unusual combination x y values, makes points outliers even though x y values appear normal examined separately.\n\nggplot(data = diamonds) +\n  geom_point(mapping = aes(x = x, y = y)) +\n  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))\n\nscatterplot better display binned plot case?Two dimensional plots reveal outliers visible one dimensional plots.\nexample, points plot unusual combination x y values, makes points outliers even though x y values appear normal examined separately.scatterplot better display binned plot case?","code":"\nggplot(data = diamonds) +\n  geom_point(mapping = aes(x = x, y = y)) +\n  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))"},{"path":"exploratory-data-analysis.html","id":"patterns-and-models","chapter":"10 Exploratory Data Analysis","heading":"10.6 Patterns and models","text":"Patterns data provide clues relationships.\nsystematic relationship exists two variables appear pattern data.\nspot pattern, ask :pattern due coincidence (.e. random chance)?pattern due coincidence (.e. random chance)?can describe relationship implied pattern?can describe relationship implied pattern?strong relationship implied pattern?strong relationship implied pattern?variables might affect relationship?variables might affect relationship?relationship change look individual subgroups data?relationship change look individual subgroups data?scatterplot Old Faithful eruption lengths versus wait time eruptions shows pattern: longer wait times associated longer eruptions.\nscatterplot also displays two clusters noticed .Patterns provide one useful tools data scientists reveal covariation.\nthink variation phenomenon creates uncertainty, covariation phenomenon reduces .\ntwo variables covary, can use values one variable make better predictions values second.\ncovariation due causal relationship (special case), can use value one variable control value second.Models tool extracting patterns data.\nexample, consider diamonds data.\n’s hard understand relationship cut price, cut carat, carat price tightly related.\n’s possible use model remove strong relationship price carat can explore subtleties remain.\nfollowing code fits model predicts price carat computes residuals (difference predicted value actual value).\nresiduals give us view price diamond, effect carat removed.’ve removed strong relationship carat price, can see expect relationship cut price: relative size, better quality diamonds expensive.’re discussing modelling book understanding models work easiest tools data wrangling programming hand.","code":"\nggplot(data = faithful) + \n  geom_point(mapping = aes(x = eruptions, y = waiting))\nlibrary(modelr)\n\nmod <- lm(log(price) ~ log(carat), data = diamonds)\n\ndiamonds2 <- diamonds %>% \n  add_residuals(mod) %>% \n  mutate(resid = exp(resid))\n\nggplot(data = diamonds2) + \n  geom_point(mapping = aes(x = carat, y = resid))\nggplot(data = diamonds2) + \n  geom_boxplot(mapping = aes(x = cut, y = resid))"},{"path":"exploratory-data-analysis.html","id":"ggplot2-calls","chapter":"10 Exploratory Data Analysis","heading":"10.7 ggplot2 calls","text":"move introductory chapters, ’ll transition concise expression ggplot2 code.\nfar ’ve explicit, helpful learning:Typically, first one two arguments function important know heart.\nfirst two arguments ggplot() data mapping, first two arguments aes() x y.\nremainder book, won’t supply names.\nsaves typing, , reducing amount boilerplate, makes easier see ’s different plots.\n’s really important programming concern ’ll come back Chapter 34.Rewriting previous plot concisely yields:Sometimes ’ll turn end pipeline data transformation plot.\nWatch transition %>% +.\nwish transition wasn’t necessary unfortunately ggplot2 created pipe discovered.","code":"\nggplot(data = faithful, mapping = aes(x = eruptions)) + \n  geom_freqpoly(binwidth = 0.25)\nggplot(faithful, aes(eruptions)) + \n  geom_freqpoly(binwidth = 0.25)\ndiamonds %>% \n  count(cut, clarity) %>% \n  ggplot(aes(clarity, cut, fill = n)) + \n    geom_tile()"},{"path":"exploratory-data-analysis.html","id":"learning-more","chapter":"10 Exploratory Data Analysis","heading":"10.8 Learning more","text":"want learn mechanics ggplot2, ’d highly recommend grabbing copy ggplot2 book: https://amzn.com/331924275X.\n’s recently updated, includes dplyr tidyr code, much space explore facets visualisation.\nUnfortunately book isn’t generally available free, connection university can probably get electronic version free SpringerLink.Another useful resource R Graphics Cookbook Winston Chang.\nMuch contents available online http://www.cookbook-r.com/Graphs/.also recommend Graphical Data Analysis R, Antony Unwin.\nbook-length treatment similar material covered chapter, space go much greater depth.","code":""},{"path":"workflow-projects.html","id":"workflow-projects","chapter":"11 Workflow: projects","heading":"11 Workflow: projects","text":"One day need quit R, go something else return analysis next day.\nOne day working multiple analyses simultaneously use R want keep separate.\nOne day need bring data outside world R send numerical results figures R back world.\nhandle real life situations, need make two decisions:analysis “real”, .e. save lasting record happened?analysis “real”, .e. save lasting record happened?analysis “live”?analysis “live”?","code":""},{"path":"workflow-projects.html","id":"what-is-real","chapter":"11 Workflow: projects","heading":"11.1 What is real?","text":"beginning R user, ’s OK consider environment (.e. objects listed environment pane) “real”.\nHowever, long run, ’ll much better consider R scripts “real”.R scripts (data files), can recreate environment.\n’s much harder recreate R scripts environment!\n’ll either retype lot code memory (making mistakes way) ’ll carefully mine R history.foster behaviour, highly recommend instruct RStudio preserve workspace sessions:cause short-term pain, now restart RStudio remember results code ran last time.\nshort-term pain save long-term agony forces capture important interactions code.\n’s nothing worse discovering three months fact ’ve stored results important calculation workspace, calculation code.great pair keyboard shortcuts work together make sure ’ve captured important parts code editor:Press Cmd/Ctrl + Shift + F10 restart RStudio.Press Cmd/Ctrl + Shift + S rerun current script.use pattern hundreds times week.","code":""},{"path":"workflow-projects.html","id":"where-does-your-analysis-live","chapter":"11 Workflow: projects","heading":"11.2 Where does your analysis live?","text":"R powerful notion working directory.\nR looks files ask load, put files ask save.\nRStudio shows current working directory top console:can print R code running getwd():beginning R user, ’s OK let home directory, documents directory, weird directory computer R’s working directory.\n’re six chapters book, ’re longer rank beginner.\nsoon now evolve organising analytical projects directories , working project, setting R’s working directory associated directory.recommend , can also set working directory within R:never ’s better way; way also puts path managing R work like expert.","code":"\ngetwd()\n#> [1] \"/Users/hadley/Documents/r4ds/r4ds\"\nsetwd(\"/path/to/my/CoolProject\")"},{"path":"workflow-projects.html","id":"paths-and-directories","chapter":"11 Workflow: projects","heading":"11.3 Paths and directories","text":"Paths directories little complicated two basic styles paths: Mac/Linux Windows.\nthree chief ways differ:important difference separate components path.\nMac Linux uses slashes (e.g. plots/diamonds.pdf) Windows uses backslashes (e.g. plots\\diamonds.pdf).\nR can work either type (matter platform ’re currently using), unfortunately, backslashes mean something special R, get single backslash path, need type two backslashes!\nmakes life frustrating, recommend always using Linux/Mac style forward slashes.important difference separate components path.\nMac Linux uses slashes (e.g. plots/diamonds.pdf) Windows uses backslashes (e.g. plots\\diamonds.pdf).\nR can work either type (matter platform ’re currently using), unfortunately, backslashes mean something special R, get single backslash path, need type two backslashes!\nmakes life frustrating, recommend always using Linux/Mac style forward slashes.Absolute paths (.e. paths point place regardless working directory) look different.\nWindows start drive letter (e.g. C:) two backslashes (e.g. \\\\servername) Mac/Linux start slash “/” (e.g. /users/hadley).\nnever use absolute paths scripts, hinder sharing: one else exactly directory configuration .Absolute paths (.e. paths point place regardless working directory) look different.\nWindows start drive letter (e.g. C:) two backslashes (e.g. \\\\servername) Mac/Linux start slash “/” (e.g. /users/hadley).\nnever use absolute paths scripts, hinder sharing: one else exactly directory configuration .last minor difference place ~ points .\n~ convenient shortcut home directory.\nWindows doesn’t really notion home directory, instead points documents directory.last minor difference place ~ points .\n~ convenient shortcut home directory.\nWindows doesn’t really notion home directory, instead points documents directory.","code":""},{"path":"workflow-projects.html","id":"rstudio-projects","chapter":"11 Workflow: projects","heading":"11.4 RStudio projects","text":"R experts keep files associated project together — input data, R scripts, analytical results, figures.\nwise common practice RStudio built-support via projects.Let’s make project use ’re working rest book.\nClick File > New Project, :Call project r4ds think carefully subdirectory put project .\ndon’t store somewhere sensible, hard find future!process complete, ’ll get new RStudio project just book.\nCheck “home” directory project current working directory:Whenever refer file relative path look .Now enter following commands script editor, save file, calling “diamonds.R”.\nNext, run complete script save PDF CSV file project directory.\nDon’t worry details, ’ll learn later book.Quit RStudio.\nInspect folder associated project — notice .Rproj file.\nDouble-click file re-open project.\nNotice get back left : ’s working directory command history, files working still open.\nfollowed instructions , , however, completely fresh environment, guaranteeing ’re starting clean slate.favorite OS-specific way, search computer diamonds.pdf find PDF (surprise) also script created (diamonds.R).\nhuge win!\nOne day want remake figure just understand came .\nrigorously save figures files R code never mouse clipboard, able reproduce old work ease!","code":"\ngetwd()\n#> [1] /Users/hadley/Documents/r4ds/r4ds\nlibrary(tidyverse)\n\nggplot(diamonds, aes(carat, price)) + \n  geom_hex()\nggsave(\"diamonds.pdf\")\n\nwrite_csv(diamonds, \"diamonds.csv\")"},{"path":"workflow-projects.html","id":"summary","chapter":"11 Workflow: projects","heading":"11.5 Summary","text":"summary, RStudio projects give solid workflow serve well future:Create RStudio project data analysis project.Create RStudio project data analysis project.Keep data files ; ’ll talk loading R data import.Keep data files ; ’ll talk loading R data import.Keep scripts ; edit , run bits whole.Keep scripts ; edit , run bits whole.Save outputs (plots cleaned data) .Save outputs (plots cleaned data) .ever use relative paths, absolute paths.ever use relative paths, absolute paths.Everything need one place, cleanly separated projects working .","code":""},{"path":"data-types-intro.html","id":"data-types-intro","chapter":"12 Introduction","heading":"12 Introduction","text":"part book, ’ll learn various types data columns data frame can contain transform .\ntransformations might want apply column vary depending type data ’re working , example text strings might want extract remove certain pieces numerical data, might want rescale .\n’ve already learned little data wrangling previous part.\nNow ’ll focus new skills specific types data frequently encounter practice.part book proceeds follows:Chapter 13, ’ll learn variant data frame use book: tibble. ’ll learn makes different regular data frames, can construct “hand”.Chapter 14 give tools working multiple interrelated datasets.Chapter 16 …Chapter 15 …Chapter 17…Chapter 18 give tools working strings introduce regular expressions, powerful tool manipulating strings.Chapter 18 give tools working strings introduce regular expressions, powerful tool manipulating strings.Chapter 20 introduce factors – R stores categorical data.\nused variable fixed set possible values, want use non-alphabetical ordering string.Chapter 20 introduce factors – R stores categorical data.\nused variable fixed set possible values, want use non-alphabetical ordering string.Chapter 21 give key tools working dates date-times.Chapter 21 give key tools working dates date-times.Chapter 22 give tools performing operation multiple columns.Chapter 22 give tools performing operation multiple columns.","code":""},{"path":"tibbles.html","id":"tibbles","chapter":"13 Tibbles","heading":"13 Tibbles","text":"","code":""},{"path":"tibbles.html","id":"introduction-6","chapter":"13 Tibbles","heading":"13.1 Introduction","text":"Throughout book work “tibbles” instead R’s traditional data.frame.\nTibbles data frames, tweak older behaviours make life little easier.\nR old language, things useful 10 20 years ago now get way.\n’s difficult change base R without breaking existing code, innovation occurs packages.\ndescribe tibble package, provides opinionated data frames make working tidyverse little easier.\nplaces, ’ll use term tibble data frame interchangeably; want draw particular attention R’s built-data frame, ’ll call data.frames.chapter leaves wanting learn tibbles, might enjoy vignette(\"tibble\").","code":""},{"path":"tibbles.html","id":"prerequisites-6","chapter":"13 Tibbles","heading":"13.1.1 Prerequisites","text":"chapter ’ll explore tibble package, part core tidyverse.","code":"\nlibrary(tidyverse)"},{"path":"tibbles.html","id":"creating-tibbles","chapter":"13 Tibbles","heading":"13.2 Creating tibbles","text":"Almost functions ’ll use book produce tibbles, tibbles one unifying features tidyverse.\nR packages use regular data frames, might want coerce data frame tibble.\ncan as_tibble():can create new tibble individual vectors tibble().\ntibble() automatically recycle inputs length 1, allows refer variables just created, shown .’re already familiar data.frame(), note tibble() much less: never changes type inputs (e.g. never converts strings factors!), never changes names variables, never creates row names.’s possible tibble column names valid R variable names, aka non-syntactic names.\nexample, might start letter, might contain unusual characters like space.\nrefer variables, need surround backticks, `:’ll also need backticks working variables packages, like ggplot2, dplyr, tidyr.Another way create tibble tribble(), short transposed tibble.\ntribble() customised data entry code: column headings defined formulas (.e. start ~), entries separated commas.\nmakes possible lay small amounts data easy read form.often add comment (line starting #), make really clear header .","code":"\nas_tibble(mtcars)\n#> <U+2029>[90m# A tibble: 32 x 11<U+2029>[39mNA#>     <U+2029>[1mmpg<U+2029>[22m   <U+2029>[1mcyl<U+2029>[22m  <U+2029>[1mdisp<U+2029>[22m    <U+2029>[1mhp<U+2029>[22m  <U+2029>[1mdrat<U+2029>[22m    <U+2029>[1mwt<U+2029>[22m  <U+2029>[1mqsec<U+2029>[22m    <U+2029>[1mvs<U+2029>[22m    <U+2029>[1mam<U+2029>[22m  <U+2029>[1mgear<U+2029>[22m  <U+2029>[1mcarb<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  21       6   160   110  3.9   2.62  16.5     0     1     4     4NA#> <U+2029>[90m2<U+2029>[39m  21       6   160   110  3.9   2.88  17.0     0     1     4     4NA#> <U+2029>[90m3<U+2029>[39m  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1NA#> <U+2029>[90m4<U+2029>[39m  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1NA#> <U+2029>[90m5<U+2029>[39m  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2NA#> <U+2029>[90m6<U+2029>[39m  18.1     6   225   105  2.76  3.46  20.2     1     0     3     1NA#> <U+2029>[90m# ... with 26 more rows<U+2029>[39mNA\ntibble(\n  x = 1:5, \n  y = 1, \n  z = x ^ 2 + y\n)\n#> <U+2029>[90m# A tibble: 5 x 3<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     1     2NA#> <U+2029>[90m2<U+2029>[39m     2     1     5NA#> <U+2029>[90m3<U+2029>[39m     3     1    10NA#> <U+2029>[90m4<U+2029>[39m     4     1    17NA#> <U+2029>[90m5<U+2029>[39m     5     1    26NA\ntb <- tibble(\n  `:)` = \"smile\", \n  ` ` = \"space\",\n  `2000` = \"number\"\n)\ntb\n#> <U+2029>[90m# A tibble: 1 x 3<U+2029>[39mNA#>   <U+2029>[1m`:)`<U+2029>[22m  <U+2029>[1m` `<U+2029>[22m   <U+2029>[1m`2000`<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m NA#> <U+2029>[90m1<U+2029>[39m smile space numberNA\ntribble(\n  ~x, ~y, ~z,\n  #--|--|----\n  \"a\", 2, 3.6,\n  \"b\", 1, 8.5\n)\n#> <U+2029>[90m# A tibble: 2 x 3<U+2029>[39mNA#>   <U+2029>[1mx<U+2029>[22m         <U+2029>[1my<U+2029>[22m     <U+2029>[1mz<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m a         2   3.6NA#> <U+2029>[90m2<U+2029>[39m b         1   8.5NA"},{"path":"tibbles.html","id":"tibbles-vs.-data.frame","chapter":"13 Tibbles","heading":"13.3 Tibbles vs. data.frame","text":"two main differences usage tibble vs. classic data.frame: printing subsetting.","code":""},{"path":"tibbles.html","id":"printing","chapter":"13 Tibbles","heading":"13.3.1 Printing","text":"Tibbles refined print method shows first 10 rows, columns fit screen.\nmakes much easier work large data.\naddition name, column reports type, nice feature borrowed str():Tibbles designed don’t accidentally overwhelm console print large data frames.\nsometimes need output default display.\noptions can help.First, can explicitly print() data frame control number rows (n) width display.\nwidth = Inf display columns:can also control default print behaviour setting options:options(tibble.print_max = n, tibble.print_min = m): n rows, print m rows.\nUse options(tibble.print_min = Inf) always show rows.options(tibble.print_max = n, tibble.print_min = m): n rows, print m rows.\nUse options(tibble.print_min = Inf) always show rows.Use options(tibble.width = Inf) always print columns, regardless width screen.Use options(tibble.width = Inf) always print columns, regardless width screen.can see complete list options looking package help package?tibble.final option use RStudio’s built-data viewer get scrollable view complete dataset.\nalso often useful end long chain manipulations.","code":"\ntibble(\n  a = lubridate::now() + runif(1e3) * 86400,\n  b = lubridate::today() + runif(1e3) * 30,\n  c = 1:1e3,\n  d = runif(1e3),\n  e = sample(letters, 1e3, replace = TRUE)\n)\n#> <U+2029>[90m# A tibble: 1,000 x 5<U+2029>[39mNA#>   <U+2029>[1ma<U+2029>[22m                   <U+2029>[1mb<U+2029>[22m              <U+2029>[1mc<U+2029>[22m     <U+2029>[1md<U+2029>[22m <U+2029>[1me<U+2029>[22m    NA#>   <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m              <U+2029>[3m<U+2029>[90m<date><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m 2021-09-03 <U+2029>[90m04:31:34<U+2029>[39m 2021-09-10     1 0.368 n    NA#> <U+2029>[90m2<U+2029>[39m 2021-09-03 <U+2029>[90m22:36:44<U+2029>[39m 2021-09-15     2 0.612 l    NA#> <U+2029>[90m3<U+2029>[39m 2021-09-03 <U+2029>[90m17:00:23<U+2029>[39m 2021-09-25     3 0.415 p    NA#> <U+2029>[90m4<U+2029>[39m 2021-09-03 <U+2029>[90m06:21:40<U+2029>[39m 2021-09-24     4 0.212 m    NA#> <U+2029>[90m5<U+2029>[39m 2021-09-03 <U+2029>[90m02:45:57<U+2029>[39m 2021-09-21     5 0.733 i    NA#> <U+2029>[90m6<U+2029>[39m 2021-09-03 <U+2029>[90m13:46:54<U+2029>[39m 2021-09-17     6 0.460 n    NA#> <U+2029>[90m# ... with 994 more rows<U+2029>[39mNA\nnycflights13::flights %>% \n  print(n = 10, width = Inf)\nnycflights13::flights %>% \n  View()"},{"path":"tibbles.html","id":"subsetting","chapter":"13 Tibbles","heading":"13.3.2 Subsetting","text":"far tools ’ve learned worked complete data frames.\nwant pull single variable, need new tools, $ [[.\n[[ can extract name position; $ extracts name little less typing.use pipe, ’ll need use special placeholder .:Alternatively, can use pull() function specifically designed extract variable data frame.\npull() also takes optional name argument specifies column used names named vector.Compared data.frame, tibbles strict: never partial matching, generate warning column trying access exist.","code":"\ndf <- tibble(\n  id = LETTERS[1:5],\n  x  = 1:5,\n  y  = 6:10\n)\n\n# Extract by name\ndf$x\n#> [1] 1 2 3 4 5\ndf[[\"x\"]]\n#> [1] 1 2 3 4 5\n\n# Extract by position\ndf[[1]]\n#> [1] \"A\" \"B\" \"C\" \"D\" \"E\"\ndf %>% .$x\n#> [1] 1 2 3 4 5\ndf %>% .[[\"x\"]]\n#> [1] 1 2 3 4 5\ndf %>% pull(x)\n#> [1] 1 2 3 4 5\ndf %>% pull(x, name = id)\n#> A B C D E \n#> 1 2 3 4 5"},{"path":"tibbles.html","id":"interacting-with-older-code","chapter":"13 Tibbles","heading":"13.4 Interacting with older code","text":"older functions don’t work tibbles.\nencounter one functions, use .data.frame() turn tibble back data.frame:main reason older functions don’t work tibble [ function.\ndon’t use [ much book dplyr::filter() dplyr::select() allow solve problems clearer code (learn little vector subsetting).\nbase R data frames, [ sometimes returns data frame, sometimes returns vector.\ntibbles, [ always returns another tibble.","code":"\nclass(as.data.frame(tb))\n#> [1] \"data.frame\""},{"path":"tibbles.html","id":"exercises-22","chapter":"13 Tibbles","heading":"13.5 Exercises","text":"can tell object tibble?\n(Hint: try printing mtcars, regular data frame).can tell object tibble?\n(Hint: try printing mtcars, regular data frame).Compare contrast following operations data.frame equivalent tibble.\ndifferent?\nmight default data frame behaviours cause frustration?\n\ndf <- data.frame(abc = 1, xyz = \"\")\ndf$x\ndf[, \"xyz\"]\ndf[, c(\"abc\", \"xyz\")]Compare contrast following operations data.frame equivalent tibble.\ndifferent?\nmight default data frame behaviours cause frustration?name variable stored object, e.g. var <- \"mpg\", can extract reference variable tibble?name variable stored object, e.g. var <- \"mpg\", can extract reference variable tibble?Practice referring non-syntactic names following data frame :\nExtracting variable called 1.\nPlotting scatterplot 1 vs 2.\nCreating new column called 3 2 divided 1.\nRenaming columns one, two three.\n\nannoying <- tibble(\n  `1` = 1:10,\n  `2` = `1` * 2 + rnorm(length(`1`))\n)Practice referring non-syntactic names following data frame :Extracting variable called 1.Plotting scatterplot 1 vs 2.Creating new column called 3 2 divided 1.Renaming columns one, two three.tibble::enframe() ?\nmight use ?tibble::enframe() ?\nmight use ?option controls many additional column names printed footer tibble?option controls many additional column names printed footer tibble?","code":"\ndf <- data.frame(abc = 1, xyz = \"a\")\ndf$x\ndf[, \"xyz\"]\ndf[, c(\"abc\", \"xyz\")]\nannoying <- tibble(\n  `1` = 1:10,\n  `2` = `1` * 2 + rnorm(length(`1`))\n)"},{"path":"relational-data.html","id":"relational-data","chapter":"14 Relational data","heading":"14 Relational data","text":"","code":""},{"path":"relational-data.html","id":"introduction-7","chapter":"14 Relational data","heading":"14.1 Introduction","text":"’s rare data analysis involves single data frame.\nTypically many data frames, must combine answer questions ’re interested .\nCollectively, multiple data frames called relational data relations, just individual datasets, important.Relations always defined pair data frames.\nrelations built simple idea: relations three data frames always property relations pair.\nSometimes elements pair can data frame!\nneeded , example, data frame people, person reference parents.work relational data need verbs work pairs data frames.\nthree families verbs designed work relational data:Mutating joins, add new variables one data frame matching observations another.Mutating joins, add new variables one data frame matching observations another.Filtering joins, filter observations one data frame based whether match observation data frame.Filtering joins, filter observations one data frame based whether match observation data frame.Set operations, treat observations set elements.Set operations, treat observations set elements.common place find relational data relational database management system (RDBMS), term encompasses almost modern databases.\n’ve used database , ’ve almost certainly used SQL.\n, find concepts chapter familiar, although expression dplyr little different.\nOne major terminology difference databases R generally refer data frames R concept referred “table” databases.\nHence ’ll see references one-table two-table verbs dplyr documentation.\nGenerally, dplyr little easier use SQL dplyr specialised data analysis: makes common data analysis operations easier, expense making difficult things aren’t commonly needed data analysis.","code":""},{"path":"relational-data.html","id":"prerequisites-7","chapter":"14 Relational data","heading":"14.1.1 Prerequisites","text":"explore relational data nycflights13 using two-table verbs dplyr.","code":"\nlibrary(tidyverse)\nlibrary(nycflights13)"},{"path":"relational-data.html","id":"nycflights13-relational","chapter":"14 Relational data","heading":"14.2 nycflights13","text":"use nycflights13 package learn relational data.\nnycflights13 contains five tibbles : airlines, airports, weather planes related flights data frame used Chapter 5 data transformation:airlines lets look full carrier name abbreviated code:\n\nairlines\n#> <U+2029>[90m# tibble: 16 x 2<U+2029>[39mNA#>   <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mname<U+2029>[22m                    NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                   NA#> <U+2029>[90m1<U+2029>[39m 9E      Endeavor Air Inc.       NA#> <U+2029>[90m2<U+2029>[39m AA      American Airlines Inc.  NA#> <U+2029>[90m3<U+2029>[39m      Alaska Airlines Inc.    NA#> <U+2029>[90m4<U+2029>[39m B6      JetBlue Airways         NA#> <U+2029>[90m5<U+2029>[39m DL      Delta Air Lines Inc.    NA#> <U+2029>[90m6<U+2029>[39m EV      ExpressJet Airlines Inc.NA#> <U+2029>[90m# ... 10 rows<U+2029>[39mNAairlines lets look full carrier name abbreviated code:airports gives information airport, identified faa airport code:\n\nairports\n#> <U+2029>[90m# tibble: 1,458 x 8<U+2029>[39mNA#>   <U+2029>[1mfaa<U+2029>[22m   <U+2029>[1mname<U+2029>[22m                             <U+2029>[1mlat<U+2029>[22m   <U+2029>[1mlon<U+2029>[22m   <U+2029>[1malt<U+2029>[22m    <U+2029>[1mtz<U+2029>[22m <U+2029>[1mdst<U+2029>[22m   <U+2029>[1mtzone<U+2029>[22m      NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                          <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m      NA#> <U+2029>[90m1<U+2029>[39m 04G   Lansdowne Airport               41.1 -<U+2029>[31m80<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m6<U+2029>[39m  <U+2029>[4m1<U+2029>[24m044    -<U+2029>[31m5<U+2029>[39m     America/Ne~NA#> <U+2029>[90m2<U+2029>[39m 06A   Moton Field Municipal Airport   32.5 -<U+2029>[31m85<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m7<U+2029>[39m   264    -<U+2029>[31m6<U+2029>[39m     America/Ch~NA#> <U+2029>[90m3<U+2029>[39m 06C   Schaumburg Regional             42.0 -<U+2029>[31m88<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m1<U+2029>[39m   801    -<U+2029>[31m6<U+2029>[39m     America/Ch~NA#> <U+2029>[90m4<U+2029>[39m 06N   Randall Airport                 41.4 -<U+2029>[31m74<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m4<U+2029>[39m   523    -<U+2029>[31m5<U+2029>[39m     America/Ne~NA#> <U+2029>[90m5<U+2029>[39m 09J   Jekyll Island Airport           31.1 -<U+2029>[31m81<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m4<U+2029>[39m    11    -<U+2029>[31m5<U+2029>[39m     America/Ne~NA#> <U+2029>[90m6<U+2029>[39m 0A9   Elizabethton Municipal Airport  36.4 -<U+2029>[31m82<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m2<U+2029>[39m  <U+2029>[4m1<U+2029>[24m593    -<U+2029>[31m5<U+2029>[39m     America/Ne~NA#> <U+2029>[90m# ... 1,452 rows<U+2029>[39mNAairports gives information airport, identified faa airport code:planes gives information plane, identified tailnum:\n\nplanes\n#> <U+2029>[90m# tibble: 3,322 x 9<U+2029>[39mNA#>   <U+2029>[1mtailnum<U+2029>[22m  <U+2029>[1myear<U+2029>[22m <U+2029>[1mtype<U+2029>[22m           <U+2029>[1mmanufacturer<U+2029>[22m   <U+2029>[1mmodel<U+2029>[22m  <U+2029>[1mengines<U+2029>[22m <U+2029>[1mseats<U+2029>[22m <U+2029>[1mspeed<U+2029>[22m <U+2029>[1mengine<U+2029>[22m NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  NA#> <U+2029>[90m1<U+2029>[39m N10156   <U+2029>[4m2<U+2029>[24m004 Fixed wing mu~ EMBRAER        EMB-1~       2    55    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m2<U+2029>[39m N102UW   <U+2029>[4m1<U+2029>[24m998 Fixed wing mu~ AIRBUS INDUST~ A320-~       2   182    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m3<U+2029>[39m N103US   <U+2029>[4m1<U+2029>[24m999 Fixed wing mu~ AIRBUS INDUST~ A320-~       2   182    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m4<U+2029>[39m N104UW   <U+2029>[4m1<U+2029>[24m999 Fixed wing mu~ AIRBUS INDUST~ A320-~       2   182    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m5<U+2029>[39m N10575   <U+2029>[4m2<U+2029>[24m002 Fixed wing mu~ EMBRAER        EMB-1~       2    55    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m6<U+2029>[39m N105UW   <U+2029>[4m1<U+2029>[24m999 Fixed wing mu~ AIRBUS INDUST~ A320-~       2   182    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m# ... 3,316 rows<U+2029>[39mNAplanes gives information plane, identified tailnum:weather gives weather NYC airport hour:\n\nweather\n#> <U+2029>[90m# tibble: 26,115 x 15<U+2029>[39mNA#>   <U+2029>[1morigin<U+2029>[22m  <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m  <U+2029>[1mtemp<U+2029>[22m  <U+2029>[1mdewp<U+2029>[22m <U+2029>[1mhumid<U+2029>[22m <U+2029>[1mwind_dir<U+2029>[22m <U+2029>[1mwind_speed<U+2029>[22m <U+2029>[1mwind_gust<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     1  39.0  26.1  59.4      270      10.4         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     2  39.0  27.0  61.6      250       8.06        <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     3  39.0  28.0  64.4      240      11.5         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     4  39.9  28.0  62.2      250      12.7         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     5  39.0  28.0  64.4      260      12.7         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     6  37.9  28.0  67.2      240      11.5         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m# ... 26,109 rows, 4 variables: <U+2029>[1mprecip<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mpressure<U+2029>[22m <dbl>, <U+2029>[1mvisib<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNAweather gives weather NYC airport hour:One way show relationships different data frames diagram:diagram little overwhelming, ’s simple compared ’ll see wild!\nkey understanding diagrams like remember relation always concerns pair data frames.\ndon’t need understand whole thing; just need understand chain relations data frames interested .nycflights13:flights connects planes via single variable, tailnum.flights connects planes via single variable, tailnum.flights connects airlines carrier variable.flights connects airlines carrier variable.flights connects airports two ways: via origin dest variables.flights connects airports two ways: via origin dest variables.flights connects weather via origin (location), year, month, day hour (time).flights connects weather via origin (location), year, month, day hour (time).","code":"\nairlines\n#> <U+2029>[90m# A tibble: 16 x 2<U+2029>[39mNA#>   <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mname<U+2029>[22m                    NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                   NA#> <U+2029>[90m1<U+2029>[39m 9E      Endeavor Air Inc.       NA#> <U+2029>[90m2<U+2029>[39m AA      American Airlines Inc.  NA#> <U+2029>[90m3<U+2029>[39m AS      Alaska Airlines Inc.    NA#> <U+2029>[90m4<U+2029>[39m B6      JetBlue Airways         NA#> <U+2029>[90m5<U+2029>[39m DL      Delta Air Lines Inc.    NA#> <U+2029>[90m6<U+2029>[39m EV      ExpressJet Airlines Inc.NA#> <U+2029>[90m# ... with 10 more rows<U+2029>[39mNA\nairports\n#> <U+2029>[90m# A tibble: 1,458 x 8<U+2029>[39mNA#>   <U+2029>[1mfaa<U+2029>[22m   <U+2029>[1mname<U+2029>[22m                             <U+2029>[1mlat<U+2029>[22m   <U+2029>[1mlon<U+2029>[22m   <U+2029>[1malt<U+2029>[22m    <U+2029>[1mtz<U+2029>[22m <U+2029>[1mdst<U+2029>[22m   <U+2029>[1mtzone<U+2029>[22m      NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                          <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m      NA#> <U+2029>[90m1<U+2029>[39m 04G   Lansdowne Airport               41.1 -<U+2029>[31m80<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m6<U+2029>[39m  <U+2029>[4m1<U+2029>[24m044    -<U+2029>[31m5<U+2029>[39m A     America/Ne~NA#> <U+2029>[90m2<U+2029>[39m 06A   Moton Field Municipal Airport   32.5 -<U+2029>[31m85<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m7<U+2029>[39m   264    -<U+2029>[31m6<U+2029>[39m A     America/Ch~NA#> <U+2029>[90m3<U+2029>[39m 06C   Schaumburg Regional             42.0 -<U+2029>[31m88<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m1<U+2029>[39m   801    -<U+2029>[31m6<U+2029>[39m A     America/Ch~NA#> <U+2029>[90m4<U+2029>[39m 06N   Randall Airport                 41.4 -<U+2029>[31m74<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m4<U+2029>[39m   523    -<U+2029>[31m5<U+2029>[39m A     America/Ne~NA#> <U+2029>[90m5<U+2029>[39m 09J   Jekyll Island Airport           31.1 -<U+2029>[31m81<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m4<U+2029>[39m    11    -<U+2029>[31m5<U+2029>[39m A     America/Ne~NA#> <U+2029>[90m6<U+2029>[39m 0A9   Elizabethton Municipal Airport  36.4 -<U+2029>[31m82<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m2<U+2029>[39m  <U+2029>[4m1<U+2029>[24m593    -<U+2029>[31m5<U+2029>[39m A     America/Ne~NA#> <U+2029>[90m# ... with 1,452 more rows<U+2029>[39mNA\nplanes\n#> <U+2029>[90m# A tibble: 3,322 x 9<U+2029>[39mNA#>   <U+2029>[1mtailnum<U+2029>[22m  <U+2029>[1myear<U+2029>[22m <U+2029>[1mtype<U+2029>[22m           <U+2029>[1mmanufacturer<U+2029>[22m   <U+2029>[1mmodel<U+2029>[22m  <U+2029>[1mengines<U+2029>[22m <U+2029>[1mseats<U+2029>[22m <U+2029>[1mspeed<U+2029>[22m <U+2029>[1mengine<U+2029>[22m NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  NA#> <U+2029>[90m1<U+2029>[39m N10156   <U+2029>[4m2<U+2029>[24m004 Fixed wing mu~ EMBRAER        EMB-1~       2    55    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m2<U+2029>[39m N102UW   <U+2029>[4m1<U+2029>[24m998 Fixed wing mu~ AIRBUS INDUST~ A320-~       2   182    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m3<U+2029>[39m N103US   <U+2029>[4m1<U+2029>[24m999 Fixed wing mu~ AIRBUS INDUST~ A320-~       2   182    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m4<U+2029>[39m N104UW   <U+2029>[4m1<U+2029>[24m999 Fixed wing mu~ AIRBUS INDUST~ A320-~       2   182    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m5<U+2029>[39m N10575   <U+2029>[4m2<U+2029>[24m002 Fixed wing mu~ EMBRAER        EMB-1~       2    55    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m6<U+2029>[39m N105UW   <U+2029>[4m1<U+2029>[24m999 Fixed wing mu~ AIRBUS INDUST~ A320-~       2   182    <U+2029>[31mNA<U+2029>[39m Turbo-~NA#> <U+2029>[90m# ... with 3,316 more rows<U+2029>[39mNA\nweather\n#> <U+2029>[90m# A tibble: 26,115 x 15<U+2029>[39mNA#>   <U+2029>[1morigin<U+2029>[22m  <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m  <U+2029>[1mtemp<U+2029>[22m  <U+2029>[1mdewp<U+2029>[22m <U+2029>[1mhumid<U+2029>[22m <U+2029>[1mwind_dir<U+2029>[22m <U+2029>[1mwind_speed<U+2029>[22m <U+2029>[1mwind_gust<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     1  39.0  26.1  59.4      270      10.4         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     2  39.0  27.0  61.6      250       8.06        <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     3  39.0  28.0  64.4      240      11.5         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     4  39.9  28.0  62.2      250      12.7         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     5  39.0  28.0  64.4      260      12.7         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m EWR     <U+2029>[4m2<U+2029>[24m013     1     1     6  37.9  28.0  67.2      240      11.5         <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m# ... with 26,109 more rows, and 4 more variables: <U+2029>[1mprecip<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mpressure<U+2029>[22m <dbl>, <U+2029>[1mvisib<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA"},{"path":"relational-data.html","id":"exercises-23","chapter":"14 Relational data","heading":"14.2.1 Exercises","text":"Imagine wanted draw (approximately) route plane flies origin destination.\nvariables need?\ndata frames need combine?Imagine wanted draw (approximately) route plane flies origin destination.\nvariables need?\ndata frames need combine?forgot draw relationship weather airports.\nrelationship appear diagram?forgot draw relationship weather airports.\nrelationship appear diagram?weather contains information origin (NYC) airports.\ncontained weather records airports USA, additional relation define flights?weather contains information origin (NYC) airports.\ncontained weather records airports USA, additional relation define flights?","code":""},{"path":"relational-data.html","id":"keys","chapter":"14 Relational data","heading":"14.3 Keys","text":"variables used connect pair data frames called keys.\nkey variable (set variables) uniquely identifies observation.\nsimple cases, single variable sufficient identify observation.\nexample, plane uniquely identified tailnum.\ncases, multiple variables may needed.\nexample, identify observation weather need five variables: year, month, day, hour, origin.two types keys:primary key uniquely identifies observation data frame.\nexample, planes$tailnum primary key uniquely identifies plane planes data frame.primary key uniquely identifies observation data frame.\nexample, planes$tailnum primary key uniquely identifies plane planes data frame.foreign key uniquely identifies observation another data frame.\nexample, flights$tailnum foreign key appears flights data frame matches flight unique plane.foreign key uniquely identifies observation another data frame.\nexample, flights$tailnum foreign key appears flights data frame matches flight unique plane.variable can primary key foreign key.\nexample, origin part weather primary key, also foreign key airports data frame.’ve identified primary keys data frames, ’s good practice verify indeed uniquely identify observation.\nOne way count() primary keys look entries n greater one:Sometimes data frame doesn’t explicit primary key: row observation, combination variables reliably identifies .\nexample, ’s primary key flights data frame?\nmight think date plus flight tail number, neither unique:starting work data, naively assumed flight number used per day: make much easier communicate problems specific flight.\nUnfortunately case!\ndata frame lacks primary key, ’s sometimes useful add one mutate() row_number().\nmakes easier match observations ’ve done filtering want check back original data.\ncalled surrogate key.primary key corresponding foreign key another data frame form relation.\nRelations typically one--many.\nexample, flight one plane, plane many flights.\ndata, ’ll occasionally see 1--1 relationship.\ncan think special case 1--many.\ncan model many--many relations many--1 relation plus 1--many relation.\nexample, data ’s many--many relationship airlines airports: airline flies many airports; airport hosts many airlines.","code":"\nplanes %>% \n  count(tailnum) %>% \n  filter(n > 1)\n#> <U+2029>[90m# A tibble: 0 x 2<U+2029>[39mNA#> <U+2029>[90m# ... with 2 variables: <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1mn<U+2029>[22m <int><U+2029>[39mNAweather %>% \n  count(year, month, day, hour, origin) %>% \n  filter(n > 1)\n#> <U+2029>[90m# A tibble: 3 x 6<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013    11     3     1 EWR        2NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013    11     3     1 JFK        2NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013    11     3     1 LGA        2NA\nflights %>% \n  count(year, month, day, flight) %>% \n  filter(n > 1)\n#> <U+2029>[90m# A tibble: 29,768 x 5<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mflight<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      1     2NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      3     2NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      4     2NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     11     3NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     15     2NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     21     2NA#> <U+2029>[90m# ... with 29,762 more rows<U+2029>[39mNAflights %>% \n  count(year, month, day, tailnum) %>% \n  filter(n > 1)\n#> <U+2029>[90m# A tibble: 64,928 x 5<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mtailnum<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 N0EGMQ      2NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 N11189      2NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 N11536      2NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 N11544      3NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 N11551      2NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 N12540      2NA#> <U+2029>[90m# ... with 64,922 more rows<U+2029>[39mNA"},{"path":"relational-data.html","id":"exercises-24","chapter":"14 Relational data","heading":"14.3.1 Exercises","text":"Add surrogate key flights.Add surrogate key flights.know days year “special”, fewer people usual fly .\nmight represent data data frame?\nprimary keys data frame?\nconnect existing data frames?know days year “special”, fewer people usual fly .\nmight represent data data frame?\nprimary keys data frame?\nconnect existing data frames?Identify keys following datasets\nLahman::Batting\nbabynames::babynames\nnasaweather::atmos\nfueleconomy::vehicles\nggplot2::diamonds\n(might need install packages read documentation.)Identify keys following datasetsLahman::Battingbabynames::babynamesnasaweather::atmosfueleconomy::vehiclesggplot2::diamonds(might need install packages read documentation.)Draw diagram illustrating connections Batting, People, Salaries data frames Lahman package.\nDraw another diagram shows relationship People, Managers, AwardsManagers.\ncharacterise relationship Batting, Pitching, Fielding data frames?Draw diagram illustrating connections Batting, People, Salaries data frames Lahman package.\nDraw another diagram shows relationship People, Managers, AwardsManagers.characterise relationship Batting, Pitching, Fielding data frames?","code":""},{"path":"relational-data.html","id":"mutating-joins","chapter":"14 Relational data","heading":"14.4 Mutating joins","text":"first tool ’ll look combining pair data frames mutating join.\nmutating join allows combine variables two data frames.\nfirst matches observations keys, copies across variables one data frame .Like mutate(), join functions add variables right, lot variables already, new variables won’t get printed .\nexamples, ’ll make easier see ’s going examples creating narrower dataset:(Remember, ’re RStudio, can also use View() avoid problem.)Imagine want add full airline name flights2 data.\ncan combine airlines flights2 data frames left_join():result joining airlines flights2 additional variable: name.\ncall type join mutating join.\ncase, got place using mutate() R’s base subsetting:hard generalise need match multiple variables, takes close reading figure overall intent.following sections explain, detail, mutating joins work.\n’ll start learning useful visual representation joins.\n’ll use explain four mutating join functions: inner join, three outer joins.\nworking real data, keys don’t always uniquely identify observations, next ’ll talk happens isn’t unique match.\nFinally, ’ll learn tell dplyr variables keys given join.","code":"\nflights2 <- flights %>% \n  select(year:day, hour, origin, dest, tailnum, carrier)\nflights2\n#> <U+2029>[90m# A tibble: 336,776 x 8<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  NA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA     NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA     NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA     NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6     NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL     NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA     NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA\nflights2 %>%\n  select(-origin, -dest) %>% \n  left_join(airlines, by = \"carrier\")\n#> <U+2029>[90m# A tibble: 336,776 x 7<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mname<U+2029>[22m                  NA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                 NA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N14228  UA      United Air Lines Inc. NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N24211  UA      United Air Lines Inc. NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N619AA  AA      American Airlines Inc.NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N804JB  B6      JetBlue Airways       NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 N668DN  DL      Delta Air Lines Inc.  NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N39463  UA      United Air Lines Inc. NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA\nflights2 %>%\n  select(-origin, -dest) %>% \n  mutate(name = airlines$name[match(carrier, airlines$carrier)])\n#> <U+2029>[90m# A tibble: 336,776 x 7<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mname<U+2029>[22m                  NA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                 NA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N14228  UA      United Air Lines Inc. NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N24211  UA      United Air Lines Inc. NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N619AA  AA      American Airlines Inc.NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N804JB  B6      JetBlue Airways       NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 N668DN  DL      Delta Air Lines Inc.  NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 N39463  UA      United Air Lines Inc. NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA"},{"path":"relational-data.html","id":"understanding-joins","chapter":"14 Relational data","heading":"14.4.1 Understanding joins","text":"help learn joins work, ’m going use visual representation:coloured column represents “key” variable: used match rows data frames.\ngrey column represents “value” column carried along ride.\nexamples ’ll show single key variable, idea generalises straightforward way multiple keys multiple values.join way connecting row x zero, one, rows y.\nfollowing diagram shows potential match intersection pair lines.(look closely, might notice ’ve switched order key value columns x. emphasise joins match based key; value just carried along ride.)actual join, matches indicated dots.\nnumber dots = number matches = number rows output.","code":"\nx <- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     3, \"x3\"\n)\ny <- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\",\n     4, \"y3\"\n)"},{"path":"relational-data.html","id":"inner-join","chapter":"14 Relational data","heading":"14.4.2 Inner join","text":"simplest type join inner join.\ninner join matches pairs observations whenever keys equal:(precise, inner equijoin keys matched using equality operator. Since joins equijoins usually drop specification.)output inner join new data frame contains key, x values, y values.\nuse tell dplyr variable key:important property inner join unmatched rows included result.\nmeans generally inner joins usually appropriate use analysis ’s easy lose observations.","code":"\nx %>% \n  inner_join(y, by = \"key\")\n#> <U+2029>[90m# A tibble: 2 x 3<U+2029>[39mNA#>     <U+2029>[1mkey<U+2029>[22m <U+2029>[1mval_x<U+2029>[22m <U+2029>[1mval_y<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1 x1    y1   NA#> <U+2029>[90m2<U+2029>[39m     2 x2    y2NA"},{"path":"relational-data.html","id":"outer-join","chapter":"14 Relational data","heading":"14.4.3 Outer joins","text":"inner join keeps observations appear data frames.\nouter join keeps observations appear least one data frames.\nthree types outer joins:left join keeps observations x.right join keeps observations y.full join keeps observations x y.joins work adding additional “virtual” observation data frame.\nobservation key always matches (key matches), value filled NA.Graphically, looks like:commonly used join left join: use whenever look additional data another data frame, preserves original observations even isn’t match.\nleft join default join: use unless strong reason prefer one others.Another way depict different types joins Venn diagram:However, great representation.\nmight jog memory join preserves observations data frame, suffers major limitation: Venn diagram can’t show happens keys don’t uniquely identify observation.","code":""},{"path":"relational-data.html","id":"join-matches","chapter":"14 Relational data","heading":"14.4.4 Duplicate keys","text":"far diagrams assumed keys unique.\n’s always case.\nsection explains happens keys unique.\ntwo possibilities:One data frame duplicate keys.\nuseful want add additional information typically one--many relationship.\n\nNote ’ve put key column slightly different position output.\nreflects key primary key y foreign key x.\n\nx <- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     2, \"x3\",\n     1, \"x4\"\n)\ny <- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\"\n)\nleft_join(x, y, = \"key\")\n#> <U+2029>[90m# tibble: 4 x 3<U+2029>[39mNA#>     <U+2029>[1mkey<U+2029>[22m <U+2029>[1mval_x<U+2029>[22m <U+2029>[1mval_y<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1 x1    y1   NA#> <U+2029>[90m2<U+2029>[39m     2 x2    y2   NA#> <U+2029>[90m3<U+2029>[39m     2 x3    y2   NA#> <U+2029>[90m4<U+2029>[39m     1 x4    y1NAOne data frame duplicate keys.\nuseful want add additional information typically one--many relationship.Note ’ve put key column slightly different position output.\nreflects key primary key y foreign key x.data frames duplicate keys.\nusually error neither data frame keys uniquely identify observation.\njoin duplicated keys, get possible combinations, Cartesian product:\n\n\nx <- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     2, \"x3\",\n     3, \"x4\"\n)\ny <- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\",\n     2, \"y3\",\n     3, \"y4\"\n)\nleft_join(x, y, = \"key\")\n#> <U+2029>[90m# tibble: 6 x 3<U+2029>[39mNA#>     <U+2029>[1mkey<U+2029>[22m <U+2029>[1mval_x<U+2029>[22m <U+2029>[1mval_y<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1 x1    y1   NA#> <U+2029>[90m2<U+2029>[39m     2 x2    y2   NA#> <U+2029>[90m3<U+2029>[39m     2 x2    y3   NA#> <U+2029>[90m4<U+2029>[39m     2 x3    y2   NA#> <U+2029>[90m5<U+2029>[39m     2 x3    y3   NA#> <U+2029>[90m6<U+2029>[39m     3 x4    y4NABoth data frames duplicate keys.\nusually error neither data frame keys uniquely identify observation.\njoin duplicated keys, get possible combinations, Cartesian product:","code":"\nx <- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     2, \"x3\",\n     1, \"x4\"\n)\ny <- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\"\n)\nleft_join(x, y, by = \"key\")\n#> <U+2029>[90m# A tibble: 4 x 3<U+2029>[39mNA#>     <U+2029>[1mkey<U+2029>[22m <U+2029>[1mval_x<U+2029>[22m <U+2029>[1mval_y<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1 x1    y1   NA#> <U+2029>[90m2<U+2029>[39m     2 x2    y2   NA#> <U+2029>[90m3<U+2029>[39m     2 x3    y2   NA#> <U+2029>[90m4<U+2029>[39m     1 x4    y1NA\nx <- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     2, \"x3\",\n     3, \"x4\"\n)\ny <- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\",\n     2, \"y3\",\n     3, \"y4\"\n)\nleft_join(x, y, by = \"key\")\n#> <U+2029>[90m# A tibble: 6 x 3<U+2029>[39mNA#>     <U+2029>[1mkey<U+2029>[22m <U+2029>[1mval_x<U+2029>[22m <U+2029>[1mval_y<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1 x1    y1   NA#> <U+2029>[90m2<U+2029>[39m     2 x2    y2   NA#> <U+2029>[90m3<U+2029>[39m     2 x2    y3   NA#> <U+2029>[90m4<U+2029>[39m     2 x3    y2   NA#> <U+2029>[90m5<U+2029>[39m     2 x3    y3   NA#> <U+2029>[90m6<U+2029>[39m     3 x4    y4NA"},{"path":"relational-data.html","id":"join-by","chapter":"14 Relational data","heading":"14.4.5 Defining the key columns","text":"far, pairs data frames always joined single variable, variable name data frames.\nconstraint encoded = \"key\".\ncan use values connect data frames ways:default, = NULL, uses variables appear data frames, called natural join.\nexample, flights weather data frames match common variables: year, month, day, hour origin.\n\nflights2 %>% \n  left_join(weather)\n#> Joining, = c(\"year\", \"month\", \"day\", \"hour\", \"origin\")\n#> <U+2029>[90m# tibble: 336,776 x 18<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m  <U+2029>[1mtemp<U+2029>[22m  <U+2029>[1mdewp<U+2029>[22m <U+2029>[1mhumid<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA       39.0  28.0  64.4NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA       39.9  25.0  54.8NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA       39.0  27.0  61.6NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6       39.0  27.0  61.6NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL       39.9  25.0  54.8NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA       39.0  28.0  64.4NA#> <U+2029>[90m# ... 336,770 rows, 7 variables: <U+2029>[1mwind_dir<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mwind_speed<U+2029>[22m <dbl>, <U+2029>[1mwind_gust<U+2029>[22m <dbl>, <U+2029>[1mprecip<U+2029>[22m <dbl>, <U+2029>[1mpressure<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mvisib<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNAThe default, = NULL, uses variables appear data frames, called natural join.\nexample, flights weather data frames match common variables: year, month, day, hour origin.character vector, = \"x\".\nlike natural join, uses common variables.\nexample, flights planes year variables, mean different things want join tailnum.\n\nflights2 %>% \n  left_join(planes, = \"tailnum\")\n#> <U+2029>[90m# tibble: 336,776 x 16<U+2029>[39mNA#>   <U+2029>[1myear.x<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1myear.y<U+2029>[22m <U+2029>[1mtype<U+2029>[22m             NA#>    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m            NA#> <U+2029>[90m1<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA        <U+2029>[4m1<U+2029>[24m999 Fixed wing multi~NA#> <U+2029>[90m2<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA        <U+2029>[4m1<U+2029>[24m998 Fixed wing multi~NA#> <U+2029>[90m3<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA        <U+2029>[4m1<U+2029>[24m990 Fixed wing multi~NA#> <U+2029>[90m4<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6        <U+2029>[4m2<U+2029>[24m012 Fixed wing multi~NA#> <U+2029>[90m5<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL        <U+2029>[4m1<U+2029>[24m991 Fixed wing multi~NA#> <U+2029>[90m6<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA        <U+2029>[4m2<U+2029>[24m012 Fixed wing multi~NA#> <U+2029>[90m# ... 336,770 rows, 6 variables: <U+2029>[1mmanufacturer<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mmodel<U+2029>[22m <chr>, <U+2029>[1mengines<U+2029>[22m <int>, <U+2029>[1mseats<U+2029>[22m <int>, <U+2029>[1mspeed<U+2029>[22m <int>, <U+2029>[1mengine<U+2029>[22m <chr><U+2029>[39mNA\nNote year variables (appear input data frames, constrained equal) disambiguated output suffix.character vector, = \"x\".\nlike natural join, uses common variables.\nexample, flights planes year variables, mean different things want join tailnum.Note year variables (appear input data frames, constrained equal) disambiguated output suffix.named character vector: = c(\"\" = \"b\").\nmatch variable data frame x variable b data frame y.\nvariables x used output.\nexample, want draw map need combine flights data airports data contains location (lat lon) airport.\nflight origin destination airport, need specify one want join :\n\nflights2 %>% \n  left_join(airports, c(\"dest\" = \"faa\"))\n#> <U+2029>[90m# tibble: 336,776 x 15<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mname<U+2029>[22m      <U+2029>[1mlat<U+2029>[22m   <U+2029>[1mlon<U+2029>[22m   <U+2029>[1malt<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA      George~  30.0 -<U+2029>[31m95<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m3<U+2029>[39m    97NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA      George~  30.0 -<U+2029>[31m95<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m3<U+2029>[39m    97NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA      Miami ~  25.8 -<U+2029>[31m80<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m3<U+2029>[39m     8NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6      <U+2029>[31mNA<U+2029>[39m       <U+2029>[31mNA<U+2029>[39m    <U+2029>[31mNA<U+2029>[39m      <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL      Hartsf~  33.6 -<U+2029>[31m84<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m4<U+2029>[39m  <U+2029>[4m1<U+2029>[24m026NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA      Chicag~  42.0 -<U+2029>[31m87<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m9<U+2029>[39m   668NA#> <U+2029>[90m# ... 336,770 rows, 3 variables: <U+2029>[1mtz<U+2029>[22m <dbl>, <U+2029>[1mdst<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mtzone<U+2029>[22m <chr><U+2029>[39mNAflights2 %>% \n  left_join(airports, c(\"origin\" = \"faa\"))\n#> <U+2029>[90m# tibble: 336,776 x 15<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mname<U+2029>[22m      <U+2029>[1mlat<U+2029>[22m   <U+2029>[1mlon<U+2029>[22m   <U+2029>[1malt<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA      Newark~  40.7 -<U+2029>[31m74<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m2<U+2029>[39m    18NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA      La Gua~  40.8 -<U+2029>[31m73<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m9<U+2029>[39m    22NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA      John F~  40.6 -<U+2029>[31m73<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m8<U+2029>[39m    13NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6      John F~  40.6 -<U+2029>[31m73<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m8<U+2029>[39m    13NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL      La Gua~  40.8 -<U+2029>[31m73<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m9<U+2029>[39m    22NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA      Newark~  40.7 -<U+2029>[31m74<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m2<U+2029>[39m    18NA#> <U+2029>[90m# ... 336,770 rows, 3 variables: <U+2029>[1mtz<U+2029>[22m <dbl>, <U+2029>[1mdst<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mtzone<U+2029>[22m <chr><U+2029>[39mNAA named character vector: = c(\"\" = \"b\").\nmatch variable data frame x variable b data frame y.\nvariables x used output.example, want draw map need combine flights data airports data contains location (lat lon) airport.\nflight origin destination airport, need specify one want join :","code":"\nflights2 %>% \n  left_join(weather)\n#> Joining, by = c(\"year\", \"month\", \"day\", \"hour\", \"origin\")\n#> <U+2029>[90m# A tibble: 336,776 x 18<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m  <U+2029>[1mtemp<U+2029>[22m  <U+2029>[1mdewp<U+2029>[22m <U+2029>[1mhumid<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA       39.0  28.0  64.4NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA       39.9  25.0  54.8NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA       39.0  27.0  61.6NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6       39.0  27.0  61.6NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL       39.9  25.0  54.8NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA       39.0  28.0  64.4NA#> <U+2029>[90m# ... with 336,770 more rows, and 7 more variables: <U+2029>[1mwind_dir<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mwind_speed<U+2029>[22m <dbl>, <U+2029>[1mwind_gust<U+2029>[22m <dbl>, <U+2029>[1mprecip<U+2029>[22m <dbl>, <U+2029>[1mpressure<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mvisib<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\nflights2 %>% \n  left_join(planes, by = \"tailnum\")\n#> <U+2029>[90m# A tibble: 336,776 x 16<U+2029>[39mNA#>   <U+2029>[1myear.x<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1myear.y<U+2029>[22m <U+2029>[1mtype<U+2029>[22m             NA#>    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m            NA#> <U+2029>[90m1<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA        <U+2029>[4m1<U+2029>[24m999 Fixed wing multi~NA#> <U+2029>[90m2<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA        <U+2029>[4m1<U+2029>[24m998 Fixed wing multi~NA#> <U+2029>[90m3<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA        <U+2029>[4m1<U+2029>[24m990 Fixed wing multi~NA#> <U+2029>[90m4<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6        <U+2029>[4m2<U+2029>[24m012 Fixed wing multi~NA#> <U+2029>[90m5<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL        <U+2029>[4m1<U+2029>[24m991 Fixed wing multi~NA#> <U+2029>[90m6<U+2029>[39m   <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA        <U+2029>[4m2<U+2029>[24m012 Fixed wing multi~NA#> <U+2029>[90m# ... with 336,770 more rows, and 6 more variables: <U+2029>[1mmanufacturer<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mmodel<U+2029>[22m <chr>, <U+2029>[1mengines<U+2029>[22m <int>, <U+2029>[1mseats<U+2029>[22m <int>, <U+2029>[1mspeed<U+2029>[22m <int>, <U+2029>[1mengine<U+2029>[22m <chr><U+2029>[39mNA\nflights2 %>% \n  left_join(airports, c(\"dest\" = \"faa\"))\n#> <U+2029>[90m# A tibble: 336,776 x 15<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mname<U+2029>[22m      <U+2029>[1mlat<U+2029>[22m   <U+2029>[1mlon<U+2029>[22m   <U+2029>[1malt<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA      George~  30.0 -<U+2029>[31m95<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m3<U+2029>[39m    97NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA      George~  30.0 -<U+2029>[31m95<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m3<U+2029>[39m    97NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA      Miami ~  25.8 -<U+2029>[31m80<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m3<U+2029>[39m     8NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6      <U+2029>[31mNA<U+2029>[39m       <U+2029>[31mNA<U+2029>[39m    <U+2029>[31mNA<U+2029>[39m      <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL      Hartsf~  33.6 -<U+2029>[31m84<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m4<U+2029>[39m  <U+2029>[4m1<U+2029>[24m026NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA      Chicag~  42.0 -<U+2029>[31m87<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m9<U+2029>[39m   668NA#> <U+2029>[90m# ... with 336,770 more rows, and 3 more variables: <U+2029>[1mtz<U+2029>[22m <dbl>, <U+2029>[1mdst<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mtzone<U+2029>[22m <chr><U+2029>[39mNAflights2 %>% \n  left_join(airports, c(\"origin\" = \"faa\"))\n#> <U+2029>[90m# A tibble: 336,776 x 15<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mtailnum<U+2029>[22m <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mname<U+2029>[22m      <U+2029>[1mlat<U+2029>[22m   <U+2029>[1mlon<U+2029>[22m   <U+2029>[1malt<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    IAH   N14228  UA      Newark~  40.7 -<U+2029>[31m74<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m2<U+2029>[39m    18NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 LGA    IAH   N24211  UA      La Gua~  40.8 -<U+2029>[31m73<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m9<U+2029>[39m    22NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    MIA   N619AA  AA      John F~  40.6 -<U+2029>[31m73<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m8<U+2029>[39m    13NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 JFK    BQN   N804JB  B6      John F~  40.6 -<U+2029>[31m73<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m8<U+2029>[39m    13NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6 LGA    ATL   N668DN  DL      La Gua~  40.8 -<U+2029>[31m73<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m9<U+2029>[39m    22NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5 EWR    ORD   N39463  UA      Newark~  40.7 -<U+2029>[31m74<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m2<U+2029>[39m    18NA#> <U+2029>[90m# ... with 336,770 more rows, and 3 more variables: <U+2029>[1mtz<U+2029>[22m <dbl>, <U+2029>[1mdst<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mtzone<U+2029>[22m <chr><U+2029>[39mNA"},{"path":"relational-data.html","id":"exercises-25","chapter":"14 Relational data","heading":"14.4.6 Exercises","text":"Compute average delay destination, join airports data frame can show spatial distribution delays.\n’s easy way draw map United States:\n\nairports %>%\n  semi_join(flights, c(\"faa\" = \"dest\")) %>%\n  ggplot(aes(lon, lat)) +\n    borders(\"state\") +\n    geom_point() +\n    coord_quickmap()\n(Don’t worry don’t understand semi_join() — ’ll learn next.)\nmight want use size colour points display average delay airport.Compute average delay destination, join airports data frame can show spatial distribution delays.\n’s easy way draw map United States:(Don’t worry don’t understand semi_join() — ’ll learn next.)might want use size colour points display average delay airport.Add location origin destination (.e. lat lon) flights.Add location origin destination (.e. lat lon) flights.relationship age plane delays?relationship age plane delays?weather conditions make likely see delay?weather conditions make likely see delay?happened June 13 2013?\nDisplay spatial pattern delays, use Google cross-reference weather.happened June 13 2013?\nDisplay spatial pattern delays, use Google cross-reference weather.","code":"\nairports %>%\n  semi_join(flights, c(\"faa\" = \"dest\")) %>%\n  ggplot(aes(lon, lat)) +\n    borders(\"state\") +\n    geom_point() +\n    coord_quickmap()"},{"path":"relational-data.html","id":"other-implementations","chapter":"14 Relational data","heading":"14.4.7 Other implementations","text":"base::merge() can perform four types mutating join:advantages specific dplyr verbs clearly convey intent code: difference joins really important concealed arguments merge().\ndplyr’s joins considerably faster don’t mess order rows.SQL inspiration dplyr’s conventions, translation straightforward:Note “INNER” “OUTER” optional, often omitted.Joining different variables data frames, e.g. inner_join(x, y, = c(\"\" = \"b\")) uses slightly different syntax SQL: SELECT * x INNER JOIN y x.= y.b.\nsyntax suggests, SQL supports wider range join types dplyr can connect data frames using constraints equality (sometimes called non-equijoins).","code":""},{"path":"relational-data.html","id":"filtering-joins","chapter":"14 Relational data","heading":"14.5 Filtering joins","text":"Filtering joins match observations way mutating joins, affect observations, variables.\ntwo types:semi_join(x, y) keeps observations x match y.anti_join(x, y) drops observations x match y.Semi-joins useful matching filtered summary data frames back original rows.\nexample, imagine ’ve found top ten popular destinations:Now want find flight went one destinations.\nconstruct filter :’s difficult extend approach multiple variables.\nexample, imagine ’d found 10 days highest average delays.\nconstruct filter statement used year, month, day match back flights?Instead can use semi-join, connects two data frames like mutating join, instead adding new columns, keeps rows x match y:Graphically, semi-join looks like :existence match important; doesn’t matter observation matched.\nmeans filtering joins never duplicate rows like mutating joins :inverse semi-join anti-join.\nanti-join keeps rows don’t match:Anti-joins useful diagnosing join mismatches.\nexample, connecting flights planes, might interested know many flights don’t match planes:","code":"\ntop_dest <- flights %>%\n  count(dest, sort = TRUE) %>%\n  head(10)\ntop_dest\n#> <U+2029>[90m# A tibble: 10 x 2<U+2029>[39mNA#>   <U+2029>[1mdest<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m ORD   <U+2029>[4m1<U+2029>[24m<U+2029>[4m7<U+2029>[24m283NA#> <U+2029>[90m2<U+2029>[39m ATL   <U+2029>[4m1<U+2029>[24m<U+2029>[4m7<U+2029>[24m215NA#> <U+2029>[90m3<U+2029>[39m LAX   <U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m174NA#> <U+2029>[90m4<U+2029>[39m BOS   <U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m508NA#> <U+2029>[90m5<U+2029>[39m MCO   <U+2029>[4m1<U+2029>[24m<U+2029>[4m4<U+2029>[24m082NA#> <U+2029>[90m6<U+2029>[39m CLT   <U+2029>[4m1<U+2029>[24m<U+2029>[4m4<U+2029>[24m064NA#> <U+2029>[90m# ... with 4 more rows<U+2029>[39mNA\nflights %>% \n  filter(dest %in% top_dest$dest)\n#> <U+2029>[90m# A tibble: 141,145 x 19<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      555            600        -<U+2029>[31m5<U+2029>[39m      913            854NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      557            600        -<U+2029>[31m3<U+2029>[39m      838            846NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      558            600        -<U+2029>[31m2<U+2029>[39m      753            745NA#> <U+2029>[90m# ... with 141,139 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\nflights %>% \n  semi_join(top_dest)\n#> Joining, by = \"dest\"\n#> <U+2029>[90m# A tibble: 141,145 x 19<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      555            600        -<U+2029>[31m5<U+2029>[39m      913            854NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      557            600        -<U+2029>[31m3<U+2029>[39m      838            846NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      558            600        -<U+2029>[31m2<U+2029>[39m      753            745NA#> <U+2029>[90m# ... with 141,139 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\nflights %>%\n  anti_join(planes, by = \"tailnum\") %>%\n  count(tailnum, sort = TRUE)\n#> <U+2029>[90m# A tibble: 722 x 2<U+2029>[39mNA#>   <U+2029>[1mtailnum<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m <U+2029>[31mNA<U+2029>[39m       <U+2029>[4m2<U+2029>[24m512NA#> <U+2029>[90m2<U+2029>[39m N725MQ    575NA#> <U+2029>[90m3<U+2029>[39m N722MQ    513NA#> <U+2029>[90m4<U+2029>[39m N723MQ    507NA#> <U+2029>[90m5<U+2029>[39m N713MQ    483NA#> <U+2029>[90m6<U+2029>[39m N735MQ    396NA#> <U+2029>[90m# ... with 716 more rows<U+2029>[39mNA"},{"path":"relational-data.html","id":"exercises-26","chapter":"14 Relational data","heading":"14.5.1 Exercises","text":"mean flight missing tailnum?\ntail numbers don’t matching record planes common?\n(Hint: one variable explains ~90% problems.)mean flight missing tailnum?\ntail numbers don’t matching record planes common?\n(Hint: one variable explains ~90% problems.)Filter flights show flights planes flown least 100 flights.Filter flights show flights planes flown least 100 flights.Combine fueleconomy::vehicles fueleconomy::common find records common models.Combine fueleconomy::vehicles fueleconomy::common find records common models.Find 48 hours (course whole year) worst delays.\nCross-reference weather data.\nCan see patterns?Find 48 hours (course whole year) worst delays.\nCross-reference weather data.\nCan see patterns?anti_join(flights, airports, = c(\"dest\" = \"faa\")) tell ?\nanti_join(airports, flights, = c(\"faa\" = \"dest\")) tell ?anti_join(flights, airports, = c(\"dest\" = \"faa\")) tell ?\nanti_join(airports, flights, = c(\"faa\" = \"dest\")) tell ?might expect ’s implicit relationship plane airline, plane flown single airline.\nConfirm reject hypothesis using tools ’ve learned .might expect ’s implicit relationship plane airline, plane flown single airline.\nConfirm reject hypothesis using tools ’ve learned .","code":""},{"path":"relational-data.html","id":"join-problems","chapter":"14 Relational data","heading":"14.6 Join problems","text":"data ’ve working chapter cleaned ’ll problems possible.\ndata unlikely nice, things data make joins go smoothly.Start identifying variables form primary key data frame.\nusually based understanding data, empirically looking combination variables give unique identifier.\njust look variables without thinking mean, might get (un)lucky find combination ’s unique current data relationship might true general.\nexample, altitude longitude uniquely identify airport, good identifiers!\n\nairports %>% count(alt, lon) %>% filter(n > 1)\n#> <U+2029>[90m# tibble: 0 x 3<U+2029>[39mNA#> <U+2029>[90m# ... 3 variables: <U+2029>[1malt<U+2029>[22m <dbl>, <U+2029>[1mlon<U+2029>[22m <dbl>, <U+2029>[1mn<U+2029>[22m <int><U+2029>[39mNAStart identifying variables form primary key data frame.\nusually based understanding data, empirically looking combination variables give unique identifier.\njust look variables without thinking mean, might get (un)lucky find combination ’s unique current data relationship might true general.example, altitude longitude uniquely identify airport, good identifiers!Check none variables primary key missing.\nvalue missing can’t identify observation!Check none variables primary key missing.\nvalue missing can’t identify observation!Check foreign keys match primary keys another data frame.\nbest way anti_join().\n’s common keys match data entry errors.\nFixing often lot work.\nmissing keys, ’ll need thoughtful use inner vs. outer joins, carefully considering whether want drop rows don’t match.Check foreign keys match primary keys another data frame.\nbest way anti_join().\n’s common keys match data entry errors.\nFixing often lot work.missing keys, ’ll need thoughtful use inner vs. outer joins, carefully considering whether want drop rows don’t match.aware simply checking number rows join sufficient ensure join gone smoothly.\ninner join duplicate keys data frames, might get unlucky number dropped rows might exactly equal number duplicated rows!","code":"\nairports %>% count(alt, lon) %>% filter(n > 1)\n#> <U+2029>[90m# A tibble: 0 x 3<U+2029>[39mNA#> <U+2029>[90m# ... with 3 variables: <U+2029>[1malt<U+2029>[22m <dbl>, <U+2029>[1mlon<U+2029>[22m <dbl>, <U+2029>[1mn<U+2029>[22m <int><U+2029>[39mNA"},{"path":"relational-data.html","id":"set-operations","chapter":"14 Relational data","heading":"14.7 Set operations","text":"final type two-table verb set operations.\nGenerally, use least frequently, occasionally useful want break single complex filter simpler pieces.\noperations work complete row, comparing values every variable.\nexpect x y inputs variables, treat observations like sets:intersect(x, y): return observations x y.union(x, y): return unique observations x y.setdiff(x, y): return observations x, y.Given simple data:four possibilities :","code":"\ndf1 <- tribble(\n  ~x, ~y,\n   1,  1,\n   2,  1\n)\ndf2 <- tribble(\n  ~x, ~y,\n   1,  1,\n   1,  2\n)\nintersect(df1, df2)\n#> <U+2029>[90m# A tibble: 1 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     1NA# Note that we get 3 rows, not 4\nunion(df1, df2)\n#> <U+2029>[90m# A tibble: 3 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     1NA#> <U+2029>[90m2<U+2029>[39m     2     1NA#> <U+2029>[90m3<U+2029>[39m     1     2NAsetdiff(df1, df2)\n#> <U+2029>[90m# A tibble: 1 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     2     1NAsetdiff(df2, df1)\n#> <U+2029>[90m# A tibble: 1 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     2NA"},{"path":"vector-tools.html","id":"vector-tools","chapter":"15 Vector tools","heading":"15 Vector tools","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"vector-tools.html","id":"introduction-8","chapter":"15 Vector tools","heading":"15.1 Introduction","text":"%%c()","code":"\nlibrary(tidyverse)\n#> -- <U+2029>[1mAttaching packages<U+2029>[22m --------------------------------------- tidyverse 1.3.1 --NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mggplot2<U+2029>[39m 3.3.5          <U+2029>[32mv<U+2029>[39m <U+2029>[34mpurrr  <U+2029>[39m 0.3.4     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtibble <U+2029>[39m 3.1.2          <U+2029>[32mv<U+2029>[39m <U+2029>[34mdplyr  <U+2029>[39m 1.0.7     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtidyr  <U+2029>[39m 1.1.3          <U+2029>[32mv<U+2029>[39m <U+2029>[34mstringr<U+2029>[39m 1.4.0.<U+2029>[31m9000<U+2029>[39mNA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mreadr  <U+2029>[39m 2.0.1          <U+2029>[32mv<U+2029>[39m <U+2029>[34mforcats<U+2029>[39m 0.5.1NA#> -- <U+2029>[1mConflicts<U+2029>[22m ------------------------------------------ tidyverse_conflicts() --NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mfilter()<U+2029>[39m masks <U+2029>[34mstats<U+2029>[39m::filter()NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mlag()<U+2029>[39m    masks <U+2029>[34mstats<U+2029>[39m::lag()NAlibrary(nycflights13)\n\nnot_cancelled <- flights %>% \n  filter(!is.na(dep_delay), !is.na(arr_delay))"},{"path":"vector-tools.html","id":"counts","chapter":"15 Vector tools","heading":"15.2 Counts","text":"Counts: ’ve seen n(), takes arguments, returns size current group.\ncount number non-missing values, use sum(!.na(x)).\ncount number distinct (unique) values, use n_distinct(x).\n\n# destinations carriers?\nnot_cancelled %>% \n  group_by(dest) %>% \n  summarise(carriers = n_distinct(carrier)) %>% \n  arrange(desc(carriers))\n#> <U+2029>[90m# tibble: 104 x 2<U+2029>[39mNA#>   <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mcarriers<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m ATL          7NA#> <U+2029>[90m2<U+2029>[39m BOS          7NA#> <U+2029>[90m3<U+2029>[39m CLT          7NA#> <U+2029>[90m4<U+2029>[39m ORD          7NA#> <U+2029>[90m5<U+2029>[39m TPA          7NA#> <U+2029>[90m6<U+2029>[39m AUS          6NA#> <U+2029>[90m# ... 98 rows<U+2029>[39mNA\nCounts useful dplyr provides simple helper want count:\n\nnot_cancelled %>% \n  count(dest)\n#> <U+2029>[90m# tibble: 104 x 2<U+2029>[39mNA#>   <U+2029>[1mdest<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m ABQ     254NA#> <U+2029>[90m2<U+2029>[39m ACK     264NA#> <U+2029>[90m3<U+2029>[39m ALB     418NA#> <U+2029>[90m4<U+2029>[39m ANC       8NA#> <U+2029>[90m5<U+2029>[39m ATL   <U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m837NA#> <U+2029>[90m6<U+2029>[39m AUS    <U+2029>[4m2<U+2029>[24m411NA#> <U+2029>[90m# ... 98 rows<U+2029>[39mNA\nJust like group_by(), can also provide multiple variables count().\n\nnot_cancelled %>% \n  count(carrier, dest)\n#> <U+2029>[90m# tibble: 312 x 3<U+2029>[39mNA#>   <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mdest<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m 9E      ATL      56NA#> <U+2029>[90m2<U+2029>[39m 9E      AUS       2NA#> <U+2029>[90m3<U+2029>[39m 9E      AVL      10NA#> <U+2029>[90m4<U+2029>[39m 9E      BNA     452NA#> <U+2029>[90m5<U+2029>[39m 9E      BOS     853NA#> <U+2029>[90m6<U+2029>[39m 9E      BTV       2NA#> <U+2029>[90m# ... 306 rows<U+2029>[39mNA\ncan optionally provide weight variable.\nexample, use “count” (sum) total number miles plane flew:\n\nnot_cancelled %>% \n  count(tailnum, wt = distance)\n#> <U+2029>[90m# tibble: 4,037 x 2<U+2029>[39mNA#>   <U+2029>[1mtailnum<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m D942DN    <U+2029>[4m3<U+2029>[24m418NA#> <U+2029>[90m2<U+2029>[39m N0EGMQ  <U+2029>[4m2<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m9<U+2029>[24m143NA#> <U+2029>[90m3<U+2029>[39m N10156  <U+2029>[4m1<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m9<U+2029>[24m664NA#> <U+2029>[90m4<U+2029>[39m N102UW   <U+2029>[4m2<U+2029>[24m<U+2029>[4m5<U+2029>[24m722NA#> <U+2029>[90m5<U+2029>[39m N103US   <U+2029>[4m2<U+2029>[24m<U+2029>[4m4<U+2029>[24m619NA#> <U+2029>[90m6<U+2029>[39m N104UW   <U+2029>[4m2<U+2029>[24m<U+2029>[4m4<U+2029>[24m616NA#> <U+2029>[90m# ... 4,031 rows<U+2029>[39mNACounts: ’ve seen n(), takes arguments, returns size current group.\ncount number non-missing values, use sum(!.na(x)).\ncount number distinct (unique) values, use n_distinct(x).Counts useful dplyr provides simple helper want count:Just like group_by(), can also provide multiple variables count().can optionally provide weight variable.\nexample, use “count” (sum) total number miles plane flew:","code":"\n# Which destinations have the most carriers?\nnot_cancelled %>% \n  group_by(dest) %>% \n  summarise(carriers = n_distinct(carrier)) %>% \n  arrange(desc(carriers))\n#> <U+2029>[90m# A tibble: 104 x 2<U+2029>[39mNA#>   <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mcarriers<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m ATL          7NA#> <U+2029>[90m2<U+2029>[39m BOS          7NA#> <U+2029>[90m3<U+2029>[39m CLT          7NA#> <U+2029>[90m4<U+2029>[39m ORD          7NA#> <U+2029>[90m5<U+2029>[39m TPA          7NA#> <U+2029>[90m6<U+2029>[39m AUS          6NA#> <U+2029>[90m# ... with 98 more rows<U+2029>[39mNA\nnot_cancelled %>% \n  count(dest)\n#> <U+2029>[90m# A tibble: 104 x 2<U+2029>[39mNA#>   <U+2029>[1mdest<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m ABQ     254NA#> <U+2029>[90m2<U+2029>[39m ACK     264NA#> <U+2029>[90m3<U+2029>[39m ALB     418NA#> <U+2029>[90m4<U+2029>[39m ANC       8NA#> <U+2029>[90m5<U+2029>[39m ATL   <U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m837NA#> <U+2029>[90m6<U+2029>[39m AUS    <U+2029>[4m2<U+2029>[24m411NA#> <U+2029>[90m# ... with 98 more rows<U+2029>[39mNA\nnot_cancelled %>% \n  count(carrier, dest)\n#> <U+2029>[90m# A tibble: 312 x 3<U+2029>[39mNA#>   <U+2029>[1mcarrier<U+2029>[22m <U+2029>[1mdest<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m 9E      ATL      56NA#> <U+2029>[90m2<U+2029>[39m 9E      AUS       2NA#> <U+2029>[90m3<U+2029>[39m 9E      AVL      10NA#> <U+2029>[90m4<U+2029>[39m 9E      BNA     452NA#> <U+2029>[90m5<U+2029>[39m 9E      BOS     853NA#> <U+2029>[90m6<U+2029>[39m 9E      BTV       2NA#> <U+2029>[90m# ... with 306 more rows<U+2029>[39mNA\nnot_cancelled %>% \n  count(tailnum, wt = distance)\n#> <U+2029>[90m# A tibble: 4,037 x 2<U+2029>[39mNA#>   <U+2029>[1mtailnum<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m D942DN    <U+2029>[4m3<U+2029>[24m418NA#> <U+2029>[90m2<U+2029>[39m N0EGMQ  <U+2029>[4m2<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m9<U+2029>[24m143NA#> <U+2029>[90m3<U+2029>[39m N10156  <U+2029>[4m1<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m9<U+2029>[24m664NA#> <U+2029>[90m4<U+2029>[39m N102UW   <U+2029>[4m2<U+2029>[24m<U+2029>[4m5<U+2029>[24m722NA#> <U+2029>[90m5<U+2029>[39m N103US   <U+2029>[4m2<U+2029>[24m<U+2029>[4m4<U+2029>[24m619NA#> <U+2029>[90m6<U+2029>[39m N104UW   <U+2029>[4m2<U+2029>[24m<U+2029>[4m4<U+2029>[24m616NA#> <U+2029>[90m# ... with 4,031 more rows<U+2029>[39mNA"},{"path":"vector-tools.html","id":"window-functions","chapter":"15 Vector tools","heading":"15.3 Window functions","text":"Offsets: lead() lag() allow refer leading lagging values.\nallows compute running differences (e.g. x - lag(x)) find values change (x != lag(x)).\nuseful conjunction group_by(), ’ll learn shortly.\n\n(x <- 1:10)\n#>  [1]  1  2  3  4  5  6  7  8  9 10\nlag(x)\n#>  [1] NA  1  2  3  4  5  6  7  8  9\nlead(x)\n#>  [1]  2  3  4  5  6  7  8  9 10 NAOffsets: lead() lag() allow refer leading lagging values.\nallows compute running differences (e.g. x - lag(x)) find values change (x != lag(x)).\nuseful conjunction group_by(), ’ll learn shortly.Ranking: number ranking functions, start min_rank().\nusual type ranking (e.g. 1st, 2nd, 2nd, 4th).\ndefault gives smallest values small ranks; use desc(x) give largest values smallest ranks.\n\ny <- c(1, 2, 2, NA, 3, 4)\nmin_rank(y)\n#> [1]  1  2  2 NA  4  5\nmin_rank(desc(y))\n#> [1]  5  3  3 NA  2  1\nmin_rank() doesn’t need, look variants row_number(), dense_rank(), percent_rank(), cume_dist(), ntile().\nSee help pages details.\n\nrow_number(y)\n#> [1]  1  2  3 NA  4  5\ndense_rank(y)\n#> [1]  1  2  2 NA  3  4\npercent_rank(y)\n#> [1] 0.00 0.25 0.25   NA 0.75 1.00\ncume_dist(y)\n#> [1] 0.2 0.6 0.6  NA 0.8 1.0Ranking: number ranking functions, start min_rank().\nusual type ranking (e.g. 1st, 2nd, 2nd, 4th).\ndefault gives smallest values small ranks; use desc(x) give largest values smallest ranks.min_rank() doesn’t need, look variants row_number(), dense_rank(), percent_rank(), cume_dist(), ntile().\nSee help pages details.Measures position: first(x), nth(x, 2), last(x).\nwork similarly x[1], x[2], x[length(x)] let set default value position exist (.e. ’re trying get 3rd element group two elements).\nexample, can find first last departure day:\n\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(\n    first_dep = first(dep_time), \n    last_dep = last(dep_time)\n  )\n#> `summarise()` grouped output 'year', 'month'. can override using `.groups` argument.\n#> <U+2029>[90m# tibble: 365 x 5<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mfirst_dep<U+2029>[22m <U+2029>[1mlast_dep<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       517     <U+2029>[4m2<U+2029>[24m356NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2        42     <U+2029>[4m2<U+2029>[24m354NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3        32     <U+2029>[4m2<U+2029>[24m349NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4        25     <U+2029>[4m2<U+2029>[24m358NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5        14     <U+2029>[4m2<U+2029>[24m357NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6        16     <U+2029>[4m2<U+2029>[24m355NA#> <U+2029>[90m# ... 359 rows<U+2029>[39mNA\nfunctions complementary filtering ranks.\nFiltering gives variables, observation separate row:\n\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  mutate(r = min_rank(desc(dep_time))) %>% \n  filter(r %% range(r))\n#> <U+2029>[90m# tibble: 770 x 20<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month, day [365]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     <U+2029>[4m2<U+2029>[24m356           <U+2029>[4m2<U+2029>[24m359        -<U+2029>[31m3<U+2029>[39m      425            437NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2       42           <U+2029>[4m2<U+2029>[24m359        43      518            442NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2     <U+2029>[4m2<U+2029>[24m354           <U+2029>[4m2<U+2029>[24m359        -<U+2029>[31m5<U+2029>[39m      413            437NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3       32           <U+2029>[4m2<U+2029>[24m359        33      504            442NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3     <U+2029>[4m2<U+2029>[24m349           <U+2029>[4m2<U+2029>[24m359       -<U+2029>[31m10<U+2029>[39m      434            445NA#> <U+2029>[90m# ... 764 rows, 12 variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mr<U+2029>[22m <int><U+2029>[39mNAMeasures position: first(x), nth(x, 2), last(x).\nwork similarly x[1], x[2], x[length(x)] let set default value position exist (.e. ’re trying get 3rd element group two elements).\nexample, can find first last departure day:functions complementary filtering ranks.\nFiltering gives variables, observation separate row:","code":"\n(x <- 1:10)\n#>  [1]  1  2  3  4  5  6  7  8  9 10\nlag(x)\n#>  [1] NA  1  2  3  4  5  6  7  8  9\nlead(x)\n#>  [1]  2  3  4  5  6  7  8  9 10 NA\ny <- c(1, 2, 2, NA, 3, 4)\nmin_rank(y)\n#> [1]  1  2  2 NA  4  5\nmin_rank(desc(y))\n#> [1]  5  3  3 NA  2  1\nrow_number(y)\n#> [1]  1  2  3 NA  4  5\ndense_rank(y)\n#> [1]  1  2  2 NA  3  4\npercent_rank(y)\n#> [1] 0.00 0.25 0.25   NA 0.75 1.00\ncume_dist(y)\n#> [1] 0.2 0.6 0.6  NA 0.8 1.0\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(\n    first_dep = first(dep_time), \n    last_dep = last(dep_time)\n  )\n#> `summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.\n#> <U+2029>[90m# A tibble: 365 x 5<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mfirst_dep<U+2029>[22m <U+2029>[1mlast_dep<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       517     <U+2029>[4m2<U+2029>[24m356NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2        42     <U+2029>[4m2<U+2029>[24m354NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3        32     <U+2029>[4m2<U+2029>[24m349NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4        25     <U+2029>[4m2<U+2029>[24m358NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5        14     <U+2029>[4m2<U+2029>[24m357NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6        16     <U+2029>[4m2<U+2029>[24m355NA#> <U+2029>[90m# ... with 359 more rows<U+2029>[39mNA\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  mutate(r = min_rank(desc(dep_time))) %>% \n  filter(r %in% range(r))\n#> <U+2029>[90m# A tibble: 770 x 20<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month, day [365]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     <U+2029>[4m2<U+2029>[24m356           <U+2029>[4m2<U+2029>[24m359        -<U+2029>[31m3<U+2029>[39m      425            437NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2       42           <U+2029>[4m2<U+2029>[24m359        43      518            442NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2     <U+2029>[4m2<U+2029>[24m354           <U+2029>[4m2<U+2029>[24m359        -<U+2029>[31m5<U+2029>[39m      413            437NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3       32           <U+2029>[4m2<U+2029>[24m359        33      504            442NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3     <U+2029>[4m2<U+2029>[24m349           <U+2029>[4m2<U+2029>[24m359       -<U+2029>[31m10<U+2029>[39m      434            445NA#> <U+2029>[90m# ... with 764 more rows, and 12 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mr<U+2029>[22m <int><U+2029>[39mNA"},{"path":"vector-tools.html","id":"dplyr","chapter":"15 Vector tools","heading":"15.3.1 dplyr","text":"Find worst members group:\n\nflights_sml %>% \n  group_by(year, month, day) %>%\n  filter(rank(desc(arr_delay)) < 10)\n#> <U+2029>[90m# tibble: 3,306 x 7<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month, day [365]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mdistance<U+2029>[22m <U+2029>[1mair_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       853       851      184       41NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       290       338     <U+2029>[4m1<U+2029>[24m134      213NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       260       263      266       46NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       157       174      213       60NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       216       222      708      121NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       255       250      589      115NA#> <U+2029>[90m# ... 3,300 rows<U+2029>[39mNAFind worst members group:Find groups bigger threshold:\n\npopular_dests <- flights %>% \n  group_by(dest) %>% \n  filter(n() > 365)\npopular_dests\n#> <U+2029>[90m# tibble: 332,577 x 19<U+2029>[39mNA#> <U+2029>[90m# Groups:   dest [77]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... 332,571 rows, 11 variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNAFind groups bigger threshold:Standardise compute per group metrics:\n\npopular_dests %>% \n  filter(arr_delay > 0) %>% \n  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% \n  select(year:day, dest, arr_delay, prop_delay)\n#> <U+2029>[90m# tibble: 131,106 x 6<U+2029>[39mNA#> <U+2029>[90m# Groups:   dest [77]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mprop_delay<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 IAH          11  0.000<U+2029>[4m1<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m1<U+2029>[24m NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 IAH          20  0.000<U+2029>[4m2<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m1<U+2029>[24m NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 MIA          33  0.000<U+2029>[4m2<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m5<U+2029>[24m NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 ORD          12  0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m4NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 FLL          19  0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m3<U+2029>[24m8NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 ORD           8  0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m3NA#> <U+2029>[90m# ... 131,100 rows<U+2029>[39mNAStandardise compute per group metrics:grouped filter grouped mutate followed ungrouped filter.\ngenerally avoid except quick dirty manipulations: otherwise ’s hard check ’ve done manipulation correctly.Functions work naturally grouped mutates filters known window functions (vs. summary functions used summaries).\ncan learn useful window functions corresponding vignette: vignette(\"window-functions\").","code":"\nflights_sml <- select(flights, \n  year:day, \n  ends_with(\"delay\"), \n  distance, \n  air_time\n)\nflights_sml %>% \n  group_by(year, month, day) %>%\n  filter(rank(desc(arr_delay)) < 10)\n#> <U+2029>[90m# A tibble: 3,306 x 7<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month, day [365]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mdistance<U+2029>[22m <U+2029>[1mair_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       853       851      184       41NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       290       338     <U+2029>[4m1<U+2029>[24m134      213NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       260       263      266       46NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       157       174      213       60NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       216       222      708      121NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       255       250      589      115NA#> <U+2029>[90m# ... with 3,300 more rows<U+2029>[39mNA\npopular_dests <- flights %>% \n  group_by(dest) %>% \n  filter(n() > 365)\npopular_dests\n#> <U+2029>[90m# A tibble: 332,577 x 19<U+2029>[39mNA#> <U+2029>[90m# Groups:   dest [77]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m <U+2029>[1msched_dep_time<U+2029>[22m <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_time<U+2029>[22m <U+2029>[1msched_arr_time<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      517            515         2      830            819NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      533            529         4      850            830NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      542            540         2      923            850NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      544            545        -<U+2029>[31m1<U+2029>[39m     <U+2029>[4m1<U+2029>[24m004           <U+2029>[4m1<U+2029>[24m022NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            600        -<U+2029>[31m6<U+2029>[39m      812            837NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      554            558        -<U+2029>[31m4<U+2029>[39m      740            728NA#> <U+2029>[90m# ... with 332,571 more rows, and 11 more variables: <U+2029>[1marr_delay<U+2029>[22m <dbl>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mcarrier<U+2029>[22m <chr>, <U+2029>[1mflight<U+2029>[22m <int>, <U+2029>[1mtailnum<U+2029>[22m <chr>, <U+2029>[1morigin<U+2029>[22m <chr>, <U+2029>[1mdest<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1mdistance<U+2029>[22m <dbl>, <U+2029>[1mhour<U+2029>[22m <dbl>, <U+2029>[1mminute<U+2029>[22m <dbl>, <U+2029>[1mtime_hour<U+2029>[22m <dttm><U+2029>[39mNA\npopular_dests %>% \n  filter(arr_delay > 0) %>% \n  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% \n  select(year:day, dest, arr_delay, prop_delay)\n#> <U+2029>[90m# A tibble: 131,106 x 6<U+2029>[39mNA#> <U+2029>[90m# Groups:   dest [77]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mprop_delay<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 IAH          11  0.000<U+2029>[4m1<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m1<U+2029>[24m NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 IAH          20  0.000<U+2029>[4m2<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m1<U+2029>[24m NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 MIA          33  0.000<U+2029>[4m2<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m5<U+2029>[24m NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 ORD          12  0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m4<U+2029>[24m<U+2029>[4m2<U+2029>[24m4NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 FLL          19  0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m3<U+2029>[24m8NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1 ORD           8  0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m8<U+2029>[24m3NA#> <U+2029>[90m# ... with 131,100 more rows<U+2029>[39mNA"},{"path":"vector-tools.html","id":"exercises-27","chapter":"15 Vector tools","heading":"15.3.2 Exercises","text":"Find 10 delayed flights using ranking function.\nwant handle ties?\nCarefully read documentation min_rank().Find 10 delayed flights using ranking function.\nwant handle ties?\nCarefully read documentation min_rank().plane (tailnum) worst -time record?plane (tailnum) worst -time record?time day fly want avoid delays much possible?time day fly want avoid delays much possible?destination, compute total minutes delay.\nflight, compute proportion total delay destination.destination, compute total minutes delay.\nflight, compute proportion total delay destination.Delays typically temporally correlated: even problem caused initial delay resolved, later flights delayed allow earlier flights leave.\nUsing lag(), explore delay flight related delay immediately preceding flight.Delays typically temporally correlated: even problem caused initial delay resolved, later flights delayed allow earlier flights leave.\nUsing lag(), explore delay flight related delay immediately preceding flight.Look destination.\nCan find flights suspiciously fast?\n(.e. flights represent potential data entry error).\nCompute air time flight relative shortest flight destination.\nflights delayed air?Look destination.\nCan find flights suspiciously fast?\n(.e. flights represent potential data entry error).\nCompute air time flight relative shortest flight destination.\nflights delayed air?Find destinations flown least two carriers.\nUse information rank carriers.Find destinations flown least two carriers.\nUse information rank carriers.","code":""},{"path":"logicals-numbers.html","id":"logicals-numbers","chapter":"16 Logicals and numbers","heading":"16 Logicals and numbers","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"logicals-numbers.html","id":"introduction-9","chapter":"16 Logicals and numbers","heading":"16.1 Introduction","text":"()","code":"\nlibrary(tidyverse)\n#> -- <U+2029>[1mAttaching packages<U+2029>[22m --------------------------------------- tidyverse 1.3.1 --NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mggplot2<U+2029>[39m 3.3.5          <U+2029>[32mv<U+2029>[39m <U+2029>[34mpurrr  <U+2029>[39m 0.3.4     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtibble <U+2029>[39m 3.1.2          <U+2029>[32mv<U+2029>[39m <U+2029>[34mdplyr  <U+2029>[39m 1.0.7     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtidyr  <U+2029>[39m 1.1.3          <U+2029>[32mv<U+2029>[39m <U+2029>[34mstringr<U+2029>[39m 1.4.0.<U+2029>[31m9000<U+2029>[39mNA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mreadr  <U+2029>[39m 2.0.1          <U+2029>[32mv<U+2029>[39m <U+2029>[34mforcats<U+2029>[39m 0.5.1NA#> -- <U+2029>[1mConflicts<U+2029>[22m ------------------------------------------ tidyverse_conflicts() --NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mfilter()<U+2029>[39m masks <U+2029>[34mstats<U+2029>[39m::filter()NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mlag()<U+2029>[39m    masks <U+2029>[34mstats<U+2029>[39m::lag()NAlibrary(nycflights13)"},{"path":"logicals-numbers.html","id":"logical-operators","chapter":"16 Logicals and numbers","heading":"16.2 Logical operators","text":"Multiple arguments filter() combined “”: every expression must true order row included output.\ntypes combinations, ’ll need use Boolean operators : & “”, | “”, ! “”.\nFigure 16.1 shows complete set Boolean operations.\nFigure 16.1: Complete set boolean operations. x left-hand circle, y right-hand circle, shaded region show parts operator selects.\nfollowing code finds flights departed November December:order operations doesn’t work like English.\ncan’t write filter(flights, month == 11 | 12), might literally translate “finds flights departed November December”.\nInstead finds months equal 11 | 12, expression evaluates TRUE.\nnumeric context (like ), TRUE becomes 1, finds flights January, November December.\nquite confusing!useful short-hand problem x %% y.\nselect every row x one values y.\nuse rewrite code :Sometimes can simplify complicated subsetting remembering De Morgan’s law: !(x & y) !x | !y, !(x | y) !x & !y.\nexample, wanted find flights weren’t delayed (arrival departure) two hours, use either following two filters:well & |, R also && ||.\nDon’t use !\n’ll learn use Section 34.4 conditional execution.Whenever start using complicated, multipart expressions filter(), consider making explicit variables instead.\nmakes much easier check work.\n’ll learn create new variables shortly.","code":"\nfilter(flights, month == 11 | month == 12)\nnov_dec <- filter(flights, month %in% c(11, 12))\nfilter(flights, !(arr_delay > 120 | dep_delay > 120))\nfilter(flights, arr_delay <= 120, dep_delay <= 120)"},{"path":"logicals-numbers.html","id":"summaries","chapter":"16 Logicals and numbers","heading":"16.3 Summaries","text":"Counts proportions logical values: sum(x > 10), mean(y == 0).\nused numeric functions, TRUE converted 1 FALSE 0.\nmakes sum() mean() useful: sum(x) gives number TRUEs x, mean(x) gives proportion.\n\nnot_cancelled <- flights %>% \n  filter(!.na(dep_delay), !.na(arr_delay))\n\n# many flights left 5am? (usually indicate delayed\n# flights previous day)\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(n_early = sum(dep_time < 500))\n#> `summarise()` grouped output 'year', 'month'. can override using `.groups` argument.\n#> <U+2029>[90m# tibble: 365 x 4<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mn_early<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       0NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2       3NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3       4NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4       3NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5       3NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6       2NA#> <U+2029>[90m# ... 359 rows<U+2029>[39mNA# proportion flights delayed hour?\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(hour_prop = mean(arr_delay > 60))\n#> `summarise()` grouped output 'year', 'month'. can override using `.groups` argument.\n#> <U+2029>[90m# tibble: 365 x 4<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mhour_prop<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1    0.072<U+2029>[4m2<U+2029>[24mNA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2    0.085<U+2029>[4m1<U+2029>[24mNA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3    0.056<U+2029>[4m7<U+2029>[24mNA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4    0.039<U+2029>[4m6<U+2029>[24mNA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5    0.034<U+2029>[4m9<U+2029>[24mNA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6    0.047<U+2029>[4m0<U+2029>[24mNA#> <U+2029>[90m# ... 359 rows<U+2029>[39mNACounts proportions logical values: sum(x > 10), mean(y == 0).\nused numeric functions, TRUE converted 1 FALSE 0.\nmakes sum() mean() useful: sum(x) gives number TRUEs x, mean(x) gives proportion.cumany() cumall()","code":"\nnot_cancelled <- flights %>% \n  filter(!is.na(dep_delay), !is.na(arr_delay))\n\n# How many flights left before 5am? (these usually indicate delayed\n# flights from the previous day)\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(n_early = sum(dep_time < 500))\n#> `summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.\n#> <U+2029>[90m# A tibble: 365 x 4<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mn_early<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1       0NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2       3NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3       4NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4       3NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5       3NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6       2NA#> <U+2029>[90m# ... with 359 more rows<U+2029>[39mNA# What proportion of flights are delayed by more than an hour?\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(hour_prop = mean(arr_delay > 60))\n#> `summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.\n#> <U+2029>[90m# A tibble: 365 x 4<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mhour_prop<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1    0.072<U+2029>[4m2<U+2029>[24mNA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2    0.085<U+2029>[4m1<U+2029>[24mNA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3    0.056<U+2029>[4m7<U+2029>[24mNA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4    0.039<U+2029>[4m6<U+2029>[24mNA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5    0.034<U+2029>[4m9<U+2029>[24mNA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6    0.047<U+2029>[4m0<U+2029>[24mNA#> <U+2029>[90m# ... with 359 more rows<U+2029>[39mNA"},{"path":"logicals-numbers.html","id":"exercises-28","chapter":"16 Logicals and numbers","heading":"16.3.1 Exercises","text":"plane, count number flights first delay greater 1 hour.","code":""},{"path":"logicals-numbers.html","id":"basic-math","chapter":"16 Logicals and numbers","heading":"16.4 Basic math","text":"many functions creating new variables can use mutate().\nkey property function must vectorised: must take vector values input, return vector number values output.\n’s way list every possible function might use, ’s selection functions frequently useful:Arithmetic operators: +, -, *, /, ^.\nvectorised, using called “recycling rules”.\none parameter shorter , automatically extended length.\nuseful one arguments single number: air_time / 60, hours * 60 + minute, etc.\nArithmetic operators also useful conjunction aggregate functions ’ll learn later.\nexample, x / sum(x) calculates proportion total, y - mean(y) computes difference mean.Arithmetic operators: +, -, *, /, ^.\nvectorised, using called “recycling rules”.\none parameter shorter , automatically extended length.\nuseful one arguments single number: air_time / 60, hours * 60 + minute, etc.Arithmetic operators also useful conjunction aggregate functions ’ll learn later.\nexample, x / sum(x) calculates proportion total, y - mean(y) computes difference mean.Modular arithmetic: %/% (integer division) %% (remainder), x == y * (x %/% y) + (x %% y).\nModular arithmetic handy tool allows break integers pieces.\nexample, flights dataset, can compute hour minute dep_time :\n\ntransmute(flights,\n  dep_time,\n  hour = dep_time %/% 100,\n  minute = dep_time %% 100\n)\n#> <U+2029>[90m# tibble: 336,776 x 3<U+2029>[39mNA#>   <U+2029>[1mdep_time<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1mminute<U+2029>[22mNA#>      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m      517     5     17NA#> <U+2029>[90m2<U+2029>[39m      533     5     33NA#> <U+2029>[90m3<U+2029>[39m      542     5     42NA#> <U+2029>[90m4<U+2029>[39m      544     5     44NA#> <U+2029>[90m5<U+2029>[39m      554     5     54NA#> <U+2029>[90m6<U+2029>[39m      554     5     54NA#> <U+2029>[90m# ... 336,770 rows<U+2029>[39mNAModular arithmetic: %/% (integer division) %% (remainder), x == y * (x %/% y) + (x %% y).\nModular arithmetic handy tool allows break integers pieces.\nexample, flights dataset, can compute hour minute dep_time :Logs: log(), log2(), log10().\nLogarithms incredibly useful transformation dealing data ranges across multiple orders magnitude.\nalso convert multiplicative relationships additive.\nelse equal, recommend using log2() ’s easy interpret: difference 1 log scale corresponds doubling original scale difference -1 corresponds halving.Logs: log(), log2(), log10().\nLogarithms incredibly useful transformation dealing data ranges across multiple orders magnitude.\nalso convert multiplicative relationships additive.else equal, recommend using log2() ’s easy interpret: difference 1 log scale corresponds doubling original scale difference -1 corresponds halving.Logical comparisons: <, <=, >, >=, !=, ==, learned earlier.\n’re complex sequence logical operations ’s often good idea store interim values new variables can check step working expected.Logical comparisons: <, <=, >, >=, !=, ==, learned earlier.\n’re complex sequence logical operations ’s often good idea store interim values new variables can check step working expected.Cumulative rolling aggregates: R provides functions running sums, products, mins maxes: cumsum(), cumprod(), cummin(), cummax(); dplyr provides cummean() cumulative means.\nneed rolling aggregates (.e. sum computed rolling window), try RcppRoll package.\n\nx <- 1:10\ncumsum(x)\n#>  [1]  1  3  6 10 15 21 28 36 45 55\ncummean(x)\n#>  [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5Cumulative rolling aggregates: R provides functions running sums, products, mins maxes: cumsum(), cumprod(), cummin(), cummax(); dplyr provides cummean() cumulative means.\nneed rolling aggregates (.e. sum computed rolling window), try RcppRoll package.","code":"\ntransmute(flights,\n  dep_time,\n  hour = dep_time %/% 100,\n  minute = dep_time %% 100\n)\n#> <U+2029>[90m# A tibble: 336,776 x 3<U+2029>[39mNA#>   <U+2029>[1mdep_time<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1mminute<U+2029>[22mNA#>      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m      517     5     17NA#> <U+2029>[90m2<U+2029>[39m      533     5     33NA#> <U+2029>[90m3<U+2029>[39m      542     5     42NA#> <U+2029>[90m4<U+2029>[39m      544     5     44NA#> <U+2029>[90m5<U+2029>[39m      554     5     54NA#> <U+2029>[90m6<U+2029>[39m      554     5     54NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA\nx <- 1:10\ncumsum(x)\n#>  [1]  1  3  6 10 15 21 28 36 45 55\ncummean(x)\n#>  [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5"},{"path":"logicals-numbers.html","id":"recycling-rules","chapter":"16 Logicals and numbers","heading":"16.4.1 Recycling rules","text":"Base R.Tidyverse.","code":""},{"path":"logicals-numbers.html","id":"summaries-1","chapter":"16 Logicals and numbers","heading":"16.5 Summaries","text":"Just using means, counts, sum can get long way, R provides many useful summary functions:Measures location: ’ve used mean(x), median(x) also useful.\nmean sum divided length; median value 50% x , 50% .\n\nnot_cancelled %>%\n  group_by(month) %>%\n  summarise(\n    med_arr_delay = median(arr_delay),\n    med_dep_delay = median(dep_delay)\n    )\n#> <U+2029>[90m# tibble: 12 x 3<U+2029>[39mNA#>   <U+2029>[1mmonth<U+2029>[22m <U+2029>[1mmed_arr_delay<U+2029>[22m <U+2029>[1mmed_dep_delay<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m         <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m         <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1            -<U+2029>[31m3<U+2029>[39m            -<U+2029>[31m2<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m     2            -<U+2029>[31m3<U+2029>[39m            -<U+2029>[31m2<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m     3            -<U+2029>[31m6<U+2029>[39m            -<U+2029>[31m1<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m     4            -<U+2029>[31m2<U+2029>[39m            -<U+2029>[31m2<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m     5            -<U+2029>[31m8<U+2029>[39m            -<U+2029>[31m1<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m     6            -<U+2029>[31m2<U+2029>[39m             0NA#> <U+2029>[90m# ... 6 rows<U+2029>[39mNA\n’s sometimes useful combine aggregation logical subsetting.\nhaven’t talked sort subsetting yet, ’ll learn Section 35.4.5.\n\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(\n    avg_delay1 = mean(arr_delay),\n    avg_delay2 = mean(arr_delay[arr_delay > 0]) # average positive delay\n  )\n#> `summarise()` grouped output 'year', 'month'. can override using `.groups` argument.\n#> <U+2029>[90m# tibble: 365 x 5<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mavg_delay1<U+2029>[22m <U+2029>[1mavg_delay2<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      12.7        32.5NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2      12.7        32.0NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3       5.73       27.7NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4      -<U+2029>[31m1<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m93<U+2029>[39m       28.3NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5      -<U+2029>[31m1<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m53<U+2029>[39m       22.6NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6       4.24       24.4NA#> <U+2029>[90m# ... 359 rows<U+2029>[39mNAMeasures location: ’ve used mean(x), median(x) also useful.\nmean sum divided length; median value 50% x , 50% .’s sometimes useful combine aggregation logical subsetting.\nhaven’t talked sort subsetting yet, ’ll learn Section 35.4.5.Measures spread: sd(x), IQR(x), mad(x).\nroot mean squared deviation, standard deviation sd(x), standard measure spread.\ninterquartile range IQR(x) median absolute deviation mad(x) robust equivalents may useful outliers.\n\n# distance destinations variable others?\nnot_cancelled %>% \n  group_by(dest) %>% \n  summarise(distance_sd = sd(distance)) %>% \n  arrange(desc(distance_sd))\n#> <U+2029>[90m# tibble: 104 x 2<U+2029>[39mNA#>   <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mdistance_sd<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m EGE         10.5 NA#> <U+2029>[90m2<U+2029>[39m SAN         10.4 NA#> <U+2029>[90m3<U+2029>[39m SFO         10.2 NA#> <U+2029>[90m4<U+2029>[39m HNL         10.0 NA#> <U+2029>[90m5<U+2029>[39m SEA          9.98NA#> <U+2029>[90m6<U+2029>[39m LAS          9.91NA#> <U+2029>[90m# ... 98 rows<U+2029>[39mNAMeasures spread: sd(x), IQR(x), mad(x).\nroot mean squared deviation, standard deviation sd(x), standard measure spread.\ninterquartile range IQR(x) median absolute deviation mad(x) robust equivalents may useful outliers.Measures rank: min(x), quantile(x, 0.25), max(x).\nQuantiles generalisation median.\nexample, quantile(x, 0.25) find value x greater 25% values, less remaining 75%.\n\n# first last flights leave day?\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(\n    first = min(dep_time),\n    last = max(dep_time)\n  )\n#> `summarise()` grouped output 'year', 'month'. can override using `.groups` argument.\n#> <U+2029>[90m# tibble: 365 x 5<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mfirst<U+2029>[22m  <U+2029>[1mlast<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1   517  <U+2029>[4m2<U+2029>[24m356NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2    42  <U+2029>[4m2<U+2029>[24m354NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3    32  <U+2029>[4m2<U+2029>[24m349NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4    25  <U+2029>[4m2<U+2029>[24m358NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5    14  <U+2029>[4m2<U+2029>[24m357NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6    16  <U+2029>[4m2<U+2029>[24m355NA#> <U+2029>[90m# ... 359 rows<U+2029>[39mNAMeasures rank: min(x), quantile(x, 0.25), max(x).\nQuantiles generalisation median.\nexample, quantile(x, 0.25) find value x greater 25% values, less remaining 75%.","code":"\nnot_cancelled %>%\n  group_by(month) %>%\n  summarise(\n    med_arr_delay = median(arr_delay),\n    med_dep_delay = median(dep_delay)\n    )\n#> <U+2029>[90m# A tibble: 12 x 3<U+2029>[39mNA#>   <U+2029>[1mmonth<U+2029>[22m <U+2029>[1mmed_arr_delay<U+2029>[22m <U+2029>[1mmed_dep_delay<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m         <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m         <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1            -<U+2029>[31m3<U+2029>[39m            -<U+2029>[31m2<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m     2            -<U+2029>[31m3<U+2029>[39m            -<U+2029>[31m2<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m     3            -<U+2029>[31m6<U+2029>[39m            -<U+2029>[31m1<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m     4            -<U+2029>[31m2<U+2029>[39m            -<U+2029>[31m2<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m     5            -<U+2029>[31m8<U+2029>[39m            -<U+2029>[31m1<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m     6            -<U+2029>[31m2<U+2029>[39m             0NA#> <U+2029>[90m# ... with 6 more rows<U+2029>[39mNA\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(\n    avg_delay1 = mean(arr_delay),\n    avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay\n  )\n#> `summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.\n#> <U+2029>[90m# A tibble: 365 x 5<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mavg_delay1<U+2029>[22m <U+2029>[1mavg_delay2<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1      12.7        32.5NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2      12.7        32.0NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3       5.73       27.7NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4      -<U+2029>[31m1<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m93<U+2029>[39m       28.3NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5      -<U+2029>[31m1<U+2029>[39m<U+2029>[31m.<U+2029>[39m<U+2029>[31m53<U+2029>[39m       22.6NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6       4.24       24.4NA#> <U+2029>[90m# ... with 359 more rows<U+2029>[39mNA\n# Why is distance to some destinations more variable than to others?\nnot_cancelled %>% \n  group_by(dest) %>% \n  summarise(distance_sd = sd(distance)) %>% \n  arrange(desc(distance_sd))\n#> <U+2029>[90m# A tibble: 104 x 2<U+2029>[39mNA#>   <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mdistance_sd<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m EGE         10.5 NA#> <U+2029>[90m2<U+2029>[39m SAN         10.4 NA#> <U+2029>[90m3<U+2029>[39m SFO         10.2 NA#> <U+2029>[90m4<U+2029>[39m HNL         10.0 NA#> <U+2029>[90m5<U+2029>[39m SEA          9.98NA#> <U+2029>[90m6<U+2029>[39m LAS          9.91NA#> <U+2029>[90m# ... with 98 more rows<U+2029>[39mNA\n# When do the first and last flights leave each day?\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(\n    first = min(dep_time),\n    last = max(dep_time)\n  )\n#> `summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.\n#> <U+2029>[90m# A tibble: 365 x 5<U+2029>[39mNA#> <U+2029>[90m# Groups:   year, month [12]<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m <U+2029>[1mfirst<U+2029>[22m  <U+2029>[1mlast<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1   517  <U+2029>[4m2<U+2029>[24m356NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     2    42  <U+2029>[4m2<U+2029>[24m354NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     3    32  <U+2029>[4m2<U+2029>[24m349NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     4    25  <U+2029>[4m2<U+2029>[24m358NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     5    14  <U+2029>[4m2<U+2029>[24m357NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     6    16  <U+2029>[4m2<U+2029>[24m355NA#> <U+2029>[90m# ... with 359 more rows<U+2029>[39mNA"},{"path":"logicals-numbers.html","id":"exercises-29","chapter":"16 Logicals and numbers","heading":"16.5.1 Exercises","text":"Brainstorm least 5 different ways assess typical delay characteristics group flights.\nConsider following scenarios:\nflight 15 minutes early 50% time, 15 minutes late 50% time.\nflight always 10 minutes late.\nflight 30 minutes early 50% time, 30 minutes late 50% time.\n99% time flight time.\n1% time ’s 2 hours late.\nimportant: arrival delay departure delay?Brainstorm least 5 different ways assess typical delay characteristics group flights.\nConsider following scenarios:flight 15 minutes early 50% time, 15 minutes late 50% time.flight 15 minutes early 50% time, 15 minutes late 50% time.flight always 10 minutes late.flight always 10 minutes late.flight 30 minutes early 50% time, 30 minutes late 50% time.flight 30 minutes early 50% time, 30 minutes late 50% time.99% time flight time.\n1% time ’s 2 hours late.99% time flight time.\n1% time ’s 2 hours late.important: arrival delay departure delay?","code":""},{"path":"logicals-numbers.html","id":"floating-point","chapter":"16 Logicals and numbers","heading":"16.6 Floating point","text":"’s another common problem might encounter using ==: floating point numbers.\nresults might surprise !Computers use finite precision arithmetic (obviously can’t store infinite number digits!) remember every number see approximation.\nInstead relying ==, use near():","code":"\n(sqrt(2) ^ 2) == 2\n#> [1] FALSE\n(1 / 49 * 49) == 1\n#> [1] FALSE\nnear(sqrt(2) ^ 2,  2)\n#> [1] TRUE\nnear(1 / 49 * 49, 1)\n#> [1] TRUE"},{"path":"logicals-numbers.html","id":"exercises-30","chapter":"16 Logicals and numbers","heading":"16.7 Exercises","text":"trigonometric functions R provide?","code":""},{"path":"missing-values.html","id":"missing-values","chapter":"17 Missing values","heading":"17 Missing values","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"missing-values.html","id":"introduction-10","chapter":"17 Missing values","heading":"17.1 Introduction","text":"Missing topics:Missing values generated matching data frames (.e. left_join() anti_join()Missing values generated matching data frames (.e. left_join() anti_join()Last observation carried forward tidy::fill()Last observation carried forward tidy::fill()coalesce() na_if()coalesce() na_if()","code":"\nlibrary(tidyverse)\n#> -- <U+2029>[1mAttaching packages<U+2029>[22m --------------------------------------- tidyverse 1.3.1 --NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mggplot2<U+2029>[39m 3.3.5          <U+2029>[32mv<U+2029>[39m <U+2029>[34mpurrr  <U+2029>[39m 0.3.4     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtibble <U+2029>[39m 3.1.2          <U+2029>[32mv<U+2029>[39m <U+2029>[34mdplyr  <U+2029>[39m 1.0.7     NA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mtidyr  <U+2029>[39m 1.1.3          <U+2029>[32mv<U+2029>[39m <U+2029>[34mstringr<U+2029>[39m 1.4.0.<U+2029>[31m9000<U+2029>[39mNA#> <U+2029>[32mv<U+2029>[39m <U+2029>[34mreadr  <U+2029>[39m 2.0.1          <U+2029>[32mv<U+2029>[39m <U+2029>[34mforcats<U+2029>[39m 0.5.1NA#> -- <U+2029>[1mConflicts<U+2029>[22m ------------------------------------------ tidyverse_conflicts() --NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mfilter()<U+2029>[39m masks <U+2029>[34mstats<U+2029>[39m::filter()NA#> <U+2029>[31mx<U+2029>[39m <U+2029>[34mdplyr<U+2029>[39m::<U+2029>[32mlag()<U+2029>[39m    masks <U+2029>[34mstats<U+2029>[39m::lag()NA"},{"path":"missing-values.html","id":"basics","chapter":"17 Missing values","heading":"17.2 Basics","text":"","code":""},{"path":"missing-values.html","id":"missing-values-filter","chapter":"17 Missing values","heading":"17.2.1 Missing values","text":"One important feature R can make comparison tricky missing values, NAs (“availables”).\nNA represents unknown value missing values “contagious”: almost operation involving unknown value also unknown.confusing result one:’s easiest understand true bit context:want determine value missing, use .na():","code":"\nNA > 5\n#> [1] NA\n10 == NA\n#> [1] NA\nNA + 10\n#> [1] NA\nNA / 2\n#> [1] NA\nNA == NA\n#> [1] NA\n# Let x be Mary's age. We don't know how old she is.\nx <- NA\n\n# Let y be John's age. We don't know how old he is.\ny <- NA\n\n# Are John and Mary the same age?\nx == y\n#> [1] NA\n# We don't know!\nis.na(x)\n#> [1] TRUE"},{"path":"missing-values.html","id":"exercises-31","chapter":"17 Missing values","heading":"17.2.2 Exercises","text":"many flights missing dep_time?\nvariables missing?\nmight rows represent?many flights missing dep_time?\nvariables missing?\nmight rows represent?use arrange() sort missing values start?\n(Hint: use !.na()).use arrange() sort missing values start?\n(Hint: use !.na()).Come another approach give output not_cancelled %>% count(dest) not_cancelled %>% count(tailnum, wt = distance) (without using count()).Come another approach give output not_cancelled %>% count(dest) not_cancelled %>% count(tailnum, wt = distance) (without using count()).Look number cancelled flights per day.\npattern?\nproportion cancelled flights related average delay?Look number cancelled flights per day.\npattern?\nproportion cancelled flights related average delay?","code":""},{"path":"missing-values.html","id":"missing-values-tidy","chapter":"17 Missing values","heading":"17.3 Explicit vs implicit missing values","text":"Changing representation dataset brings important subtlety missing values.\nSurprisingly, value can missing one two possible ways:Explicitly, .e. flagged NA.Implicitly, .e. simply present data.Let’s illustrate idea simple data set:two missing values dataset:return fourth quarter 2015 explicitly missing, cell value instead contains NA.return fourth quarter 2015 explicitly missing, cell value instead contains NA.return first quarter 2016 implicitly missing, simply appear dataset.return first quarter 2016 implicitly missing, simply appear dataset.One way think difference Zen-like koan: explicit missing value presence absence; implicit missing value absence presence.way dataset represented can make implicit values explicit.\nexample, can make implicit missing value explicit putting years columns:explicit missing values may important representations data, can set values_drop_na = TRUE pivot_longer() turn explicit missing values implicit:Another important tool making missing values explicit tidy data complete():complete() takes set columns, finds unique combinations.\nensures original dataset contains values, filling explicit NAs necessary.’s one important tool know working missing values.\nSometimes data source primarily used data entry, missing values indicate previous value carried forward:can fill missing values fill().\ntakes set columns want missing values replaced recent non-missing value (sometimes called last observation carried forward).","code":"\nstocks <- tibble(\n  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),\n  qtr    = c(   1,    2,    3,    4,    2,    3,    4),\n  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)\n)\nstocks %>%\n  pivot_wider(names_from = year, values_from = return)\n#> <U+2029>[90m# A tibble: 4 x 3<U+2029>[39mNA#>     <U+2029>[1mqtr<U+2029>[22m <U+2029>[1m`2015`<U+2029>[22m <U+2029>[1m`2016`<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1   1.88  <U+2029>[31mNA<U+2029>[39m   NA#> <U+2029>[90m2<U+2029>[39m     2   0.59   0.92NA#> <U+2029>[90m3<U+2029>[39m     3   0.35   0.17NA#> <U+2029>[90m4<U+2029>[39m     4  <U+2029>[31mNA<U+2029>[39m      2.66NA\nstocks %>%\n  pivot_wider(names_from = year, values_from = return) %>%\n  pivot_longer(\n    cols = c(`2015`, `2016`),\n    names_to = \"year\",\n    values_to = \"return\",\n    values_drop_na = TRUE\n  )\n#> <U+2029>[90m# A tibble: 6 x 3<U+2029>[39mNA#>     <U+2029>[1mqtr<U+2029>[22m <U+2029>[1myear<U+2029>[22m  <U+2029>[1mreturn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1 2015    1.88NA#> <U+2029>[90m2<U+2029>[39m     2 2015    0.59NA#> <U+2029>[90m3<U+2029>[39m     2 2016    0.92NA#> <U+2029>[90m4<U+2029>[39m     3 2015    0.35NA#> <U+2029>[90m5<U+2029>[39m     3 2016    0.17NA#> <U+2029>[90m6<U+2029>[39m     4 2016    2.66NA\nstocks %>%\n  complete(year, qtr)\n#> <U+2029>[90m# A tibble: 8 x 3<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m   <U+2029>[1mqtr<U+2029>[22m <U+2029>[1mreturn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m015     1   1.88NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m015     2   0.59NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m015     3   0.35NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m015     4  <U+2029>[31mNA<U+2029>[39m   NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m016     1  <U+2029>[31mNA<U+2029>[39m   NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m016     2   0.92NA#> <U+2029>[90m# ... with 2 more rows<U+2029>[39mNA\ntreatment <- tribble(\n  ~person,           ~treatment, ~response,\n  \"Derrick Whitmore\", 1,         7,\n  NA,                 2,         10,\n  NA,                 3,         9,\n  \"Katherine Burke\",  1,         4\n)\ntreatment %>%\n  fill(person)\n#> <U+2029>[90m# A tibble: 4 x 3<U+2029>[39mNA#>   <U+2029>[1mperson<U+2029>[22m           <U+2029>[1mtreatment<U+2029>[22m <U+2029>[1mresponse<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Derrick Whitmore         1        7NA#> <U+2029>[90m2<U+2029>[39m Derrick Whitmore         2       10NA#> <U+2029>[90m3<U+2029>[39m Derrick Whitmore         3        9NA#> <U+2029>[90m4<U+2029>[39m Katherine Burke          1        4NA"},{"path":"missing-values.html","id":"exercises-32","chapter":"17 Missing values","heading":"17.3.1 Exercises","text":"Compare contrast fill arguments pivot_wider() complete().Compare contrast fill arguments pivot_wider() complete().direction argument fill() ?direction argument fill() ?","code":""},{"path":"missing-values.html","id":"dplyr-verbs","chapter":"17 Missing values","heading":"17.4 dplyr verbs","text":"filter() includes rows condition TRUE; excludes FALSE NA values.\nwant preserve missing values, ask explicitly:Missing values always sorted end:","code":"\ndf <- tibble(x = c(1, NA, 3))\nfilter(df, x > 1)\n#> <U+2029>[90m# A tibble: 1 x 1<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     3NAfilter(df, is.na(x) | x > 1)\n#> <U+2029>[90m# A tibble: 2 x 1<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m    <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m     3NA\ndf <- tibble(x = c(5, 2, NA))\narrange(df, x)\n#> <U+2029>[90m# A tibble: 3 x 1<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     2NA#> <U+2029>[90m2<U+2029>[39m     5NA#> <U+2029>[90m3<U+2029>[39m    <U+2029>[31mNA<U+2029>[39mNAarrange(df, desc(x))\n#> <U+2029>[90m# A tibble: 3 x 1<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     5NA#> <U+2029>[90m2<U+2029>[39m     2NA#> <U+2029>[90m3<U+2029>[39m    <U+2029>[31mNA<U+2029>[39mNA"},{"path":"missing-values.html","id":"exercises-33","chapter":"17 Missing values","heading":"17.5 Exercises","text":"NA ^ 0 missing? NA | TRUE missing? FALSE & NA missing? Can figure general rule? (NA * 0 tricky counterexample!)","code":""},{"path":"strings.html","id":"strings","chapter":"18 Strings","heading":"18 Strings","text":"reading work--progress second edition R Data Science. chapter currently undergoing heavy restructuring may confusing incomplete. can find polished first edition https://r4ds..co.nz.","code":""},{"path":"strings.html","id":"introduction-11","chapter":"18 Strings","heading":"18.1 Introduction","text":"chapter introduces strings.\n’ll learn basics strings work R create “hand”.\nBig topic spread three chapters: ’ll focus basic mechanics, Chapter 19 ’ll dive details regular expressions sometimes cryptic language describing patterns strings, ’ll return strings later Chapter 37 think programming perspective (rather data analysis perspective).\n’ll finish discussion new challenges arise working non-English strings.base R contains functions allow us perform pretty much operations described chapter, ’re going use stringr package.\nstringr carefully designed consistent possible knowledge gained one function can easily transferred next.\nstringr functions start str_ prefix.\nparticularly useful use RStudio, typing str_ trigger autocomplete, allowing see stringr’s functions:","code":""},{"path":"strings.html","id":"prerequisites-8","chapter":"18 Strings","heading":"18.1.1 Prerequisites","text":"chapter focus stringr package string manipulation, part core tidyverse.\n’ll also work babynames dataset.","code":"\nlibrary(tidyverse)\nlibrary(babynames)"},{"path":"strings.html","id":"creating-a-string","chapter":"18 Strings","heading":"18.2 Creating a string","text":"begin, let’s discuss mechanics creating string.\n’ve created strings passing earlier book, didn’t discuss details.\nFirst, two basic ways create string: using either single quotes (') double quotes (\").\nUnlike languages, difference behaviour.\nrecommend always using \", unless want create string contains multiple \".forget close quote, ’ll see +, continuation character:happen , press Escape try .","code":"\nstring1 <- \"This is a string\"\nstring2 <- 'If I want to include a \"quote\" inside a string, I use single quotes'> \"This is a string without a closing quote\n+ \n+ \n+ HELP I'M STUCK"},{"path":"strings.html","id":"escapes","chapter":"18 Strings","heading":"18.2.1 Escapes","text":"include literal single double quote string can use \\ “escape” :means want include literal backslash, ’ll need double : \"\\\\\":Beware printed representation string string , printed representation shows escapes.\nsee raw contents string, use str_view():","code":"\ndouble_quote <- \"\\\"\" # or '\"'\nsingle_quote <- '\\'' # or \"'\"\nbackslash <- \"\\\\\"\nx <- c(single_quote, double_quote, backslash)\nx\n#> [1] \"'\"  \"\\\"\" \"\\\\\"\nstr_view(x)\n#> '\n#> \"\n#> \\"},{"path":"strings.html","id":"raw-strings","chapter":"18 Strings","heading":"18.2.2 Raw strings","text":"Creating string multiple quotes backslashes gets confusing quickly.\nexample, lets create string contains contents chunk define double_quote single_quote variables:can instead use raw string4 reduce amount escaping:raw string starts r\"( finishes )\".\nstring contains )\" can instead use r\"[]\" r\"{}\", ’s still enough, can insert number dashes make opening closing pairs unique, e.g. `r\"--()--\", `r\"---()---\",etc.","code":"\ntricky <- \"double_quote <- \\\"\\\\\\\"\\\" # or '\\\"'\nsingle_quote <- '\\\\'' # or \\\"'\\\"\"\nstr_view(tricky)\n#> double_quote <- \"\\\"\" # or '\"'\n#> single_quote <- '\\'' # or \"'\"\ntricky <- r\"(double_quote <- \"\\\"\" # or '\"'\nsingle_quote <- '\\'' # or \"'\"\n)\"\nstr_view(tricky)\n#> double_quote <- \"\\\"\" # or '\"'\n#> single_quote <- '\\'' # or \"'\""},{"path":"strings.html","id":"other-special-characters","chapter":"18 Strings","heading":"18.2.3 Other special characters","text":"well \\\", \\', \\\\ handful special characters may come handy. common \"\\n\", newline, \"\\t\", tab, can see complete list ?'\"'.’ll also sometimes see strings containing Unicode escapes start \\u \\U.\nway writing non-English characters works systems:","code":"\nx <- c(\"\\u00b5\", \"\\U0001f604\")\nx\n#> [1] \"μ\"  \"<U+0001F604>\"str_view(x)\n#> μ#> <U+0001F604>"},{"path":"strings.html","id":"combining-strings","chapter":"18 Strings","heading":"18.3 Combining strings","text":"Use str_c()5 join together multiple character vectors single vector:str_c() obeys usual recycling rules:like functions R, missing values contagious.\ncan use coalesce() replace missing values value choosing:Since str_c() creates vector, ’ll usually use mutate():Another powerful way combining strings glue package.\ncan either use glue::glue() directly call via str_glue() wrapper stringr provides .\nGlue works little differently methods: give single string within string use {} indicate existing variables evaluated:Like str_c(), str_glue() pairs well mutate():can use valid R code inside {}, ’s good idea pull complex calculations variables can easily check work.","code":"\nstr_c(\"x\", \"y\")\n#> [1] \"xy\"\nstr_c(\"x\", \"y\", \"z\")\n#> [1] \"xyz\"\nnames <- c(\"Timothy\", \"Dewey\", \"Mable\")\nstr_c(\"Hi \", names, \"!\")\n#> [1] \"Hi Timothy!\" \"Hi Dewey!\"   \"Hi Mable!\"\nx <- c(\"abc\", NA)\nstr_c(\"|-\", x, \"-|\")\n#> [1] \"|-abc-|\" NA\nstr_c(\"|-\", coalesce(x, \"\"), \"-|\")\n#> [1] \"|-abc-|\" \"|--|\"\nstarwars %>% \n  mutate(greeting = str_c(\"Hi! I'm \", name, \".\"), .after = name)\n#> <U+2029>[90m# A tibble: 87 x 15<U+2029>[39mNA#>   <U+2029>[1mname<U+2029>[22m   <U+2029>[1mgreeting<U+2029>[22m  <U+2029>[1mheight<U+2029>[22m  <U+2029>[1mmass<U+2029>[22m <U+2029>[1mhair_color<U+2029>[22m <U+2029>[1mskin_color<U+2029>[22m <U+2029>[1meye_color<U+2029>[22m <U+2029>[1mbirth_year<U+2029>[22m <U+2029>[1msex<U+2029>[22m  NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Luke ~ Hi! I'm ~    172    77 blond      fair       blue            19   male NA#> <U+2029>[90m2<U+2029>[39m C-3PO  Hi! I'm ~    167    75 <U+2029>[31mNA<U+2029>[39m         gold       yellow         112   none NA#> <U+2029>[90m3<U+2029>[39m R2-D2  Hi! I'm ~     96    32 <U+2029>[31mNA<U+2029>[39m         white, bl~ red             33   none NA#> <U+2029>[90m4<U+2029>[39m Darth~ Hi! I'm ~    202   136 none       white      yellow          41.9 male NA#> <U+2029>[90m5<U+2029>[39m Leia ~ Hi! I'm ~    150    49 brown      light      brown           19   fema~NA#> <U+2029>[90m6<U+2029>[39m Owen ~ Hi! I'm ~    178   120 brown, gr~ light      blue            52   male NA#> <U+2029>[90m# ... with 81 more rows, and 6 more variables: <U+2029>[1mgender<U+2029>[22m <chr>, <U+2029>[1mhomeworld<U+2029>[22m <chr>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1mspecies<U+2029>[22m <chr>, <U+2029>[1mfilms<U+2029>[22m <list>, <U+2029>[1mvehicles<U+2029>[22m <list>, <U+2029>[1mstarships<U+2029>[22m <list><U+2029>[39mNA\nstr_glue(\"|-{x}-|\")\n#> |-abc-|\n#> |-NA-|\nstarwars %>% \n  mutate(\n    intro = str_glue(\"Hi! My is {name} and I'm a {species} from {homeworld}\"),\n    .keep = \"none\"\n  )\n#> <U+2029>[90m# A tibble: 87 x 1<U+2029>[39mNA#>   <U+2029>[1mintro<U+2029>[22m                                                 NA#>   <U+2029>[3m<U+2029>[90m<glue><U+2029>[39m<U+2029>[23m                                                NA#> <U+2029>[90m1<U+2029>[39m Hi! My is Luke Skywalker and I'm a Human from TatooineNA#> <U+2029>[90m2<U+2029>[39m Hi! My is C-3PO and I'm a Droid from Tatooine         NA#> <U+2029>[90m3<U+2029>[39m Hi! My is R2-D2 and I'm a Droid from Naboo            NA#> <U+2029>[90m4<U+2029>[39m Hi! My is Darth Vader and I'm a Human from Tatooine   NA#> <U+2029>[90m5<U+2029>[39m Hi! My is Leia Organa and I'm a Human from Alderaan   NA#> <U+2029>[90m6<U+2029>[39m Hi! My is Owen Lars and I'm a Human from Tatooine     NA#> <U+2029>[90m# ... with 81 more rows<U+2029>[39mNA"},{"path":"strings.html","id":"length-and-subsetting","chapter":"18 Strings","heading":"18.4 Length and subsetting","text":"’s natural think letters make individual string.\n(note idea “letter” isn’t natural fit every language, ’ll come back Section 18.14).\nexample, str_length() tells length string characters:use count() find distribution lengths US babynames, filter() look longest names:can extract parts string using str_sub(string, start, end).\nstart end arguments inclusive, length returned string end - start + 1:can use negative values count back end string: -1 last character, -2 second last character, etc.Note str_sub() won’t fail string short: just return much possible:use str_sub() mutate() find first last letter name:Sometimes ’ll get column ’s made individual fixed length strings joined together:can extract columns using str_sub():use separate() helper function:Note give separate() three columns two positions — ’s ’re telling separate() break string.TODO: draw diagram emphasise ’s space characters.Later , ’ll come back two related problems: components varying length separated character, varying number components want split rows, rather columns.","code":"\nstr_length(c(\"a\", \"R for data science\", NA))\n#> [1]  1 18 NA\nbabynames %>%\n  count(length = str_length(name), wt = n)\n#> <U+2029>[90m# A tibble: 14 x 2<U+2029>[39mNA#>   <U+2029>[1mlength<U+2029>[22m        <U+2029>[1mn<U+2029>[22mNA#>    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m      2   <U+2029>[4m3<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m8<U+2029>[24m150NA#> <U+2029>[90m2<U+2029>[39m      3  8<U+2029>[4m5<U+2029>[24m<U+2029>[4m8<U+2029>[24m<U+2029>[4m9<U+2029>[24m596NA#> <U+2029>[90m3<U+2029>[39m      4 48<U+2029>[4m5<U+2029>[24m<U+2029>[4m0<U+2029>[24m<U+2029>[4m6<U+2029>[24m739NA#> <U+2029>[90m4<U+2029>[39m      5 87<U+2029>[4m0<U+2029>[24m<U+2029>[4m1<U+2029>[24m<U+2029>[4m1<U+2029>[24m607NA#> <U+2029>[90m5<U+2029>[39m      6 90<U+2029>[4m7<U+2029>[24m<U+2029>[4m4<U+2029>[24m<U+2029>[4m9<U+2029>[24m404NA#> <U+2029>[90m6<U+2029>[39m      7 72<U+2029>[4m1<U+2029>[24m<U+2029>[4m2<U+2029>[24m<U+2029>[4m0<U+2029>[24m767NA#> <U+2029>[90m# ... with 8 more rows<U+2029>[39mNAbabynames %>% \n  filter(str_length(name) == 15) %>% \n  count(name, wt = n, sort = TRUE)\n#> <U+2029>[90m# A tibble: 34 x 2<U+2029>[39mNA#>   <U+2029>[1mname<U+2029>[22m                <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m           <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Franciscojavier   123NA#> <U+2029>[90m2<U+2029>[39m Christopherjohn   118NA#> <U+2029>[90m3<U+2029>[39m Johnchristopher   118NA#> <U+2029>[90m4<U+2029>[39m Christopherjame   108NA#> <U+2029>[90m5<U+2029>[39m Christophermich    52NA#> <U+2029>[90m6<U+2029>[39m Ryanchristopher    45NA#> <U+2029>[90m# ... with 28 more rows<U+2029>[39mNA\nx <- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 1, 3)\n#> [1] \"App\" \"Ban\" \"Pea\"\nstr_sub(x, -3, -1)\n#> [1] \"ple\" \"ana\" \"ear\"\nstr_sub(\"a\", 1, 5)\n#> [1] \"a\"\nbabynames %>% \n  mutate(\n    first = str_sub(name, 1, 1),\n    last = str_sub(name, -1, -1)\n  )\n#> <U+2029>[90m# A tibble: 1,924,665 x 7<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1msex<U+2029>[22m   <U+2029>[1mname<U+2029>[22m          <U+2029>[1mn<U+2029>[22m   <U+2029>[1mprop<U+2029>[22m <U+2029>[1mfirst<U+2029>[22m <U+2029>[1mlast<U+2029>[22m NA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Mary       <U+2029>[4m7<U+2029>[24m065 0.072<U+2029>[4m4<U+2029>[24m M     y    NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Anna       <U+2029>[4m2<U+2029>[24m604 0.026<U+2029>[4m7<U+2029>[24m A     a    NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Emma       <U+2029>[4m2<U+2029>[24m003 0.020<U+2029>[4m5<U+2029>[24m E     a    NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Elizabeth  <U+2029>[4m1<U+2029>[24m939 0.019<U+2029>[4m9<U+2029>[24m E     h    NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Minnie     <U+2029>[4m1<U+2029>[24m746 0.017<U+2029>[4m9<U+2029>[24m M     e    NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Margaret   <U+2029>[4m1<U+2029>[24m578 0.016<U+2029>[4m2<U+2029>[24m M     t    NA#> <U+2029>[90m# ... with 1,924,659 more rows<U+2029>[39mNA\ndf <- tribble(\n  ~ sex_year_age,\n  \"M200115\",\n  \"F201503\",\n)\ndf %>% mutate(\n  sex = str_sub(sex_year_age, 1, 1),\n  year = str_sub(sex_year_age, 2, 5),\n  age = str_sub(sex_year_age, 6, 7),\n)\n#> <U+2029>[90m# A tibble: 2 x 4<U+2029>[39mNA#>   <U+2029>[1msex_year_age<U+2029>[22m <U+2029>[1msex<U+2029>[22m   <U+2029>[1myear<U+2029>[22m  <U+2029>[1mage<U+2029>[22m  NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m        <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m M200115      M     2001  15   NA#> <U+2029>[90m2<U+2029>[39m F201503      F     2015  03NA\ndf %>% \n  separate(sex_year_age, c(\"sex\", \"year\", \"age\"), c(1, 5))\n#> <U+2029>[90m# A tibble: 2 x 3<U+2029>[39mNA#>   <U+2029>[1msex<U+2029>[22m   <U+2029>[1myear<U+2029>[22m  <U+2029>[1mage<U+2029>[22m  NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m M     2001  15   NA#> <U+2029>[90m2<U+2029>[39m F     2015  03NA"},{"path":"strings.html","id":"exercises-34","chapter":"18 Strings","heading":"18.4.1 Exercises","text":"Use str_length() str_sub() extract middle letter baby name. string even number characters?","code":""},{"path":"strings.html","id":"long-strings","chapter":"18 Strings","heading":"18.5 Long strings","text":"Sometimes reason care length string ’re trying fit label.\nstringr provides two useful tools cases string long:str_trunc(x, 20) ensures string longer 20 characters, replacing thing long ….str_trunc(x, 20) ensures string longer 20 characters, replacing thing long ….str_wrap(x, 20) wraps string introducing new lines line 20 characters (doesn’t hyphenate, however, word longer 20 characters make longer time)str_wrap(x, 20) wraps string introducing new lines line 20 characters (doesn’t hyphenate, however, word longer 20 characters make longer time)","code":"\nx <- \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n\nstr_trunc(x, 30)\n#> [1] \"Lorem ipsum dolor sit amet,...\"\nstr_view(str_wrap(x, 30))\n#> Lorem ipsum dolor sit amet,\n#> consectetur adipiscing\n#> elit, sed do eiusmod tempor\n#> incididunt ut labore et dolore\n#> magna aliqua. Ut enim ad\n#> minim veniam, quis nostrud\n#> exercitation ullamco laboris\n#> nisi ut aliquip ex ea commodo\n#> consequat."},{"path":"strings.html","id":"string-summaries","chapter":"18 Strings","heading":"18.6 String summaries","text":"str_c() combines multiple character vectors single character vector; output length input.\nrelated function str_flatten(): takes character vector returns single string:Just like sum() mean() take vector numbers return single number, str_flatten() takes character vector returns single string.\nmakes str_flatten() summary function strings, ’ll often pair summarise():","code":"\nstr_flatten(c(\"x\", \"y\", \"z\"))\n#> [1] \"xyz\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \")\n#> [1] \"x, y, z\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \", \", and \")\n#> [1] \"x, y, and z\"\ndf <- tribble(\n  ~ name, ~ fruit,\n  \"Carmen\", \"banana\",\n  \"Carmen\", \"apple\",\n  \"Marvin\", \"nectarine\",\n  \"Terence\", \"cantaloupe\",\n  \"Terence\", \"papaya\",\n  \"Terence\", \"madarine\"\n)\ndf %>%\n  group_by(name) %>% \n  summarise(fruits = str_flatten(fruit, \", \"))\n#> <U+2029>[90m# A tibble: 3 x 2<U+2029>[39mNA#>   <U+2029>[1mname<U+2029>[22m    <U+2029>[1mfruits<U+2029>[22m                      NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                       NA#> <U+2029>[90m1<U+2029>[39m Carmen  banana, apple               NA#> <U+2029>[90m2<U+2029>[39m Marvin  nectarine                   NA#> <U+2029>[90m3<U+2029>[39m Terence cantaloupe, papaya, madarineNA"},{"path":"strings.html","id":"detect-matches","chapter":"18 Strings","heading":"18.7 Detect matches","text":"determine character vector matches pattern, use str_detect().\nreturns logical vector length input:makes logical pairing filter().\nfollowing example returns names contain lower-case “x”:Remember use logical vector numeric context, FALSE becomes 0 TRUE becomes 1.\nmeans can use summarise() sum() mean() str_detect() want answer questions prevalence patterns.\nexample, following snippet, gives proportion names containing “x” year:(Note gives us proportion names contain x; wanted proportion babies given name containing x, ’d need perform weighted mean).variation str_detect() str_count(): rather simple yes , tells many matches string:’s natural use str_count() mutate():","code":"\nx <- c(\"apple\", \"banana\", \"pear\")\nstr_detect(x, \"e\")\n#> [1]  TRUE FALSE  TRUE\nbabynames %>% filter(str_detect(name, \"x\"))\n#> <U+2029>[90m# A tibble: 16,317 x 5<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1msex<U+2029>[22m   <U+2029>[1mname<U+2029>[22m          <U+2029>[1mn<U+2029>[22m      <U+2029>[1mprop<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Roxie        62 0.000<U+2029>[4m6<U+2029>[24m<U+2029>[4m3<U+2029>[24m<U+2029>[4m5<U+2029>[24m NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Dixie        15 0.000<U+2029>[4m1<U+2029>[24m<U+2029>[4m5<U+2029>[24m<U+2029>[4m4<U+2029>[24m NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Roxanna       9 0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m9<U+2029>[24m<U+2029>[4m2<U+2029>[24m2NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 F     Texas         5 0.000<U+2029>[4m0<U+2029>[24m<U+2029>[4m5<U+2029>[24m<U+2029>[4m1<U+2029>[24m2NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 M     Alexander   211 0.001<U+2029>[4m7<U+2029>[24m<U+2029>[4m8<U+2029>[24m  NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m1<U+2029>[24m880 M     Alex        147 0.001<U+2029>[4m2<U+2029>[24m<U+2029>[4m4<U+2029>[24m  NA#> <U+2029>[90m# ... with 16,311 more rows<U+2029>[39mNA\nbabynames %>% \n  group_by(year) %>% \n  summarise(prop_x = mean(str_detect(name, \"x\"))) %>% \n  ggplot(aes(year, prop_x)) + \n  geom_line()\nstr_count(x, \"p\")\n#> [1] 2 0 1\nbabynames %>% \n  distinct(name) %>% \n  mutate(\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#> <U+2029>[90m# A tibble: 97,310 x 3<U+2029>[39mNA#>   <U+2029>[1mname<U+2029>[22m      <U+2029>[1mvowels<U+2029>[22m <U+2029>[1mconsonants<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Mary           1          3NA#> <U+2029>[90m2<U+2029>[39m Anna           1          3NA#> <U+2029>[90m3<U+2029>[39m Emma           1          3NA#> <U+2029>[90m4<U+2029>[39m Elizabeth      3          6NA#> <U+2029>[90m5<U+2029>[39m Minnie         3          3NA#> <U+2029>[90m6<U+2029>[39m Margaret       3          5NA#> <U+2029>[90m# ... with 97,304 more rows<U+2029>[39mNA"},{"path":"strings.html","id":"exercises-35","chapter":"18 Strings","heading":"18.7.1 Exercises","text":"word highest number vowels? word highest proportion vowels? (Hint: denominator?)","code":""},{"path":"strings.html","id":"introduction-to-regular-expressions","chapter":"18 Strings","heading":"18.8 Introduction to regular expressions","text":"can continue need discuss second argument str_detect() — pattern want match.\n, used simple string, pattern actually much richer tool called regular expression.\nregular expression uses special characters match string patterns.\nexample, . match character, \".\" match string contains followed another character:str_view() shows regular expressions help understand ’s happening:Regular expressions powerful flexible language ’ll come back Chapter 19.\n’ll use important components syntax learn stringr tools working patterns.three useful quantifiers can applied pattern: ? makes pattern option (.e. matches 0 1 times), + lets pattern repeat (ie. matches least ), * lets pattern optional repeat (.e. matches number times, including 0).ab? match “”, optionally followed bab? match “”, optionally followed bab+ matches “”, followed least one bab+ matches “”, followed least one bab* matches “”, followed number bsab* matches “”, followed number bsYou can use () control precedence:(ab)? optionally matches “ab”(ab)? optionally matches “ab”(ab)+ matches one “ab” repeats(ab)+ matches one “ab” repeatsThere various alternatives . match restricted set characters.\nOne useful operator character class: [abcd] match “”, “b”, “c”, “d”; [^abcd] matches anything except “”, “b”, “c”, “d”.can opt-regular expression rules using fixed:Note fixed strings regular expressions case sensitive default.\ncan opt setting ignore_case = TRUE.’ll come back case later, ’s trivial many languages.","code":"\nstr_detect(c(\"a\", \"ab\", \"ae\", \"bd\", \"ea\", \"eab\"), \"a.\")\n#> [1] FALSE  TRUE  TRUE FALSE FALSE  TRUE\nstr_view(c(\"a\", \"ab\", \"ae\", \"bd\", \"ea\", \"eab\"), \"a.\")\n#> a\n#> <U+2029>[36m<ab><U+2029>[39mNA#> <U+2029>[36m<ae><U+2029>[39mNA#> bd\n#> ea\n#> e<U+2029>[36m<ab><U+2029>[39mNA\nstr_view(c(\"aba\", \"ababab\", \"abbbbbb\"), \"ab+\")\n#> <U+2029>[36m<ab><U+2029>[39maNA#> <U+2029>[36m<ab><U+2029>[39mababNA#> <U+2029>[36m<abbbbbb><U+2029>[39mNAstr_view(c(\"aba\", \"ababab\", \"abbbbbb\"), \"(ab)+\")\n#> <U+2029>[36m<ab><U+2029>[39maNA#> <U+2029>[36m<ababab><U+2029>[39mNA#> <U+2029>[36m<ab><U+2029>[39mbbbbbNA\nstr_view(c(\"\", \"a\", \".\"), fixed(\".\"))\n#> \n#> a\n#> <U+2029>[36m<.><U+2029>[39mNA\nstr_view_all(\"x  X  xy\", \"X\")\n#> x  <U+2029>[36m<X><U+2029>[39m  xyNAstr_view_all(\"x  X  xy\", fixed(\"X\", ignore_case = TRUE))\n#> <U+2029>[36m<x><U+2029>[39m  <U+2029>[36m<X><U+2029>[39m  <U+2029>[36m<x><U+2029>[39myNAstr_view_all(\"x  X  xy\", regex(\".Y\", ignore_case = TRUE))\n#> x  X  <U+2029>[36m<xy><U+2029>[39mNA"},{"path":"strings.html","id":"exercises-36","chapter":"18 Strings","heading":"18.8.1 Exercises","text":"following challenges, try solving using single regular expression, combination multiple str_detect() calls.\nFind words start end x.\nFind words start vowel end consonant.\nwords contain least one different vowel?\nfollowing challenges, try solving using single regular expression, combination multiple str_detect() calls.Find words start end x.Find words start vowel end consonant.words contain least one different vowel?","code":""},{"path":"strings.html","id":"replacing-matches","chapter":"18 Strings","heading":"18.9 Replacing matches","text":"str_replace_all() allow replace matches new strings.\nsimplest use replace pattern fixed string:str_replace_all() can perform multiple replacements supplying named vector.\nname gives regular expression match, value gives replacement.str_remove_all() short cut str_replace_all(x, pattern, \"\") — removes matching patterns string.Use mutate()Using pipe inside mutate.\nRecommendation make function, think testing — don’t need formal tests, useful build set positive negative test cases .","code":"\nx <- c(\"apple\", \"pear\", \"banana\")\nstr_replace_all(x, \"[aeiou]\", \"-\")\n#> [1] \"-ppl-\"  \"p--r\"   \"b-n-n-\"\nx <- c(\"1 house\", \"1 person has 2 cars\", \"3 people\")\nstr_replace_all(x, c(\"1\" = \"one\", \"2\" = \"two\", \"3\" = \"three\"))\n#> [1] \"one house\"               \"one person has two cars\"\n#> [3] \"three people\""},{"path":"strings.html","id":"exercises-37","chapter":"18 Strings","heading":"18.9.0.1 Exercises","text":"Replace forward slashes string backslashes.Replace forward slashes string backslashes.Implement simple version str_to_lower() using str_replace_all().Implement simple version str_to_lower() using str_replace_all().Switch first last letters words.\nstrings still words?Switch first last letters words.\nstrings still words?","code":""},{"path":"strings.html","id":"extract-full-matches","chapter":"18 Strings","heading":"18.10 Extract full matches","text":"data tibble, ’s often easier use tidyr::extract().\nworks like str_match() requires name matches, placed new columns:","code":"\ntibble(sentence = sentences) %>% \n  tidyr::extract(\n    sentence, c(\"article\", \"noun\"), \"(a|the) ([^ ]+)\", \n    remove = FALSE\n  )\n#> <U+2029>[90m# A tibble: 720 x 3<U+2029>[39mNA#>   <U+2029>[1msentence<U+2029>[22m                                    <U+2029>[1marticle<U+2029>[22m <U+2029>[1mnoun<U+2029>[22m   NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                                       <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  NA#> <U+2029>[90m1<U+2029>[39m The birch canoe slid on the smooth planks.  the     smooth NA#> <U+2029>[90m2<U+2029>[39m Glue the sheet to the dark blue background. the     sheet  NA#> <U+2029>[90m3<U+2029>[39m It's easy to tell the depth of a well.      the     depth  NA#> <U+2029>[90m4<U+2029>[39m These days a chicken leg is a rare dish.    a       chickenNA#> <U+2029>[90m5<U+2029>[39m Rice is often served in round bowls.        <U+2029>[31mNA<U+2029>[39m      <U+2029>[31mNA<U+2029>[39m     NA#> <U+2029>[90m6<U+2029>[39m The juice of lemons makes fine punch.       <U+2029>[31mNA<U+2029>[39m      <U+2029>[31mNA<U+2029>[39m     NA#> <U+2029>[90m# ... with 714 more rows<U+2029>[39mNA"},{"path":"strings.html","id":"exercises-38","chapter":"18 Strings","heading":"18.10.1 Exercises","text":"previous example, might noticed regular expression matched “flickered”, colour. Modify regex fix problem.Find words come “number” like “one”, “two”, “three” etc. Pull number word.Find contractions. Separate pieces apostrophe.","code":""},{"path":"strings.html","id":"strings---columns","chapter":"18 Strings","heading":"18.11 Strings -> Columns","text":"","code":""},{"path":"strings.html","id":"separate","chapter":"18 Strings","heading":"18.12 Separate","text":"separate() pulls apart one column multiple columns, splitting wherever separator character appears.\nTake table3:rate column contains cases population variables, need split two variables.\nseparate() takes name column separate, names columns separate , shown Figure 18.1 code .\nFigure 18.1: Separating rate cases population make table3 tidy\ndefault, separate() split values wherever sees non-alphanumeric character (.e. character isn’t number letter).\nexample, code , separate() split values rate forward slash characters.\nwish use specific character separate column, can pass character sep argument separate().\nexample, rewrite code :separate_rows()","code":"\ntable3\n#> <U+2029>[90m# A tibble: 6 x 3<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m <U+2029>[1mrate<U+2029>[22m             NA#> <U+2029>[90m*<U+2029>[39m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m            NA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999 745/19987071     NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000 2666/20595360    NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999 37737/172006362  NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000 80488/174504898  NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 212258/1272915272NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 213766/1280428583NA\ntable3 %>%\n  separate(rate, into = c(\"cases\", \"population\"))\n#> <U+2029>[90m# A tibble: 6 x 4<U+2029>[39mNA#>   <U+2029>[1mcountry<U+2029>[22m      <U+2029>[1myear<U+2029>[22m <U+2029>[1mcases<U+2029>[22m  <U+2029>[1mpopulation<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m       <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     NA#> <U+2029>[90m1<U+2029>[39m Afghanistan  <U+2029>[4m1<U+2029>[24m999 745    19987071  NA#> <U+2029>[90m2<U+2029>[39m Afghanistan  <U+2029>[4m2<U+2029>[24m000 2666   20595360  NA#> <U+2029>[90m3<U+2029>[39m Brazil       <U+2029>[4m1<U+2029>[24m999 37737  172006362 NA#> <U+2029>[90m4<U+2029>[39m Brazil       <U+2029>[4m2<U+2029>[24m000 80488  174504898 NA#> <U+2029>[90m5<U+2029>[39m China        <U+2029>[4m1<U+2029>[24m999 212258 1272915272NA#> <U+2029>[90m6<U+2029>[39m China        <U+2029>[4m2<U+2029>[24m000 213766 1280428583NA\ntable3 %>%\n  separate(rate, into = c(\"cases\", \"population\"), sep = \"/\")"},{"path":"strings.html","id":"strings---rows","chapter":"18 Strings","heading":"18.13 Strings -> Rows","text":"","code":"\nstarwars %>% \n  select(name, eye_color) %>% \n  filter(str_detect(eye_color, \", \")) %>% \n  separate_rows(eye_color)\n#> <U+2029>[90m# A tibble: 4 x 2<U+2029>[39mNA#>   <U+2029>[1mname<U+2029>[22m     <U+2029>[1meye_color<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    NA#> <U+2029>[90m1<U+2029>[39m R4-P17   red      NA#> <U+2029>[90m2<U+2029>[39m R4-P17   blue     NA#> <U+2029>[90m3<U+2029>[39m Grievous green    NA#> <U+2029>[90m4<U+2029>[39m Grievous yellowNA"},{"path":"strings.html","id":"exercises-39","chapter":"18 Strings","heading":"18.13.1 Exercises","text":"Split string like \"apples, pears, bananas\" individual components.Split string like \"apples, pears, bananas\" individual components.better split boundary(\"word\") \" \"?better split boundary(\"word\") \" \"?splitting empty string (\"\") ?\nExperiment, read documentation.splitting empty string (\"\") ?\nExperiment, read documentation.","code":""},{"path":"strings.html","id":"other-languages","chapter":"18 Strings","heading":"18.14 Other writing systems","text":"Unicode system representing many writing systems used around world.\nFundamental unit code point.\nusually represents something like letter symbol, might also formatting like diacritic mark (e.g.) skin tone emoji.\nCharacter vs grapheme cluster.Include examples https://gankra.github.io/blah/text-hates-/.stringr functions default English locale.\nensures code works way every system, avoiding subtle bugs.Maybe things think true, aren’t list?","code":""},{"path":"strings.html","id":"encoding","chapter":"18 Strings","heading":"18.14.1 Encoding","text":"generally find base R Encoding() useful supports three different encodings (interpreting mean non-trivial) tells encoding R thinks , really .\ntypically problem declaring encoding wrong.tidyverse follows best practices6 using UTF-8 everywhere, string create tidyverse use UTF-8.\n’s still possible problems, ’ll typically arise data import.\n’ve diagnosed encoding problem, fix data import (.e. using encoding argument readr::locale()).","code":""},{"path":"strings.html","id":"length-and-subsetting-1","chapter":"18 Strings","heading":"18.14.2 Length and subsetting","text":"seems like straightforward computation ’re familiar English, things get complex quick working languages.Four common Latin, Chinese, Arabic, Devangari, represent three different systems writing systems:Latin uses alphabet, consonant vowel gets letter.Latin uses alphabet, consonant vowel gets letter.Chinese.\nLogograms.\nHalf width vs full width.\nEnglish letters roughly twice high wide.\nChinese characters roughly square.Chinese.\nLogograms.\nHalf width vs full width.\nEnglish letters roughly twice high wide.\nChinese characters roughly square.Arabic abjad, consonants written vowels optionally diacritics.\nAdditionally, ’s written right--left, first letter letter far right.Arabic abjad, consonants written vowels optionally diacritics.\nAdditionally, ’s written right--left, first letter letter far right.Devangari abugida symbol represents consonant-vowel pair, , vowel notation secondary.Devangari abugida symbol represents consonant-vowel pair, , vowel notation secondary.instance, ‘ch’ two letters English Latin, considered one letter Czech Slovak.\n— http://utf8everywhere.orgThis problem even Latin alphabets many languages use diacritics, glyphs added basic alphabet.\nproblem Unicode provides two ways representing characters accents: many common characters special codepoint, others can built individual components.","code":"\n# But\nstr_split(\"check\", boundary(\"character\", locale = \"cs_CZ\"))\n#> [[1]]\n#> [1] \"c\" \"h\" \"e\" \"c\" \"k\"\nx <- c(\"á\" \"\"x<U+0301>\"NA)NAstr_length(x)\n#> [1] 1 9\n# str_width(x)\nstr_sub(x, 1, 1)\n#> [1] \"á\" \"x\"\n# stri_width(c(\"全形\", \"ab\"))NA# 0, 1, or 2\n# but this assumes no font substitution\ncyrillic_a <- \"А\"latin_a <- \"A\"\ncyrillic_a == latin_a\n#> [1] FALSE\nstringi::stri_escape_unicode(cyrillic_a)\n#> [1] \"\\\\u0410\"\nstringi::stri_escape_unicode(latin_a)\n#> [1] \"A\""},{"path":"strings.html","id":"collation-rules","chapter":"18 Strings","heading":"18.14.3 Collation rules","text":"coll(): compare strings using standard collation rules.\nuseful case insensitive matching.\nNote coll() takes locale parameter controls rules used comparing characters.\nUnfortunately different parts world use different rules!B\noth fixed() regex() ignore_case arguments, allow pick locale: always use default locale.\ncan see following code; stringi later.downside coll() speed; rules recognising characters complicated, coll() relatively slow compared regex() fixed().","code":"\na1 <- \"\\u00e1\"\na2 <- \"a\\u0301\"\nc(a1, a2)\n#> [1] \"á\" \"a<U+0301>\"a1 == a2\n#> [1] FALSE\n\nstr_detect(a1, fixed(a2))\n#> [1] FALSE\nstr_detect(a1, coll(a2))\n#> [1] TRUE"},{"path":"strings.html","id":"upper-and-lower-case","chapter":"18 Strings","heading":"18.14.4 Upper and lower case","text":"Relatively writing systems upper lower case: Latin, Greek, Cyrillic, plus handful lessor known languages.used str_to_lower() change text lower case.\ncan also use str_to_upper() str_to_title().\nHowever, changing case complicated might first appear different languages different rules changing case.\ncan pick set rules use specifying locale:locale specified ISO 639 language code, two three letter abbreviation.\ndon’t already know code language, Wikipedia good list, can see supported stringi::stri_locale_list().\nleave locale blank, use English.locale also affects case-insensitive matching, coll(ignore_case =  TRUE) can control coll():can also case insensitive matching fixed(ignore_case = TRUE), uses simple approximation work cases.","code":"\n# Turkish has two i's: with and without a dot, and it\n# has a different rule for capitalising them:\nstr_to_upper(c(\"i\", \"<U+0131>\"NA)NA)NA#> [1] \"I\"        \"<U+0131>\"\nstr_to_upper(c(\"i\", \"<U+0131>\")e = \"tr\")=NA\"tr\"NA)NA#> [1] \"<U+0130>\" \"<U+0131>\"\ni <- c(\"I<U+0130>i<U+0131>\"NA)NAstr_view_all(i, coll(\"i\", ignore_case = TRUE))\n#> <U+2029>[36m<I><U+2029>[39m<U+0130><U+2029>[36m<i><U+2029>[39m<U+0131>NAstr_view_all(i, coll(\"i\", ignore_case = TRUE, locale = \"tr\"))\n#> I<U+0130><U+2029>[36m<i><U+2029>[39m<U+0131>NA"},{"path":"strings.html","id":"sorting","chapter":"18 Strings","heading":"18.14.5 Sorting","text":"Unicode collation algorithm: https://unicode.org/reports/tr10/Another important operation ’s affected locale sorting.\nbase R order() sort() functions sort strings using current locale.\nwant robust behaviour across different computers, may want use str_sort() str_order() take additional locale argument.Can also control “strength”, determines accents sorted.TODO: add connection arrange()","code":"\nstr_sort(c(\"a\", \"ch\", \"c\", \"h\"))\n#> [1] \"a\"  \"c\"  \"ch\" \"h\"\nstr_sort(c(\"a\", \"ch\", \"c\", \"h\"), locale = \"cs_CZ\")\n#> [1] \"a\"  \"c\"  \"h\"  \"ch\""},{"path":"regular-expressions.html","id":"regular-expressions","chapter":"19 Regular expressions","heading":"19 Regular expressions","text":"reading work--progress second edition R Data Science. chapter currently undergoing heavy restructuring may confusing incomplete. can find polished first edition https://r4ds..co.nz.","code":""},{"path":"regular-expressions.html","id":"introduction-12","chapter":"19 Regular expressions","heading":"19.1 Introduction","text":"focus chapter regular expressions, regexps short.\nRegular expressions useful strings usually contain unstructured semi-structured data, regexps concise language describing patterns strings.\nfirst look regexp, ’ll think cat walked across keyboard, understanding improves soon start make sense.","code":""},{"path":"regular-expressions.html","id":"matching-patterns-with-regular-expressions","chapter":"19 Regular expressions","heading":"19.2 Matching patterns with regular expressions","text":"Regexps terse language allow describe patterns strings.\ntake little get head around, understand , ’ll find extremely useful.learn regular expressions, ’ll use str_view() str_view_all().\nfunctions take character vector regular expression, show match.\n’ll start simple regular expressions gradually get complicated.\n’ve mastered pattern matching, ’ll learn apply ideas various stringr functions.","code":""},{"path":"regular-expressions.html","id":"prerequisites-9","chapter":"19 Regular expressions","heading":"19.2.1 Prerequisites","text":"chapter focus stringr package string manipulation, part core tidyverse.","code":"\nlibrary(tidyverse)"},{"path":"regular-expressions.html","id":"basic-matches","chapter":"19 Regular expressions","heading":"19.3 Basic matches","text":"simplest patterns match exact strings:next step complexity ., matches character (except newline):“.” matches character, match character “.”?\nneed use “escape” tell regular expression want match exactly, use special behaviour.\nLike strings, regexps use backslash, \\, escape special behaviour.\nmatch ., need regexp \\..\nUnfortunately creates problem.\nuse strings represent regular expressions, \\ also used escape symbol strings.\ncreate regular expression \\. need string \"\\\\.\".\\ used escape character regular expressions, match literal \\?\nWell need escape , creating regular expression \\\\.\ncreate regular expression, need use string, also needs escape \\.\nmeans match literal \\ need write \"\\\\\\\\\" — need four backslashes match one!book, ’ll write regular expression \\. strings represent regular expression \"\\\\.\".","code":"\nx <- c(\"apple\", \"banana\", \"pear\")\nstr_view(x, \"an\")\n#> apple\n#> b<U+2029>[36m<an><U+2029>[39manaNA#> pear\nstr_view(x, \".a.\")\n#> apple\n#> <U+2029>[36m<ban><U+2029>[39manaNA#> p<U+2029>[36m<ear><U+2029>[39mNA\n# To create the regular expression, we need \\\\\ndot <- \"\\\\.\"\n\n# But the expression itself only contains one:\nwriteLines(dot)\n#> \\.\n\n# And this tells R to look for an explicit .\nstr_view(c(\"abc\", \"a.c\", \"bef\"), \"a\\\\.c\")\n#> abc\n#> <U+2029>[36m<a.c><U+2029>[39mNA#> bef\nx <- \"a\\\\b\"\nwriteLines(x)\n#> a\\b\n\nstr_view(x, \"\\\\\\\\\")\n#> a<U+2029>[36m<\\><U+2029>[39mbNA"},{"path":"regular-expressions.html","id":"exercises-40","chapter":"19 Regular expressions","heading":"19.3.1 Exercises","text":"Explain strings don’t match \\: \"\\\", \"\\\\\", \"\\\\\\\".Explain strings don’t match \\: \"\\\", \"\\\\\", \"\\\\\\\".match sequence \"'\\?match sequence \"'\\?patterns regular expression \\..\\..\\.. match?\nrepresent string?patterns regular expression \\..\\..\\.. match?\nrepresent string?","code":""},{"path":"regular-expressions.html","id":"anchors","chapter":"19 Regular expressions","heading":"19.4 Anchors","text":"default, regular expressions match part string.\n’s often useful anchor regular expression matches start end string.\ncan use:^ match start string.$ match end string.remember , try mnemonic learned Evan Misshula: begin power (^), end money ($).force regular expression match complete string, anchor ^ $:can also match boundary words \\b.\ndon’t often use R, sometimes use ’m search RStudio want find name function ’s component functions.\nexample, ’ll search \\bsum\\b avoid matching summarise, summary, rowsum .","code":"\nx <- c(\"apple\", \"banana\", \"pear\")\nstr_view(x, \"^a\")\n#> <U+2029>[36m<a><U+2029>[39mppleNA#> banana\n#> pear\nstr_view(x, \"a$\")\n#> apple\n#> banan<U+2029>[36m<a><U+2029>[39mNA#> pear\nx <- c(\"apple pie\", \"apple\", \"apple cake\")\nstr_view(x, \"apple\")\n#> <U+2029>[36m<apple><U+2029>[39m pieNA#> <U+2029>[36m<apple><U+2029>[39mNA#> <U+2029>[36m<apple><U+2029>[39m cakeNAstr_view(x, \"^apple$\")\n#> apple pie\n#> <U+2029>[36m<apple><U+2029>[39mNA#> apple cake"},{"path":"regular-expressions.html","id":"exercises-41","chapter":"19 Regular expressions","heading":"19.4.1 Exercises","text":"match literal string \"$^$\"?match literal string \"$^$\"?Given corpus common words stringr::words, create regular expressions find words :\nStart “y”.\nEnd “x”\nexactly three letters long. (Don’t cheat using str_length()!)\nseven letters .\nSince list long, might want use match argument str_view() show matching non-matching words.Given corpus common words stringr::words, create regular expressions find words :Start “y”.End “x”exactly three letters long. (Don’t cheat using str_length()!)seven letters .Since list long, might want use match argument str_view() show matching non-matching words.","code":""},{"path":"regular-expressions.html","id":"overlapping-and-zero-width-patterns","chapter":"19 Regular expressions","heading":"19.5 Overlapping and zero-width patterns","text":"Note matches never overlap.\nexample, \"abababa\", many times pattern \"aba\" match?\nRegular expressions say two, three:","code":"\nstr_count(\"abababa\", \"aba\")\n#> [1] 2\nstr_view_all(\"abababa\", \"aba\")\n#> <U+2029>[36m<aba><U+2029>[39mb<U+2029>[36m<aba><U+2029>[39mNA"},{"path":"regular-expressions.html","id":"character-classes-and-alternatives","chapter":"19 Regular expressions","heading":"19.6 Character classes and alternatives","text":"number special patterns match one character.\n’ve already seen ., matches character apart newline.\nfour useful tools:\\d: matches digit.\\s: matches whitespace (e.g. space, tab, newline).[abc]: matches , b, c.[^abc]: matches anything except , b, c.Remember, create regular expression containing \\d \\s, ’ll need escape \\ string, ’ll type \"\\\\d\" \"\\\\s\".character class containing single character nice alternative backslash escapes want include single metacharacter regex.\nMany people find readable.works () regex metacharacters: $ . | ? * + ( ) [ {.\nUnfortunately, characters special meaning even inside character class must handled backslash escapes: ] \\ ^ -.can use alternation pick one alternative patterns.\nexample, abc|d..f match either ‘“abc”’, \"deaf\".\nNote precedence | low, abc|xyz matches abc xyz abcyz abxyz.\nLike mathematical expressions, precedence ever gets confusing, use parentheses make clear want:complex logical conditions (e.g. match b c unless d) ’s often easier combine multiple str_detect() calls logical operators, rather trying create single regular expression.\nexample, two ways find words don’t contain vowels:results identical, think first approach significantly easier understand.\nregular expression gets overly complicated, try breaking smaller pieces, giving piece name, combining pieces logical operations.","code":"\n# Look for a literal character that normally has special meaning in a regex\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[.]c\")\n#> abc\n#> <U+2029>[36m<a.c><U+2029>[39mNA#> a*c\n#> a c\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \".[*]c\")\n#> abc\n#> a.c\n#> <U+2029>[36m<a*c><U+2029>[39mNA#> a c\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[ ]\")\n#> abc\n#> a.c\n#> a*c\n#> <U+2029>[36m<a ><U+2029>[39mcNA\nstr_view(c(\"grey\", \"gray\"), \"gr(e|a)y\")\n#> <U+2029>[36m<grey><U+2029>[39mNA#> <U+2029>[36m<gray><U+2029>[39mNA\n# Find all words containing at least one vowel, and negate\nno_vowels_1 <- !str_detect(words, \"[aeiou]\")\n# Find all words consisting only of consonants (non-vowels)\nno_vowels_2 <- str_detect(words, \"^[^aeiou]+$\")\nidentical(no_vowels_1, no_vowels_2)\n#> [1] TRUE"},{"path":"regular-expressions.html","id":"exercises-42","chapter":"19 Regular expressions","heading":"19.6.1 Exercises","text":"Create regular expressions find words :\nStart vowel.\ncontain consonants. (Hint: thinking matching “”-vowels.)\nEnd ed, eed.\nEnd ing ise.\nCreate regular expressions find words :Start vowel.contain consonants. (Hint: thinking matching “”-vowels.)End ed, eed.End ing ise.Empirically verify rule “e except c”.Empirically verify rule “e except c”.“q” always followed “u”?“q” always followed “u”?Write regular expression matches word ’s probably written British English, American English.Write regular expression matches word ’s probably written British English, American English.Create regular expression match telephone numbers commonly written country.Create regular expression match telephone numbers commonly written country.","code":""},{"path":"regular-expressions.html","id":"repetition-quantifiers","chapter":"19 Regular expressions","heading":"19.7 Repetition / Quantifiers","text":"next step power involves controlling many times pattern matches:?: 0 1+: 1 *: 0 moreNote precedence operators high, can write: colou?r match either American British spellings.\nmeans uses need parentheses, like bana(na)+.can also specify number matches precisely:{n}: exactly n{n,}: n {1,m}: m{n,m}: n mBy default matches “greedy”: match longest string possible.\ncan make “lazy”, matching shortest string possible putting ? .\nadvanced feature regular expressions, ’s useful know exists:Collectively, operators called quantifiers quantify many times match can occur.","code":"\nx <- \"1888 is the longest year in Roman numerals: MDCCCLXXXVIII\"\nstr_view(x, \"CC?\")\n#> 1888 is the longest year in Roman numerals: MD<U+2029>[36m<CC><U+2029>[39mCLXXXVIIINAstr_view(x, \"CC+\")\n#> 1888 is the longest year in Roman numerals: MD<U+2029>[36m<CCC><U+2029>[39mLXXXVIIINAstr_view(x, 'C[LX]+')\n#> 1888 is the longest year in Roman numerals: MDCC<U+2029>[36m<CLXXX><U+2029>[39mVIIINA\nstr_view(x, \"C{2}\")\n#> 1888 is the longest year in Roman numerals: MD<U+2029>[36m<CC><U+2029>[39mCLXXXVIIINAstr_view(x, \"C{2,}\")\n#> 1888 is the longest year in Roman numerals: MD<U+2029>[36m<CCC><U+2029>[39mLXXXVIIINAstr_view(x, \"C{1,3}\")\n#> 1888 is the longest year in Roman numerals: MD<U+2029>[36m<CCC><U+2029>[39mLXXXVIIINAstr_view(x, \"C{2,3}\")\n#> 1888 is the longest year in Roman numerals: MD<U+2029>[36m<CCC><U+2029>[39mLXXXVIIINA\nstr_view(x, 'C{2,3}?')\n#> 1888 is the longest year in Roman numerals: MD<U+2029>[36m<CC><U+2029>[39mCLXXXVIIINAstr_view(x, 'C[LX]+?')\n#> 1888 is the longest year in Roman numerals: MDCC<U+2029>[36m<CL><U+2029>[39mXXXVIIINA"},{"path":"regular-expressions.html","id":"exercises-43","chapter":"19 Regular expressions","heading":"19.7.1 Exercises","text":"Describe equivalents ?, +, * {m,n} form.Describe equivalents ?, +, * {m,n} form.Describe words regular expressions match: (read carefully see ’m using regular expression string defines regular expression.)\n^.*$\n\"\\\\{.+\\\\}\"\n\\d{4}-\\d{2}-\\d{2}\n\"\\\\\\\\{4}\"\nDescribe words regular expressions match: (read carefully see ’m using regular expression string defines regular expression.)^.*$\"\\\\{.+\\\\}\"\\d{4}-\\d{2}-\\d{2}\"\\\\\\\\{4}\"Create regular expressions find words :\nStart three consonants.\nthree vowels row.\ntwo vowel-consonant pairs row.\nCreate regular expressions find words :Start three consonants.three vowels row.two vowel-consonant pairs row.Solve beginner regexp crosswords <https://regexcrossword.com/challenges/beginner>.Solve beginner regexp crosswords <https://regexcrossword.com/challenges/beginner>.","code":""},{"path":"regular-expressions.html","id":"grouping-and-backreferences","chapter":"19 Regular expressions","heading":"19.8 Grouping and backreferences","text":"Earlier, learned parentheses way disambiguate complex expressions.\nParentheses also create numbered capturing group (number 1, 2 etc.).\ncapturing group stores part string matched part regular expression inside parentheses.\ncan refer text previously matched capturing group backreferences, like \\1, \\2 etc.\nexample, following regular expression finds fruits repeated pair letters.(Shortly, ’ll also see ’re useful conjunction str_match().)Also use replacement:Names start end letter.\nImplement str_sub() instead.","code":"\nstr_view(fruit, \"(..)\\\\1\", match = TRUE)\n#> b<U+2029>[36m<anan><U+2029>[39maNA#> <U+2029>[36m<coco><U+2029>[39mnutNA#> <U+2029>[36m<cucu><U+2029>[39mmberNA#> <U+2029>[36m<juju><U+2029>[39mbeNA#> <U+2029>[36m<papa><U+2029>[39myaNA#> s<U+2029>[36m<alal><U+2029>[39m berryNA\nsentences %>% \n  str_replace(\"([^ ]+) ([^ ]+) ([^ ]+)\", \"\\\\1 \\\\3 \\\\2\") %>% \n  head(5)\n#> [1] \"The canoe birch slid on the smooth planks.\" \n#> [2] \"Glue sheet the to the dark blue background.\"\n#> [3] \"It's to easy tell the depth of a well.\"     \n#> [4] \"These a days chicken leg is a rare dish.\"   \n#> [5] \"Rice often is served in round bowls.\""},{"path":"regular-expressions.html","id":"exercises-44","chapter":"19 Regular expressions","heading":"19.8.1 Exercises","text":"Describe, words, expressions match:\n(.)\\1\\1\n\"(.)(.)\\\\2\\\\1\"\n(..)\\1\n\"(.).\\\\1.\\\\1\"\n\"(.)(.)(.).*\\\\3\\\\2\\\\1\"\nDescribe, words, expressions match:(.)\\1\\1\"(.)(.)\\\\2\\\\1\"(..)\\1\"(.).\\\\1.\\\\1\"\"(.)(.)(.).*\\\\3\\\\2\\\\1\"Construct regular expressions match words :\nStart end character.\nContain repeated pair letters (e.g. “church” contains “ch” repeated twice.)\nContain one letter repeated least three places (e.g. “eleven” contains three “e”s.)\nConstruct regular expressions match words :Start end character.Contain repeated pair letters (e.g. “church” contains “ch” repeated twice.)Contain one letter repeated least three places (e.g. “eleven” contains three “e”s.)","code":""},{"path":"regular-expressions.html","id":"other-uses-of-regular-expressions","chapter":"19 Regular expressions","heading":"19.9 Other uses of regular expressions","text":"two useful function base R also use regular expressions:apropos() searches objects available global environment.\nuseful can’t quite remember name function.\n\napropos(\"replace\")\n#> [1] \"%+replace%\"       \"replace\"          \"replace_na\"       \"setReplaceMethod\"\n#> [5] \"str_replace\"      \"str_replace_all\"  \"str_replace_na\"   \"theme_replace\"apropos() searches objects available global environment.\nuseful can’t quite remember name function.dir() lists files directory.\npattern argument takes regular expression returns file names match pattern.\nexample, can find R Markdown files current directory :\n\nhead(dir(pattern = \"\\\\.Rmd$\"))\n#> [1] \"column-wise.Rmd\"       \"communicate-plots.Rmd\" \"communicate.Rmd\"      \n#> [4] \"contribute.Rmd\"        \"data-import.Rmd\"       \"data-tidy.Rmd\"\n(’re comfortable “globs” like *.Rmd, can convert regular expressions glob2rx()):dir() lists files directory.\npattern argument takes regular expression returns file names match pattern.\nexample, can find R Markdown files current directory :(’re comfortable “globs” like *.Rmd, can convert regular expressions glob2rx()):","code":"\napropos(\"replace\")\n#> [1] \"%+replace%\"       \"replace\"          \"replace_na\"       \"setReplaceMethod\"\n#> [5] \"str_replace\"      \"str_replace_all\"  \"str_replace_na\"   \"theme_replace\"\nhead(dir(pattern = \"\\\\.Rmd$\"))\n#> [1] \"column-wise.Rmd\"       \"communicate-plots.Rmd\" \"communicate.Rmd\"      \n#> [4] \"contribute.Rmd\"        \"data-import.Rmd\"       \"data-tidy.Rmd\""},{"path":"regular-expressions.html","id":"options","chapter":"19 Regular expressions","heading":"19.10 Options","text":"use pattern ’s string, ’s automatically wrapped call regex():can use arguments regex() control details match:ignore_case = TRUE allows characters match either uppercase lowercase forms.\nalways uses current locale.\n\nbananas <- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n#> <U+2029>[36m<banana><U+2029>[39mNA#> Banana\n#> BANANA\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n#> <U+2029>[36m<banana><U+2029>[39mNA#> <U+2029>[36m<Banana><U+2029>[39mNA#> <U+2029>[36m<BANANA><U+2029>[39mNAignore_case = TRUE allows characters match either uppercase lowercase forms.\nalways uses current locale.multiline = TRUE allows ^ $ match start end line rather start end complete string.\n\nx <- \"Line 1\\nLine 2\\nLine 3\"\nstr_extract_all(x, \"^Line\")[[1]]\n#> [1] \"Line\"\nstr_extract_all(x, regex(\"^Line\", multiline = TRUE))[[1]]\n#> [1] \"Line\" \"Line\" \"Line\"multiline = TRUE allows ^ $ match start end line rather start end complete string.comments = TRUE allows use comments white space make complex regular expressions understandable.\nSpaces ignored, everything #.\nmatch literal space, ’ll need escape : \"\\\\ \".\n\nphone <- regex(\"\n  \\\\(?     # optional opening parens\n  (\\\\d{3}) # area code\n  [) -]?   # optional closing parens, space, dash\n  (\\\\d{3}) # another three numbers\n  [ -]?    # optional space dash\n  (\\\\d{3}) # three numbers\n  \", comments = TRUE)\n\nstr_match(\"514-791-8141\", phone)\n#>      [,1]          [,2]  [,3]  [,4] \n#> [1,] \"514-791-814\" \"514\" \"791\" \"814\"comments = TRUE allows use comments white space make complex regular expressions understandable.\nSpaces ignored, everything #.\nmatch literal space, ’ll need escape : \"\\\\ \".dotall = TRUE allows . match everything, including \\n.dotall = TRUE allows . match everything, including \\n.","code":"\n# The regular call:\nstr_view(fruit, \"nana\")\n# Is shorthand for\nstr_view(fruit, regex(\"nana\"))\nbananas <- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n#> <U+2029>[36m<banana><U+2029>[39mNA#> Banana\n#> BANANA\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n#> <U+2029>[36m<banana><U+2029>[39mNA#> <U+2029>[36m<Banana><U+2029>[39mNA#> <U+2029>[36m<BANANA><U+2029>[39mNA\nx <- \"Line 1\\nLine 2\\nLine 3\"\nstr_extract_all(x, \"^Line\")[[1]]\n#> [1] \"Line\"\nstr_extract_all(x, regex(\"^Line\", multiline = TRUE))[[1]]\n#> [1] \"Line\" \"Line\" \"Line\"\nphone <- regex(\"\n  \\\\(?     # optional opening parens\n  (\\\\d{3}) # area code\n  [) -]?   # optional closing parens, space, or dash\n  (\\\\d{3}) # another three numbers\n  [ -]?    # optional space or dash\n  (\\\\d{3}) # three more numbers\n  \", comments = TRUE)\n\nstr_match(\"514-791-8141\", phone)\n#>      [,1]          [,2]  [,3]  [,4] \n#> [1,] \"514-791-814\" \"514\" \"791\" \"814\""},{"path":"regular-expressions.html","id":"a-caution","chapter":"19 Regular expressions","heading":"19.11 A caution","text":"word caution continue: regular expressions powerful, ’s easy try solve every problem single regular expression.\nwords Jamie Zawinski:people, confronted problem, think “know, ’ll use regular expressions.” Now two problems.cautionary tale, check regular expression checks email address valid:somewhat pathological example (email addresses actually surprisingly complex), used real code.\nSee Stack Overflow discussion http://stackoverflow.com//201378 details.Don’t forget ’re programming language tools disposal.\nInstead creating one complex regular expression, ’s often easier write series simpler regexps.\nget stuck trying create single regexp solves problem, take step back think break problem smaller pieces, solving challenge moving onto next one.","code":"(?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t]\n)+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\n\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(\n?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \n\\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\0\n31]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\\n](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+\n(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:\n(?:\\r\\n)?[ \\t])*))*|(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z\n|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)\n?[ \\t])*)*\\<(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\\nr\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[\n \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)\n?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t]\n)*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[\n \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*\n)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t]\n)+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)\n*:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+\n|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\n\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\n\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t\n]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031\n]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](\n?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?\n:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?\n:\\r\\n)?[ \\t])*))*\\>(?:(?:\\r\\n)?[ \\t])*)|(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?\n:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?\n[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*:(?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^()<>@,;:\\\\\".\\[\\] \n\\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\n\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>\n@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"\n(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t]\n)*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\n\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?\n:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\n\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?:[^()<>@,;:\\\\\".\\[\\] \\000-\n\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(\n?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*\\<(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()<>@,;\n:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([\n^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\"\n.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\\n]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\\n[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\\nr\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \n\\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]\n|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()<>@,;:\\\\\".\\[\\] \\0\n00-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\\n.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,\n;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?\n:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*\n(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\n\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[\n^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]\n]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\>(?:(?:\\r\\n)?[ \\t])*)(?:,\\s*(\n?:(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\n\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(\n?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\n\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t\n])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t\n])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?\n:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\n\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?:\n[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\\n]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*\\<(?:(?:\\r\\n)\n?[ \\t])*(?:@(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"\n()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)\n?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>\n@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[\n \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,\n;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t]\n)*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\n\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)?\n(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\n\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\n\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\n\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])\n*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])\n+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\\n.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z\n|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\>(?:(\n?:\\r\\n)?[ \\t])*))*)?;\\s*)"},{"path":"factors.html","id":"factors","chapter":"20 Factors","heading":"20 Factors","text":"","code":""},{"path":"factors.html","id":"introduction-13","chapter":"20 Factors","heading":"20.1 Introduction","text":"R, factors used work categorical variables, variables fixed known set possible values.\nalso useful want display character vectors non-alphabetical order.Historically, factors much easier work characters.\nresult, many functions base R automatically convert characters factors.\nmeans factors often crop places ’re actually helpful.\nFortunately, don’t need worry tidyverse, can focus situations factors genuinely useful.","code":""},{"path":"factors.html","id":"prerequisites-10","chapter":"20 Factors","heading":"20.1.1 Prerequisites","text":"work factors, ’ll use forcats package, part core tidyverse.\nprovides tools dealing categorical variables (’s anagram factors!) using wide range helpers working factors.","code":"\nlibrary(tidyverse)"},{"path":"factors.html","id":"learning-more-1","chapter":"20 Factors","heading":"20.1.2 Learning more","text":"want learn factors, recommend reading Amelia McNamara Nicholas Horton’s paper, Wrangling categorical data R.\npaper lays history discussed stringsAsFactors: unauthorized biography stringsAsFactors = <sigh>, compares tidy approaches categorical data outlined book base R methods.\nearly version paper helped motivate scope forcats package; thanks Amelia & Nick!","code":""},{"path":"factors.html","id":"creating-factors","chapter":"20 Factors","heading":"20.2 Creating factors","text":"Imagine variable records month:Using string record variable two problems:twelve possible months, ’s nothing saving typos:\n\nx2 <- c(\"Dec\", \"Apr\", \"Jam\", \"Mar\")twelve possible months, ’s nothing saving typos:doesn’t sort useful way:\n\nsort(x1)\n#> [1] \"Apr\" \"Dec\" \"Jan\" \"Mar\"doesn’t sort useful way:can fix problems factor.\ncreate factor must start creating list valid levels:Now can create factor:values set silently converted NA:want warning, can use readr::parse_factor():omit levels, ’ll taken data alphabetical order:Sometimes ’d prefer order levels match order first appearance data.\ncan creating factor setting levels unique(x), fact, fct_inorder():ever need access set valid levels directly, can levels():","code":"\nx1 <- c(\"Dec\", \"Apr\", \"Jan\", \"Mar\")\nx2 <- c(\"Dec\", \"Apr\", \"Jam\", \"Mar\")\nsort(x1)\n#> [1] \"Apr\" \"Dec\" \"Jan\" \"Mar\"\nmonth_levels <- c(\n  \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n  \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n)\ny1 <- factor(x1, levels = month_levels)\ny1\n#> [1] Dec Apr Jan Mar\n#> Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\nsort(y1)\n#> [1] Jan Mar Apr Dec\n#> Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\ny2 <- factor(x2, levels = month_levels)\ny2\n#> [1] Dec  Apr  <NA> Mar \n#> Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\ny2 <- parse_factor(x2, levels = month_levels)\n#> Warning: 1 parsing failure.\n#> row col           expected actual\n#>   3  -- value in level set    Jam\nfactor(x1)\n#> [1] Dec Apr Jan Mar\n#> Levels: Apr Dec Jan Mar\nf1 <- factor(x1, levels = unique(x1))\nf1\n#> [1] Dec Apr Jan Mar\n#> Levels: Dec Apr Jan Mar\n\nf2 <- x1 %>% factor() %>% fct_inorder()\nf2\n#> [1] Dec Apr Jan Mar\n#> Levels: Dec Apr Jan Mar\nlevels(f2)\n#> [1] \"Dec\" \"Apr\" \"Jan\" \"Mar\""},{"path":"factors.html","id":"general-social-survey","chapter":"20 Factors","heading":"20.3 General Social Survey","text":"rest chapter, ’re going focus forcats::gss_cat.\n’s sample data General Social Survey, long-running US survey conducted independent research organization NORC University Chicago.\nsurvey thousands questions, gss_cat ’ve selected handful illustrate common challenges ’ll encounter working factors.(Remember, since dataset provided package, can get information variables ?gss_cat.)factors stored tibble, can’t see levels easily.\nOne way see count():bar chart:default, ggplot2 drop levels don’t values.\ncan force display :levels represent valid values simply occur dataset.\ndplyr::count() set .drop option FALSE, show .working factors, two common operations changing order levels, changing values levels.\noperations described sections .","code":"\ngss_cat\n#> <U+2029>[90m# A tibble: 21,483 x 9<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmarital<U+2029>[22m         <U+2029>[1mage<U+2029>[22m <U+2029>[1mrace<U+2029>[22m  <U+2029>[1mrincome<U+2029>[22m        <U+2029>[1mpartyid<U+2029>[22m   <U+2029>[1mrelig<U+2029>[22m  <U+2029>[1mdenom<U+2029>[22m  <U+2029>[1mtvhours<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m         <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m    <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m000 Never married    26 White $8000 to 9999  Ind,near~ Prote~ South~      12NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m000 Divorced         48 White $8000 to 9999  Not str ~ Prote~ Bapti~      <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m000 Widowed          67 White Not applicable Independ~ Prote~ No de~       2NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m000 Never married    39 White Not applicable Ind,near~ Ortho~ Not a~       4NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m000 Divorced         25 White Not applicable Not str ~ None   Not a~       1NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m000 Married          25 White $20000 - 24999 Strong d~ Prote~ South~      <U+2029>[31mNA<U+2029>[39mNA#> <U+2029>[90m# ... with 21,477 more rows<U+2029>[39mNA\ngss_cat %>%\n  count(race)\n#> <U+2029>[90m# A tibble: 3 x 2<U+2029>[39mNA#>   <U+2029>[1mrace<U+2029>[22m      <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Other  <U+2029>[4m1<U+2029>[24m959NA#> <U+2029>[90m2<U+2029>[39m Black  <U+2029>[4m3<U+2029>[24m129NA#> <U+2029>[90m3<U+2029>[39m White <U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m395NA\nggplot(gss_cat, aes(race)) +\n  geom_bar()\nggplot(gss_cat, aes(race)) +\n  geom_bar() +\n  scale_x_discrete(drop = FALSE)\ngss_cat %>% \n  count(race, \n        .drop = FALSE)\n#> <U+2029>[90m# A tibble: 4 x 2<U+2029>[39mNA#>   <U+2029>[1mrace<U+2029>[22m               <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m          <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Other           <U+2029>[4m1<U+2029>[24m959NA#> <U+2029>[90m2<U+2029>[39m Black           <U+2029>[4m3<U+2029>[24m129NA#> <U+2029>[90m3<U+2029>[39m White          <U+2029>[4m1<U+2029>[24m<U+2029>[4m6<U+2029>[24m395NA#> <U+2029>[90m4<U+2029>[39m Not applicable     0NA"},{"path":"factors.html","id":"exercise","chapter":"20 Factors","heading":"20.3.1 Exercise","text":"Explore distribution rincome (reported income).\nmakes default bar chart hard understand?\nimprove plot?Explore distribution rincome (reported income).\nmakes default bar chart hard understand?\nimprove plot?common relig survey?\n’s common partyid?common relig survey?\n’s common partyid?relig denom (denomination) apply ?\ncan find table?\ncan find visualisation?relig denom (denomination) apply ?\ncan find table?\ncan find visualisation?","code":""},{"path":"factors.html","id":"modifying-factor-order","chapter":"20 Factors","heading":"20.4 Modifying factor order","text":"’s often useful change order factor levels visualisation.\nexample, imagine want explore average number hours spent watching TV per day across religions:difficult interpret plot ’s overall pattern.\ncan improve reordering levels relig using fct_reorder().\nfct_reorder() takes three arguments:f, factor whose levels want modify.x, numeric vector want use reorder levels.Optionally, fun, function ’s used multiple values x value f. default value median.Reordering religion makes much easier see people “Don’t know” category watch much TV, Hinduism & Eastern religions watch much less.start making complicated transformations, ’d recommend moving aes() separate mutate() step.\nexample, rewrite plot :create similar plot looking average age varies across reported income level?, arbitrarily reordering levels isn’t good idea!\n’s rincome already principled order shouldn’t mess .\nReserve fct_reorder() factors whose levels arbitrarily ordered.However, make sense pull “applicable” front special levels.\ncan use fct_relevel().\ntakes factor, f, number levels want move front line.think average age “applicable” high?Another type reordering useful colouring lines plot.\nfct_reorder2() reorders factor y values associated largest x values.\nmakes plot easier read line colours line legend.Finally, bar plots, can use fct_infreq() order levels increasing frequency: simplest type reordering doesn’t need extra variables.\nmay want combine fct_rev().","code":"\nrelig_summary <- gss_cat %>%\n  group_by(relig) %>%\n  summarise(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(relig_summary, aes(tvhours, relig)) + geom_point()\nggplot(relig_summary, aes(tvhours, fct_reorder(relig, tvhours))) +\n  geom_point()\nrelig_summary %>%\n  mutate(relig = fct_reorder(relig, tvhours)) %>%\n  ggplot(aes(tvhours, relig)) +\n    geom_point()\nrincome_summary <- gss_cat %>%\n  group_by(rincome) %>%\n  summarise(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(rincome_summary, aes(age, fct_reorder(rincome, age))) + geom_point()\nggplot(rincome_summary, aes(age, fct_relevel(rincome, \"Not applicable\"))) +\n  geom_point()\nby_age <- gss_cat %>%\n  filter(!is.na(age)) %>%\n  count(age, marital) %>%\n  group_by(age) %>%\n  mutate(prop = n / sum(n))\n\nggplot(by_age, aes(age, prop, colour = marital)) +\n  geom_line(na.rm = TRUE)\n\nggplot(by_age, aes(age, prop, colour = fct_reorder2(marital, age, prop))) +\n  geom_line() +\n  labs(colour = \"marital\")\ngss_cat %>%\n  mutate(marital = marital %>% fct_infreq() %>% fct_rev()) %>%\n  ggplot(aes(marital)) +\n    geom_bar()"},{"path":"factors.html","id":"exercises-45","chapter":"20 Factors","heading":"20.4.1 Exercises","text":"suspiciously high numbers tvhours.\nmean good summary?suspiciously high numbers tvhours.\nmean good summary?factor gss_cat identify whether order levels arbitrary principled.factor gss_cat identify whether order levels arbitrary principled.moving “applicable” front levels move bottom plot?moving “applicable” front levels move bottom plot?","code":""},{"path":"factors.html","id":"modifying-factor-levels","chapter":"20 Factors","heading":"20.5 Modifying factor levels","text":"powerful changing orders levels changing values.\nallows clarify labels publication, collapse levels high-level displays.\ngeneral powerful tool fct_recode().\nallows recode, change, value level.\nexample, take gss_cat$partyid:levels terse inconsistent.\nLet’s tweak longer use parallel construction.fct_recode() leave levels aren’t explicitly mentioned , warn accidentally refer level doesn’t exist.combine groups, can assign multiple old levels new level:must use technique care: group together categories truly different end misleading results.want collapse lot levels, fct_collapse() useful variant fct_recode().\nnew variable, can provide vector old levels:Sometimes just want lump together small groups make plot table simpler.\n’s job fct_lump_*() family functions.\nfct_lump_lowfreq() simple starting point progressively lumps smallest groups categories “”, always keeping “” smallest category.case ’s helpful: true majority Americans survey Protestant, ’d probably like see details!\nInstead, can use fct_lump_n() specify want exactly 10 groups:","code":"\ngss_cat %>% count(partyid)\n#> <U+2029>[90m# A tibble: 10 x 2<U+2029>[39mNA#>   <U+2029>[1mpartyid<U+2029>[22m                <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m              <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m No answer            154NA#> <U+2029>[90m2<U+2029>[39m Don't know             1NA#> <U+2029>[90m3<U+2029>[39m Other party          393NA#> <U+2029>[90m4<U+2029>[39m Strong republican   <U+2029>[4m2<U+2029>[24m314NA#> <U+2029>[90m5<U+2029>[39m Not str republican  <U+2029>[4m3<U+2029>[24m032NA#> <U+2029>[90m6<U+2029>[39m Ind,near rep        <U+2029>[4m1<U+2029>[24m791NA#> <U+2029>[90m# ... with 4 more rows<U+2029>[39mNA\ngss_cat %>%\n  mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\"\n  )) %>%\n  count(partyid)\n#> <U+2029>[90m# A tibble: 10 x 2<U+2029>[39mNA#>   <U+2029>[1mpartyid<U+2029>[22m                   <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m                 <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m No answer               154NA#> <U+2029>[90m2<U+2029>[39m Don't know                1NA#> <U+2029>[90m3<U+2029>[39m Other party             393NA#> <U+2029>[90m4<U+2029>[39m Republican, strong     <U+2029>[4m2<U+2029>[24m314NA#> <U+2029>[90m5<U+2029>[39m Republican, weak       <U+2029>[4m3<U+2029>[24m032NA#> <U+2029>[90m6<U+2029>[39m Independent, near rep  <U+2029>[4m1<U+2029>[24m791NA#> <U+2029>[90m# ... with 4 more rows<U+2029>[39mNA\ngss_cat %>%\n  mutate(partyid = fct_recode(partyid,\n    \"Republican, strong\"    = \"Strong republican\",\n    \"Republican, weak\"      = \"Not str republican\",\n    \"Independent, near rep\" = \"Ind,near rep\",\n    \"Independent, near dem\" = \"Ind,near dem\",\n    \"Democrat, weak\"        = \"Not str democrat\",\n    \"Democrat, strong\"      = \"Strong democrat\",\n    \"Other\"                 = \"No answer\",\n    \"Other\"                 = \"Don't know\",\n    \"Other\"                 = \"Other party\"\n  )) %>%\n  count(partyid)\n#> <U+2029>[90m# A tibble: 8 x 2<U+2029>[39mNA#>   <U+2029>[1mpartyid<U+2029>[22m                   <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m                 <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Other                   548NA#> <U+2029>[90m2<U+2029>[39m Republican, strong     <U+2029>[4m2<U+2029>[24m314NA#> <U+2029>[90m3<U+2029>[39m Republican, weak       <U+2029>[4m3<U+2029>[24m032NA#> <U+2029>[90m4<U+2029>[39m Independent, near rep  <U+2029>[4m1<U+2029>[24m791NA#> <U+2029>[90m5<U+2029>[39m Independent            <U+2029>[4m4<U+2029>[24m119NA#> <U+2029>[90m6<U+2029>[39m Independent, near dem  <U+2029>[4m2<U+2029>[24m499NA#> <U+2029>[90m# ... with 2 more rows<U+2029>[39mNA\ngss_cat %>%\n  mutate(partyid = fct_collapse(partyid,\n    other = c(\"No answer\", \"Don't know\", \"Other party\"),\n    rep = c(\"Strong republican\", \"Not str republican\"),\n    ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n    dem = c(\"Not str democrat\", \"Strong democrat\")\n  )) %>%\n  count(partyid)\n#> <U+2029>[90m# A tibble: 4 x 2<U+2029>[39mNA#>   <U+2029>[1mpartyid<U+2029>[22m     <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m other     548NA#> <U+2029>[90m2<U+2029>[39m rep      <U+2029>[4m5<U+2029>[24m346NA#> <U+2029>[90m3<U+2029>[39m ind      <U+2029>[4m8<U+2029>[24m409NA#> <U+2029>[90m4<U+2029>[39m dem      <U+2029>[4m7<U+2029>[24m180NA\ngss_cat %>%\n  mutate(relig = fct_lump_lowfreq(relig)) %>%\n  count(relig)\n#> <U+2029>[90m# A tibble: 2 x 2<U+2029>[39mNA#>   <U+2029>[1mrelig<U+2029>[22m          <U+2029>[1mn<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m      <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m Protestant <U+2029>[4m1<U+2029>[24m<U+2029>[4m0<U+2029>[24m846NA#> <U+2029>[90m2<U+2029>[39m Other      <U+2029>[4m1<U+2029>[24m<U+2029>[4m0<U+2029>[24m637NA\ngss_cat %>%\n  mutate(relig = fct_lump_n(relig, n = 10)) %>%\n  count(relig, sort = TRUE) %>%\n  print(n = Inf)\n#> <U+2029>[90m# A tibble: 10 x 2<U+2029>[39mNA#>    <U+2029>[1mrelig<U+2029>[22m                       <U+2029>[1mn<U+2029>[22mNA#>    <U+2029>[3m<U+2029>[90m<fct><U+2029>[39m<U+2029>[23m                   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m 1<U+2029>[39m Protestant              <U+2029>[4m1<U+2029>[24m<U+2029>[4m0<U+2029>[24m846NA#> <U+2029>[90m 2<U+2029>[39m Catholic                 <U+2029>[4m5<U+2029>[24m124NA#> <U+2029>[90m 3<U+2029>[39m None                     <U+2029>[4m3<U+2029>[24m523NA#> <U+2029>[90m 4<U+2029>[39m Christian                 689NA#> <U+2029>[90m 5<U+2029>[39m Other                     458NA#> <U+2029>[90m 6<U+2029>[39m Jewish                    388NA#> <U+2029>[90m 7<U+2029>[39m Buddhism                  147NA#> <U+2029>[90m 8<U+2029>[39m Inter-nondenominational   109NA#> <U+2029>[90m 9<U+2029>[39m Moslem/islam              104NA#> <U+2029>[90m10<U+2029>[39m Orthodox-christian         95NA"},{"path":"factors.html","id":"exercises-46","chapter":"20 Factors","heading":"20.5.1 Exercises","text":"proportions people identifying Democrat, Republican, Independent changed time?proportions people identifying Democrat, Republican, Independent changed time?collapse rincome small set categories?collapse rincome small set categories?Notice 9 groups (excluding ) fct_lump example .\n10?\n(Hint: type ?fct_lump, find default argument other_level “”.)Notice 9 groups (excluding ) fct_lump example .\n10?\n(Hint: type ?fct_lump, find default argument other_level “”.)","code":""},{"path":"dates-and-times.html","id":"dates-and-times","chapter":"21 Dates and times","heading":"21 Dates and times","text":"","code":""},{"path":"dates-and-times.html","id":"introduction-14","chapter":"21 Dates and times","heading":"21.1 Introduction","text":"chapter show work dates times R.\nfirst glance, dates times seem simple.\nuse time regular life, don’t seem cause much confusion.\nHowever, learn dates times, complicated seem get.\nwarm , try three seemingly simple questions:every year 365 days?every day 24 hours?every minute 60 seconds?’m sure know every year 365 days, know full rule determining year leap year?\n(three parts.) might remembered many parts world use daylight savings time (DST), days 23 hours, others 25.\nmight known minutes 61 seconds every now leap seconds added Earth’s rotation gradually slowing .Dates times hard reconcile two physical phenomena (rotation Earth orbit around sun) whole raft geopolitical phenomena including months, time zones, DST.\nchapter won’t teach every last detail dates times, give solid grounding practical skills help common data analysis challenges.","code":""},{"path":"dates-and-times.html","id":"prerequisites-11","chapter":"21 Dates and times","heading":"21.1.1 Prerequisites","text":"chapter focus lubridate package, makes easier work dates times R.\nlubridate part core tidyverse need ’re working dates/times.\nalso need nycflights13 practice data.","code":"\nlibrary(tidyverse)\n\nlibrary(lubridate)\nlibrary(nycflights13)"},{"path":"dates-and-times.html","id":"creating-datetimes","chapter":"21 Dates and times","heading":"21.2 Creating date/times","text":"three types date/time data refer instant time:date.\nTibbles print <date>.date.\nTibbles print <date>.time within day.\nTibbles print <time>.time within day.\nTibbles print <time>.date-time date plus time: uniquely identifies instant time (typically nearest second).\nTibbles print <dttm>.\nElsewhere R called POSIXct, don’t think ’s useful name.date-time date plus time: uniquely identifies instant time (typically nearest second).\nTibbles print <dttm>.\nElsewhere R called POSIXct, don’t think ’s useful name.chapter going focus dates date-times R doesn’t native class storing times.\nneed one, can use hms package.always use simplest possible data type works needs.\nmeans can use date instead date-time, .\nDate-times substantially complicated need handle time zones, ’ll come back end chapter.get current date date-time can use today() now():Otherwise, three ways ’re likely create date/time:string.individual date-time components.existing date/time object.work follows.","code":"\ntoday()\n#> [1] \"2021-09-03\"\nnow()\n#> [1] \"2021-09-03 02:36:49 CST\""},{"path":"dates-and-times.html","id":"from-strings","chapter":"21 Dates and times","heading":"21.2.1 From strings","text":"Date/time data often comes strings.\n’ve seen one approach parsing strings date-times date-times.\nAnother approach use helpers provided lubridate.\nautomatically work format specify order component.\nuse , identify order year, month, day appear dates, arrange “y”, “m”, “d” order.\ngives name lubridate function parse date.\nexample:functions also take unquoted numbers.\nconcise way create single date/time object, might need filtering date/time data.\nymd() short unambiguous:ymd() friends create dates.\ncreate date-time, add underscore one “h”, “m”, “s” name parsing function:can also force creation date-time date supplying timezone:","code":"\nymd(\"2017-01-31\")\n#> [1] \"2017-01-31\"\nmdy(\"January 31st, 2017\")\n#> [1] \"2017-01-31\"\ndmy(\"31-Jan-2017\")\n#> [1] \"2017-01-31\"\nymd(20170131)\n#> [1] \"2017-01-31\"\nymd_hms(\"2017-01-31 20:11:59\")\n#> [1] \"2017-01-31 20:11:59 UTC\"\nmdy_hm(\"01/31/2017 08:01\")\n#> [1] \"2017-01-31 08:01:00 UTC\"\nymd(20170131, tz = \"UTC\")\n#> [1] \"2017-01-31 UTC\""},{"path":"dates-and-times.html","id":"from-individual-components","chapter":"21 Dates and times","heading":"21.2.2 From individual components","text":"Instead single string, sometimes ’ll individual components date-time spread across multiple columns.\nflights data:create date/time sort input, use make_date() dates, make_datetime() date-times:Let’s thing four time columns flights.\ntimes represented slightly odd format, use modulus arithmetic pull hour minute components.\n’ve created date-time variables, focus variables ’ll explore rest chapter.data, can visualise distribution departure times across year:within single day:Note use date-times numeric context (like histogram), 1 means 1 second, binwidth 86400 means one day.\ndates, 1 means 1 day.","code":"\nflights %>% \n  select(year, month, day, hour, minute)\n#> <U+2029>[90m# A tibble: 336,776 x 5<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1mminute<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     15NA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     29NA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     40NA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     45NA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6      0NA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     58NA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA\nflights %>% \n  select(year, month, day, hour, minute) %>% \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n#> <U+2029>[90m# A tibble: 336,776 x 6<U+2029>[39mNA#>    <U+2029>[1myear<U+2029>[22m <U+2029>[1mmonth<U+2029>[22m   <U+2029>[1mday<U+2029>[22m  <U+2029>[1mhour<U+2029>[22m <U+2029>[1mminute<U+2029>[22m <U+2029>[1mdeparture<U+2029>[22m          NA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m             NA#> <U+2029>[90m1<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     15 2013-01-01 <U+2029>[90m05:15:00<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     29 2013-01-01 <U+2029>[90m05:29:00<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     40 2013-01-01 <U+2029>[90m05:40:00<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     45 2013-01-01 <U+2029>[90m05:45:00<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     6      0 2013-01-01 <U+2029>[90m06:00:00<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m  <U+2029>[4m2<U+2029>[24m013     1     1     5     58 2013-01-01 <U+2029>[90m05:58:00<U+2029>[39mNA#> <U+2029>[90m# ... with 336,770 more rows<U+2029>[39mNA\nmake_datetime_100 <- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\nflights_dt <- flights %>% \n  filter(!is.na(dep_time), !is.na(arr_time)) %>% \n  mutate(\n    dep_time = make_datetime_100(year, month, day, dep_time),\n    arr_time = make_datetime_100(year, month, day, arr_time),\n    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)\n  ) %>% \n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\nflights_dt\n#> <U+2029>[90m# A tibble: 328,063 x 9<U+2029>[39mNA#>   <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m            <U+2029>[1msched_dep_time<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m              <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m             NA#> <U+2029>[90m1<U+2029>[39m EWR    IAH           2        11 2013-01-01 <U+2029>[90m05:17:00<U+2029>[39m 2013-01-01 <U+2029>[90m05:15:00<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m LGA    IAH           4        20 2013-01-01 <U+2029>[90m05:33:00<U+2029>[39m 2013-01-01 <U+2029>[90m05:29:00<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m JFK    MIA           2        33 2013-01-01 <U+2029>[90m05:42:00<U+2029>[39m 2013-01-01 <U+2029>[90m05:40:00<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m JFK    BQN          -<U+2029>[31m1<U+2029>[39m       -<U+2029>[31m18<U+2029>[39m 2013-01-01 <U+2029>[90m05:44:00<U+2029>[39m 2013-01-01 <U+2029>[90m05:45:00<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m LGA    ATL          -<U+2029>[31m6<U+2029>[39m       -<U+2029>[31m25<U+2029>[39m 2013-01-01 <U+2029>[90m05:54:00<U+2029>[39m 2013-01-01 <U+2029>[90m06:00:00<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m EWR    ORD          -<U+2029>[31m4<U+2029>[39m        12 2013-01-01 <U+2029>[90m05:54:00<U+2029>[39m 2013-01-01 <U+2029>[90m05:58:00<U+2029>[39mNA#> <U+2029>[90m# ... with 328,057 more rows, and 3 more variables: <U+2029>[1marr_time<U+2029>[22m <dttm>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1msched_arr_time<U+2029>[22m <dttm>, <U+2029>[1mair_time<U+2029>[22m <dbl><U+2029>[39mNA\nflights_dt %>% \n  ggplot(aes(dep_time)) + \n  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day\nflights_dt %>% \n  filter(dep_time < ymd(20130102)) %>% \n  ggplot(aes(dep_time)) + \n  geom_freqpoly(binwidth = 600) # 600 s = 10 minutes"},{"path":"dates-and-times.html","id":"from-other-types","chapter":"21 Dates and times","heading":"21.2.3 From other types","text":"may want switch date-time date.\n’s job as_datetime() as_date():Sometimes ’ll get date/times numeric offsets “Unix Epoch”, 1970-01-01.\noffset seconds, use as_datetime(); ’s days, use as_date().","code":"\nas_datetime(today())\n#> [1] \"2021-09-03 UTC\"\nas_date(now())\n#> [1] \"2021-09-03\"\nas_datetime(60 * 60 * 10)\n#> [1] \"1970-01-01 10:00:00 UTC\"\nas_date(365 * 10 + 2)\n#> [1] \"1980-01-01\""},{"path":"dates-and-times.html","id":"exercises-47","chapter":"21 Dates and times","heading":"21.2.4 Exercises","text":"happens parse string contains invalid dates?\n\nymd(c(\"2010-10-10\", \"bananas\"))happens parse string contains invalid dates?tzone argument today() ?\nimportant?tzone argument today() ?\nimportant?Use appropriate lubridate function parse following dates:\n\nd1 <- \"January 1, 2010\"\nd2 <- \"2015-Mar-07\"\nd3 <- \"06-Jun-2017\"\nd4 <- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 <- \"12/30/14\" # Dec 30, 2014Use appropriate lubridate function parse following dates:","code":"\nymd(c(\"2010-10-10\", \"bananas\"))\nd1 <- \"January 1, 2010\"\nd2 <- \"2015-Mar-07\"\nd3 <- \"06-Jun-2017\"\nd4 <- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 <- \"12/30/14\" # Dec 30, 2014"},{"path":"dates-and-times.html","id":"date-time-components","chapter":"21 Dates and times","heading":"21.3 Date-time components","text":"Now know get date-time data R’s date-time data structures, let’s explore can .\nsection focus accessor functions let get set individual components.\nnext section look arithmetic works date-times.","code":""},{"path":"dates-and-times.html","id":"getting-components","chapter":"21 Dates and times","heading":"21.3.1 Getting components","text":"can pull individual parts date accessor functions year(), month(), mday() (day month), yday() (day year), wday() (day week), hour(), minute(), second().month() wday() can set label = TRUE return abbreviated name month day week.\nSet abbr = FALSE return full name.can use wday() see flights depart week weekend:’s interesting pattern look average departure delay minute within hour.\nlooks like flights leaving minutes 20-30 50-60 much lower delays rest hour!Interestingly, look scheduled departure time don’t see strong pattern:see pattern actual departure times?\nWell, like much data collected humans, ’s strong bias towards flights leaving “nice” departure times.\nAlways alert sort pattern whenever work data involves human judgement!","code":"\ndatetime <- ymd_hms(\"2016-07-08 12:34:56\")\n\nyear(datetime)\n#> [1] 2016\nmonth(datetime)\n#> [1] 7\nmday(datetime)\n#> [1] 8\n\nyday(datetime)\n#> [1] 190\nwday(datetime)\n#> [1] 6\nmonth(datetime, label = TRUE)\n#> [1] 7月#> 12 Levels: 1月 < 2月 < 3月 < 4月 < 5月 < 6月 < 7月 < 8月 < 9月 < ... < 12月NAwday(datetime, label = TRUE, abbr = FALSE)\n#> [1] 星期五NA#> Levels: 星期日 < 星期一 < 星期二 < 星期三 < 星期四 < 星期五 < 星期六NA\nflights_dt %>% \n  mutate(wday = wday(dep_time, label = TRUE)) %>% \n  ggplot(aes(x = wday)) +\n    geom_bar()\nflights_dt %>% \n  mutate(minute = minute(dep_time)) %>% \n  group_by(minute) %>% \n  summarise(\n    avg_delay = mean(dep_delay, na.rm = TRUE),\n    n = n()) %>% \n  ggplot(aes(minute, avg_delay)) +\n    geom_line()\nsched_dep <- flights_dt %>% \n  mutate(minute = minute(sched_dep_time)) %>% \n  group_by(minute) %>% \n  summarise(\n    avg_delay = mean(arr_delay, na.rm = TRUE),\n    n = n())\n\nggplot(sched_dep, aes(minute, avg_delay)) +\n  geom_line()\nggplot(sched_dep, aes(minute, n)) +\n  geom_line()"},{"path":"dates-and-times.html","id":"rounding","chapter":"21 Dates and times","heading":"21.3.2 Rounding","text":"alternative approach plotting individual components round date nearby unit time, floor_date(), round_date(), ceiling_date().\nfunction takes vector dates adjust name unit round (floor), round (ceiling), round .\n, example, allows us plot number flights per week:Computing difference rounded unrounded date can particularly useful.","code":"\nflights_dt %>% \n  count(week = floor_date(dep_time, \"week\")) %>% \n  ggplot(aes(week, n)) +\n    geom_line()"},{"path":"dates-and-times.html","id":"setting-components","chapter":"21 Dates and times","heading":"21.3.3 Setting components","text":"can also use accessor function set components date/time:Alternatively, rather modifying place, can create new date-time update().\nalso allows set multiple values .values big, roll-:can use update() show distribution flights across course day every day year:Setting larger components date constant powerful technique allows explore patterns smaller components.","code":"\n(datetime <- ymd_hms(\"2016-07-08 12:34:56\"))\n#> [1] \"2016-07-08 12:34:56 UTC\"\n\nyear(datetime) <- 2020\ndatetime\n#> [1] \"2020-07-08 12:34:56 UTC\"\nmonth(datetime) <- 01\ndatetime\n#> [1] \"2020-01-08 12:34:56 UTC\"\nhour(datetime) <- hour(datetime) + 1\ndatetime\n#> [1] \"2020-01-08 13:34:56 UTC\"\nupdate(datetime, year = 2020, month = 2, mday = 2, hour = 2)\n#> [1] \"2020-02-02 02:34:56 UTC\"\nymd(\"2015-02-01\") %>% \n  update(mday = 30)\n#> [1] \"2015-03-02\"\nymd(\"2015-02-01\") %>% \n  update(hour = 400)\n#> [1] \"2015-02-17 16:00:00 UTC\"\nflights_dt %>% \n  mutate(dep_hour = update(dep_time, yday = 1)) %>% \n  ggplot(aes(dep_hour)) +\n    geom_freqpoly(binwidth = 300)"},{"path":"dates-and-times.html","id":"exercises-48","chapter":"21 Dates and times","heading":"21.3.4 Exercises","text":"distribution flight times within day change course year?distribution flight times within day change course year?Compare dep_time, sched_dep_time dep_delay.\nconsistent?\nExplain findings.Compare dep_time, sched_dep_time dep_delay.\nconsistent?\nExplain findings.Compare air_time duration departure arrival.\nExplain findings.\n(Hint: consider location airport.)Compare air_time duration departure arrival.\nExplain findings.\n(Hint: consider location airport.)average delay time change course day?\nuse dep_time sched_dep_time?\n?average delay time change course day?\nuse dep_time sched_dep_time?\n?day week leave want minimise chance delay?day week leave want minimise chance delay?makes distribution diamonds$carat flights$sched_dep_time similar?makes distribution diamonds$carat flights$sched_dep_time similar?Confirm hypothesis early departures flights minutes 20-30 50-60 caused scheduled flights leave early.\nHint: create binary variable tells whether flight delayed.Confirm hypothesis early departures flights minutes 20-30 50-60 caused scheduled flights leave early.\nHint: create binary variable tells whether flight delayed.","code":""},{"path":"dates-and-times.html","id":"time-spans","chapter":"21 Dates and times","heading":"21.4 Time spans","text":"Next ’ll learn arithmetic dates works, including subtraction, addition, division.\nAlong way, ’ll learn three important classes represent time spans:durations, represent exact number seconds.periods, represent human units like weeks months.intervals, represent starting ending point.","code":""},{"path":"dates-and-times.html","id":"durations","chapter":"21 Dates and times","heading":"21.4.1 Durations","text":"R, subtract two dates, get difftime object:difftime class object records time span seconds, minutes, hours, days, weeks.\nambiguity can make difftimes little painful work , lubridate provides alternative always uses seconds: duration.Durations come bunch convenient constructors:Durations always record time span seconds.\nLarger units created converting minutes, hours, days, weeks, years seconds standard rate (60 seconds minute, 60 minutes hour, 24 hours day, 7 days week, 365 days year).can add multiply durations:can add subtract durations days:However, durations represent exact number seconds, sometimes might get unexpected result:one day 1pm March 12, 2pm March 13?!\nlook carefully date might also notice time zones changed.\nDST, March 12 23 hours, add full days worth seconds end different time.","code":"\n# How old is Hadley?\nh_age <- today() - ymd(19791014)\nh_age\n#> Time difference of 15300 days\nas.duration(h_age)\n#> [1] \"1321920000s (~41.89 years)\"\ndseconds(15)\n#> [1] \"15s\"\ndminutes(10)\n#> [1] \"600s (~10 minutes)\"\ndhours(c(12, 24))\n#> [1] \"43200s (~12 hours)\" \"86400s (~1 days)\"\nddays(0:5)\n#> [1] \"0s\"                \"86400s (~1 days)\"  \"172800s (~2 days)\"\n#> [4] \"259200s (~3 days)\" \"345600s (~4 days)\" \"432000s (~5 days)\"\ndweeks(3)\n#> [1] \"1814400s (~3 weeks)\"\ndyears(1)\n#> [1] \"31557600s (~1 years)\"\n2 * dyears(1)\n#> [1] \"63115200s (~2 years)\"\ndyears(1) + dweeks(12) + dhours(15)\n#> [1] \"38869200s (~1.23 years)\"\ntomorrow <- today() + ddays(1)\nlast_year <- today() - dyears(1)\none_pm <- ymd_hms(\"2016-03-12 13:00:00\", tz = \"America/New_York\")\n\none_pm\n#> [1] \"2016-03-12 13:00:00 EST\"\none_pm + ddays(1)\n#> [1] \"2016-03-13 14:00:00 EDT\""},{"path":"dates-and-times.html","id":"periods","chapter":"21 Dates and times","heading":"21.4.2 Periods","text":"solve problem, lubridate provides periods.\nPeriods time spans don’t fixed length seconds, instead work “human” times, like days months.\nallows work intuitive way:Like durations, periods can created number friendly constructor functions.can add multiply periods:course, add dates.\nCompared durations, periods likely expect:Let’s use periods fix oddity related flight dates.\nplanes appear arrived destination departed New York City.overnight flights.\nused date information departure arrival times, flights arrived following day.\ncan fix adding days(1) arrival time overnight flight.Now flights obey laws physics.","code":"\none_pm\n#> [1] \"2016-03-12 13:00:00 EST\"\none_pm + days(1)\n#> [1] \"2016-03-13 13:00:00 EDT\"\nseconds(15)\n#> [1] \"15S\"\nminutes(10)\n#> [1] \"10M 0S\"\nhours(c(12, 24))\n#> [1] \"12H 0M 0S\" \"24H 0M 0S\"\ndays(7)\n#> [1] \"7d 0H 0M 0S\"\nmonths(1:6)\n#> [1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n#> [5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\nweeks(3)\n#> [1] \"21d 0H 0M 0S\"\nyears(1)\n#> [1] \"1y 0m 0d 0H 0M 0S\"\n10 * (months(6) + days(1))\n#> [1] \"60m 10d 0H 0M 0S\"\ndays(50) + hours(25) + minutes(2)\n#> [1] \"50d 25H 2M 0S\"\n# A leap year\nymd(\"2016-01-01\") + dyears(1)\n#> [1] \"2016-12-31 06:00:00 UTC\"\nymd(\"2016-01-01\") + years(1)\n#> [1] \"2017-01-01\"\n\n# Daylight Savings Time\none_pm + ddays(1)\n#> [1] \"2016-03-13 14:00:00 EDT\"\none_pm + days(1)\n#> [1] \"2016-03-13 13:00:00 EDT\"\nflights_dt %>% \n  filter(arr_time < dep_time) \n#> <U+2029>[90m# A tibble: 10,633 x 9<U+2029>[39mNA#>   <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m            <U+2029>[1msched_dep_time<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m              <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m             NA#> <U+2029>[90m1<U+2029>[39m EWR    BQN           9        -<U+2029>[31m4<U+2029>[39m 2013-01-01 <U+2029>[90m19:29:00<U+2029>[39m 2013-01-01 <U+2029>[90m19:20:00<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m JFK    DFW          59        <U+2029>[31mNA<U+2029>[39m 2013-01-01 <U+2029>[90m19:39:00<U+2029>[39m 2013-01-01 <U+2029>[90m18:40:00<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m EWR    TPA          -<U+2029>[31m2<U+2029>[39m         9 2013-01-01 <U+2029>[90m20:58:00<U+2029>[39m 2013-01-01 <U+2029>[90m21:00:00<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m EWR    SJU          -<U+2029>[31m6<U+2029>[39m       -<U+2029>[31m12<U+2029>[39m 2013-01-01 <U+2029>[90m21:02:00<U+2029>[39m 2013-01-01 <U+2029>[90m21:08:00<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m EWR    SFO          11       -<U+2029>[31m14<U+2029>[39m 2013-01-01 <U+2029>[90m21:08:00<U+2029>[39m 2013-01-01 <U+2029>[90m20:57:00<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m LGA    FLL         -<U+2029>[31m10<U+2029>[39m        -<U+2029>[31m2<U+2029>[39m 2013-01-01 <U+2029>[90m21:20:00<U+2029>[39m 2013-01-01 <U+2029>[90m21:30:00<U+2029>[39mNA#> <U+2029>[90m# ... with 10,627 more rows, and 3 more variables: <U+2029>[1marr_time<U+2029>[22m <dttm>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1msched_arr_time<U+2029>[22m <dttm>, <U+2029>[1mair_time<U+2029>[22m <dbl><U+2029>[39mNA\nflights_dt <- flights_dt %>% \n  mutate(\n    overnight = arr_time < dep_time,\n    arr_time = arr_time + days(ifelse(overnight, 0, 1)),\n    sched_arr_time = sched_arr_time + days(overnight * 1)\n  )\nflights_dt %>% \n  filter(overnight, arr_time < dep_time) \n#> <U+2029>[90m# A tibble: 10,633 x 10<U+2029>[39mNA#>   <U+2029>[1morigin<U+2029>[22m <U+2029>[1mdest<U+2029>[22m  <U+2029>[1mdep_delay<U+2029>[22m <U+2029>[1marr_delay<U+2029>[22m <U+2029>[1mdep_time<U+2029>[22m            <U+2029>[1msched_dep_time<U+2029>[22m     NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m  <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m     <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m              <U+2029>[3m<U+2029>[90m<dttm><U+2029>[39m<U+2029>[23m             NA#> <U+2029>[90m1<U+2029>[39m EWR    BQN           9        -<U+2029>[31m4<U+2029>[39m 2013-01-01 <U+2029>[90m19:29:00<U+2029>[39m 2013-01-01 <U+2029>[90m19:20:00<U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m JFK    DFW          59        <U+2029>[31mNA<U+2029>[39m 2013-01-01 <U+2029>[90m19:39:00<U+2029>[39m 2013-01-01 <U+2029>[90m18:40:00<U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m EWR    TPA          -<U+2029>[31m2<U+2029>[39m         9 2013-01-01 <U+2029>[90m20:58:00<U+2029>[39m 2013-01-01 <U+2029>[90m21:00:00<U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m EWR    SJU          -<U+2029>[31m6<U+2029>[39m       -<U+2029>[31m12<U+2029>[39m 2013-01-01 <U+2029>[90m21:02:00<U+2029>[39m 2013-01-01 <U+2029>[90m21:08:00<U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m EWR    SFO          11       -<U+2029>[31m14<U+2029>[39m 2013-01-01 <U+2029>[90m21:08:00<U+2029>[39m 2013-01-01 <U+2029>[90m20:57:00<U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m LGA    FLL         -<U+2029>[31m10<U+2029>[39m        -<U+2029>[31m2<U+2029>[39m 2013-01-01 <U+2029>[90m21:20:00<U+2029>[39m 2013-01-01 <U+2029>[90m21:30:00<U+2029>[39mNA#> <U+2029>[90m# ... with 10,627 more rows, and 4 more variables: <U+2029>[1marr_time<U+2029>[22m <dttm>,<U+2029>[39mNA#> <U+2029>[90m#   <U+2029>[1msched_arr_time<U+2029>[22m <dttm>, <U+2029>[1mair_time<U+2029>[22m <dbl>, <U+2029>[1movernight<U+2029>[22m <lgl><U+2029>[39mNA"},{"path":"dates-and-times.html","id":"intervals","chapter":"21 Dates and times","heading":"21.4.3 Intervals","text":"’s obvious dyears(1) / ddays(365) return: one, durations always represented number seconds, duration year defined 365 days worth seconds.years(1) / days(1) return?\nWell, year 2015 return 365, 2016, return 366!\n’s quite enough information lubridate give single clear answer.\ninstead give estimate, warning:want accurate measurement, ’ll use interval.\ninterval duration starting point: makes precise can determine exactly long :find many periods fall interval, need use integer division:","code":"\nyears(1) / days(1)\n#> [1] 365.25\nnext_year <- today() + years(1)\n(today() %--% next_year) / ddays(1)\n#> [1] 365\n(today() %--% next_year) %/% days(1)\n#> [1] 365"},{"path":"dates-and-times.html","id":"summary-1","chapter":"21 Dates and times","heading":"21.4.4 Summary","text":"pick duration, periods, intervals?\nalways, pick simplest data structure solves problem.\ncare physical time, use duration; need add human times, use period; need figure long span human units, use interval.Figure 21.1 summarises permitted arithmetic operations different data types.\nFigure 21.1: allowed arithmetic operations pairs date/time classes.\n","code":""},{"path":"dates-and-times.html","id":"exercises-49","chapter":"21 Dates and times","heading":"21.4.5 Exercises","text":"Explain days(overnight * 1) someone just started learning R.\nwork?Explain days(overnight * 1) someone just started learning R.\nwork?Create vector dates giving first day every month 2015.\nCreate vector dates giving first day every month current year.Create vector dates giving first day every month 2015.\nCreate vector dates giving first day every month current year.Write function given birthday (date), returns old years.Write function given birthday (date), returns old years.can’t (today() %--% (today() + years(1))) / months(1) work?can’t (today() %--% (today() + years(1))) / months(1) work?","code":""},{"path":"dates-and-times.html","id":"time-zones","chapter":"21 Dates and times","heading":"21.5 Time zones","text":"Time zones enormously complicated topic interaction geopolitical entities.\nFortunately don’t need dig details ’re important data analysis, challenges ’ll need tackle head .first challenge everyday names time zones tend ambiguous.\nexample, ’re American ’re probably familiar EST, Eastern Standard Time.\nHowever, Australia Canada also EST!\navoid confusion, R uses international standard IANA time zones.\nuse consistent naming scheme “/”, typically form “<continent>/<city>” (exceptions every country lies continent).\nExamples include “America/New_York”, “Europe/Paris”, “Pacific/Auckland”.might wonder time zone uses city, typically think time zones associated country region within country.\nIANA database record decades worth time zone rules.\ncourse decades, countries change names (break apart) fairly frequently, city names tend stay .\nAnother problem name needs reflect current behaviour, also complete history.\nexample, time zones “America/New_York” “America/Detroit”.\ncities currently use Eastern Standard Time 1969-1972 Michigan (state Detroit located), follow DST, needs different name.\n’s worth reading raw time zone database (available http://www.iana.org/time-zones) just read stories!can find R thinks current time zone Sys.timezone():(R doesn’t know, ’ll get NA.)see complete list time zone names OlsonNames():R, time zone attribute date-time controls printing.\nexample, three objects represent instant time:can verify ’re time using subtraction:Unless otherwise specified, lubridate always uses UTC.\nUTC (Coordinated Universal Time) standard time zone used scientific community roughly equivalent predecessor GMT (Greenwich Mean Time).\nDST, makes convenient representation computation.\nOperations combine date-times, like c(), often drop time zone.\ncase, date-times display local time zone:can change time zone two ways:Keep instant time , change ’s displayed.\nUse instant correct, want natural display.\n\nx4a <- with_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4a\n#> [1] \"2015-06-02 02:30:00 +1030\" \"2015-06-02 02:30:00 +1030\"\n#> [3] \"2015-06-02 02:30:00 +1030\"\nx4a - x4\n#> Time differences secs\n#> [1] 0 0 0\n(also illustrates another challenge times zones: ’re integer hour offsets!)Keep instant time , change ’s displayed.\nUse instant correct, want natural display.(also illustrates another challenge times zones: ’re integer hour offsets!)Change underlying instant time.\nUse instant labelled incorrect time zone, need fix .\n\nx4b <- force_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4b\n#> [1] \"2015-06-01 12:00:00 +1030\" \"2015-06-01 12:00:00 +1030\"\n#> [3] \"2015-06-01 12:00:00 +1030\"\nx4b - x4\n#> Time differences hours\n#> [1] -14.5 -14.5 -14.5Change underlying instant time.\nUse instant labelled incorrect time zone, need fix .","code":"\nSys.timezone()\n#> [1] \"Asia/Taipei\"\nlength(OlsonNames())\n#> [1] 593\nhead(OlsonNames())\n#> [1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n#> [4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"\n(x1 <- ymd_hms(\"2015-06-01 12:00:00\", tz = \"America/New_York\"))\n#> [1] \"2015-06-01 12:00:00 EDT\"\n(x2 <- ymd_hms(\"2015-06-01 18:00:00\", tz = \"Europe/Copenhagen\"))\n#> [1] \"2015-06-01 18:00:00 CEST\"\n(x3 <- ymd_hms(\"2015-06-02 04:00:00\", tz = \"Pacific/Auckland\"))\n#> [1] \"2015-06-02 04:00:00 NZST\"\nx1 - x2\n#> Time difference of 0 secs\nx1 - x3\n#> Time difference of 0 secs\nx4 <- c(x1, x2, x3)\nx4\n#> [1] \"2015-06-01 12:00:00 EDT\" \"2015-06-01 12:00:00 EDT\"\n#> [3] \"2015-06-01 12:00:00 EDT\"\nx4a <- with_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4a\n#> [1] \"2015-06-02 02:30:00 +1030\" \"2015-06-02 02:30:00 +1030\"\n#> [3] \"2015-06-02 02:30:00 +1030\"\nx4a - x4\n#> Time differences in secs\n#> [1] 0 0 0\nx4b <- force_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4b\n#> [1] \"2015-06-01 12:00:00 +1030\" \"2015-06-01 12:00:00 +1030\"\n#> [3] \"2015-06-01 12:00:00 +1030\"\nx4b - x4\n#> Time differences in hours\n#> [1] -14.5 -14.5 -14.5"},{"path":"column-wise.html","id":"column-wise","chapter":"22 Column-wise operations","heading":"22 Column-wise operations","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"column-wise.html","id":"introduction-15","chapter":"22 Column-wise operations","heading":"22.1 Introduction","text":"","code":""},{"path":"column-wise.html","id":"prerequisites-12","chapter":"22 Column-wise operations","heading":"22.1.1 Prerequisites","text":"chapter ’ll continue using dplyr.\ndplyr member core tidyverse.","code":"\nlibrary(tidyverse)"},{"path":"import-intro.html","id":"import-intro","chapter":"23 Introduction","heading":"23 Introduction","text":"part book, ’ll learn get R.\n’ll focus plain-text rectangular formats, spreadsheets, databases, web data.part book proceeds follows:Chapter 24, ’ll learn get plain-text data rectangular formats disk R.Chapter 24, ’ll learn get plain-text data rectangular formats disk R.Chapter 25, ’ll learn get data Excel spreadsheets Google Sheets R.Chapter 25, ’ll learn get data Excel spreadsheets Google Sheets R.Chapter 26, ’ll learn getting data R databases.\nChapter 26, ’ll learn getting data R databases.\nChapter 27, ’ll learn harvesting data web getting R.Chapter 27, ’ll learn harvesting data web getting R.’ll close part brief discussion types data pointers get R Chapter 28.’ll close part brief discussion types data pointers get R Chapter 28.","code":""},{"path":"import-rectangular.html","id":"import-rectangular","chapter":"24 Rectangular data","heading":"24 Rectangular data","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"import-spreadsheets.html","id":"import-spreadsheets","chapter":"25 Spreadsheets","heading":"25 Spreadsheets","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"import-databases.html","id":"import-databases","chapter":"26 Databases","heading":"26 Databases","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"import-webscrape.html","id":"import-webscrape","chapter":"27 Web scraping","heading":"27 Web scraping","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"import-other.html","id":"import-other","chapter":"28 Other types of data","heading":"28 Other types of data","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"wrangle-intro.html","id":"wrangle-intro","chapter":"29 Introduction","heading":"29 Introduction","text":"part book, ’ll learn data tidying, art getting data R useful form visualisation modelling.\nData wrangling important: without can’t work data!\nthree main parts data wrangling:part book proceeds follows:Chapter 30 give tools working list columns — data stored columns tibble lists.Chapter 30 give tools working list columns — data stored columns tibble lists.Chapter 31, ’ll learn hierarchical data formats turn rectangular data via unnesting.Chapter 31, ’ll learn hierarchical data formats turn rectangular data via unnesting.","code":""},{"path":"list-columns.html","id":"list-columns","chapter":"30 List columns","heading":"30 List columns","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":""},{"path":"list-columns.html","id":"introduction-16","chapter":"30 List columns","heading":"30.1 Introduction","text":"","code":""},{"path":"list-columns.html","id":"prerequisites-13","chapter":"30 List columns","heading":"30.1.1 Prerequisites","text":"chapter ’ll continue using tidyr, also provides bunch tools rectangle datasets.\ntidyr member core tidyverse.","code":"\nlibrary(tidyverse)"},{"path":"rectangle-data.html","id":"rectangle-data","chapter":"31 Data rectangling","heading":"31 Data rectangling","text":"","code":""},{"path":"rectangle-data.html","id":"introduction-17","chapter":"31 Data rectangling","heading":"31.1 Introduction","text":"","code":""},{"path":"rectangle-data.html","id":"prerequisites-14","chapter":"31 Data rectangling","heading":"31.1.1 Prerequisites","text":"chapter ’ll continue using tidyr, also provides bunch tools rectangle datasets.\ntidyr member core tidyverse.","code":"\nlibrary(tidyverse)"},{"path":"program-intro.html","id":"program-intro","chapter":"32 Introduction","heading":"32 Introduction","text":"part book, ’ll improve programming skills.\nProgramming cross-cutting skill needed data science work: must use computer data science; head, pencil paper.Programming produces code, code tool communication.\nObviously code tells computer want .\nalso communicates meaning humans.\nThinking code vehicle communication important every project fundamentally collaborative.\nEven ’re working people, ’ll definitely working future-!\nWriting clear code important others (like future-) can understand tackled analysis way .\nmeans getting better programming also involves getting better communicating.\ntime, want code become just easier write, easier others read.Writing code similar many ways writing prose.\nOne parallel find particularly useful cases rewriting key clarity.\nfirst expression ideas unlikely particularly clear, may need rewrite multiple times.\nsolving data analysis challenge, ’s often worth looking code thinking whether ’s obvious ’ve done.\nspend little time rewriting code ideas fresh, can save lot time later trying recreate code .\ndoesn’t mean rewrite every function: need balance need achieve now saving time long run.\n(rewrite functions likely first attempt clear.)following four chapters, ’ll learn skills allow tackle new programs solve existing problems greater clarity ease:Chapter 33, dive deep pipe, %>%, learn works, alternatives , use .Chapter 33, dive deep pipe, %>%, learn works, alternatives , use .Copy--paste powerful tool, avoid twice.\nRepeating code dangerous can easily lead errors inconsistencies.\nInstead, Chapter 34, ’ll learn write functions let extract repeated code can easily reused.Copy--paste powerful tool, avoid twice.\nRepeating code dangerous can easily lead errors inconsistencies.\nInstead, Chapter 34, ’ll learn write functions let extract repeated code can easily reused.start write powerful functions, ’ll need solid grounding R’s data structures, provided vectors, discuss Chapter 35.\nmust master four common atomic vectors, three important S3 classes built top , understand mysteries list data frame.start write powerful functions, ’ll need solid grounding R’s data structures, provided vectors, discuss Chapter 35.\nmust master four common atomic vectors, three important S3 classes built top , understand mysteries list data frame.Functions extract repeated code, often need repeat actions different inputs.\nneed tools iteration let similar things .\ntools include loops functional programming, ’ll learn Chapter 36.Functions extract repeated code, often need repeat actions different inputs.\nneed tools iteration let similar things .\ntools include loops functional programming, ’ll learn Chapter 36.","code":""},{"path":"program-intro.html","id":"learning-more-2","chapter":"32 Introduction","heading":"32.1 Learning more","text":"goal chapters teach minimum programming need practice data science, turns reasonable amount.\nmastered material book, strongly believe invest programming skills.\nLearning programming long-term investment: won’t pay immediately, long term allow solve new problems quickly, let reuse insights previous problems new scenarios.learn need study R programming language, just interactive environment data science.\nwritten two books help :Hands Programming R, Garrett Grolemund.\nintroduction R programming language great place start R first programming language.\ncovers similar material chapters, different style different motivation examples (based casino).\n’s useful complement find four chapters go quickly.Hands Programming R, Garrett Grolemund.\nintroduction R programming language great place start R first programming language.\ncovers similar material chapters, different style different motivation examples (based casino).\n’s useful complement find four chapters go quickly.Advanced R Hadley Wickham.\ndives details R programming language.\ngreat place start existing programming experience.\n’s also great next step ’ve internalised ideas chapters.\ncan read online http://adv-r..co.nz.Advanced R Hadley Wickham.\ndives details R programming language.\ngreat place start existing programming experience.\n’s also great next step ’ve internalised ideas chapters.\ncan read online http://adv-r..co.nz.","code":""},{"path":"pipes.html","id":"pipes","chapter":"33 Pipes","heading":"33 Pipes","text":"","code":""},{"path":"pipes.html","id":"introduction-18","chapter":"33 Pipes","heading":"33.1 Introduction","text":"Pipes powerful tool clearly expressing sequence multiple operations.\nfar, ’ve using without knowing work, alternatives .\nNow, chapter, ’s time explore pipe detail.\n’ll learn alternatives pipe, shouldn’t use pipe, useful related tools.","code":""},{"path":"pipes.html","id":"prerequisites-15","chapter":"33 Pipes","heading":"33.1.1 Prerequisites","text":"pipe, %>%, comes magrittr package Stefan Milton Bache.\nPackages tidyverse load %>% automatically, don’t usually load magrittr explicitly.\n, however, ’re focussing piping, aren’t loading packages, load explicitly.","code":"\nlibrary(magrittr)"},{"path":"pipes.html","id":"piping-alternatives","chapter":"33 Pipes","heading":"33.2 Piping alternatives","text":"point pipe help write code way easier read understand.\nsee pipe useful, ’re going explore number ways writing code.\nLet’s use code tell story little bunny named Foo Foo:Little bunny Foo Foo\nWent hopping forest\nScooping field mice\nbopping \nadThis popular Children’s poem accompanied hand actions.’ll start defining object represent little bunny Foo Foo:’ll use function key verb: hop(), scoop(), bop().\nUsing object verbs, (least) four ways retell story code:Save intermediate step new object.Overwrite original object many times.Compose functions.Use pipe.’ll work approach, showing code talking advantages disadvantages.","code":"\nfoo_foo <- little_bunny()"},{"path":"pipes.html","id":"intermediate-steps","chapter":"33 Pipes","heading":"33.2.1 Intermediate steps","text":"simplest approach save step new object:main downside form forces name intermediate element.\nnatural names, good idea, .\nmany times, like example, aren’t natural names, add numeric suffixes make names unique.\nleads two problems:code cluttered unimportant namesThe code cluttered unimportant namesYou carefully increment suffix line.carefully increment suffix line.Whenever write code like , invariably use wrong number one line spend 10 minutes scratching head trying figure went wrong code.may also worry form creates many copies data takes lot memory.\nSurprisingly, ’s case.\nFirst, note proactively worrying memory useful way spend time: worry becomes problem (.e. run memory), .\nSecond, R isn’t stupid, share columns across data frames, possible.\nLet’s take look actual data manipulation pipeline add new column ggplot2::diamonds:pryr::object_size() gives memory occupied arguments.\nresults seem counterintuitive first:diamonds takes 3.46 MB,diamonds2 takes 3.89 MB,diamonds diamonds2 together take 3.89 MB!can work?\nWell, diamonds2 10 columns common diamonds: ’s need duplicate data, two data frames variables common.\nvariables get copied modify one .\nfollowing example, modify single value diamonds$carat.\nmeans carat variable can longer shared two data frames, copy must made.\nsize data frame unchanged, collective size increases:(Note use pryr::object_size() , built-object.size().\nobject.size() takes single object can’t compute data shared across multiple objects.)","code":"\nfoo_foo_1 <- hop(foo_foo, through = forest)\nfoo_foo_2 <- scoop(foo_foo_1, up = field_mice)\nfoo_foo_3 <- bop(foo_foo_2, on = head)\ndiamonds <- ggplot2::diamonds\ndiamonds2 <- diamonds %>% \n  dplyr::mutate(price_per_carat = price / carat)\n\npryr::object_size(diamonds)\n#> 3,456,344 B\npryr::object_size(diamonds2)\n#> 3,887,976 B\npryr::object_size(diamonds, diamonds2)\n#> 3,888,552 B\ndiamonds$carat[1] <- NA\npryr::object_size(diamonds)\n#> 3,456,344 B\npryr::object_size(diamonds2)\n#> 3,887,976 B\npryr::object_size(diamonds, diamonds2)\n#> 4,320,120 B"},{"path":"pipes.html","id":"overwrite-the-original","chapter":"33 Pipes","heading":"33.2.2 Overwrite the original","text":"Instead creating intermediate objects step, overwrite original object:less typing (less thinking), ’re less likely make mistakes.\nHowever, two problems:Debugging painful: make mistake ’ll need re-run complete pipeline beginning.Debugging painful: make mistake ’ll need re-run complete pipeline beginning.repetition object transformed (’ve written foo_foo six times!) obscures ’s changing line.repetition object transformed (’ve written foo_foo six times!) obscures ’s changing line.","code":"\nfoo_foo <- hop(foo_foo, through = forest)\nfoo_foo <- scoop(foo_foo, up = field_mice)\nfoo_foo <- bop(foo_foo, on = head)"},{"path":"pipes.html","id":"function-composition","chapter":"33 Pipes","heading":"33.2.3 Function composition","text":"Another approach abandon assignment just string function calls together:disadvantage read inside-, right--left, arguments end spread far apart (evocatively called Dagwood sandwich problem).\nshort, code hard human consume.","code":"\nbop(\n  scoop(\n    hop(foo_foo, through = forest),\n    up = field_mice\n  ), \n  on = head\n)"},{"path":"pipes.html","id":"use-the-pipe","chapter":"33 Pipes","heading":"33.2.4 Use the pipe","text":"Finally, can use pipe:favourite form, focusses verbs, nouns.\ncan read series function compositions like ’s set imperative actions.\nFoo Foo hops, scoops, bops.\ndownside, course, need familiar pipe.\n’ve never seen %>% , ’ll idea code .\nFortunately, people pick idea quickly, share code others aren’t familiar pipe, can easily teach .pipe works performing “lexical transformation”: behind scenes, magrittr reassembles code pipe form works overwriting intermediate object.\nrun pipe like one , magrittr something like :means pipe won’t work two classes functions:Functions use current environment.\nexample, assign() create new variable given name current environment:\n\nassign(\"x\", 10)\nx\n#> [1] 10\n\n\"x\" %>% assign(100)\nx\n#> [1] 10\nuse assign pipe work assigns temporary environment used %>%.\nwant use assign pipe, must explicit environment:\n\nenv <- environment()\n\"x\" %>% assign(100, envir = env)\nx\n#> [1] 100\nfunctions problem include get() load().Functions use current environment.\nexample, assign() create new variable given name current environment:use assign pipe work assigns temporary environment used %>%.\nwant use assign pipe, must explicit environment:functions problem include get() load().Functions use lazy evaluation.\nR, function arguments computed function uses , prior calling function.\npipe computes element turn, can’t rely behaviour.\nOne place problem tryCatch(), lets capture handle errors:\n\ntryCatch(stop(\"!\"), error = function(e) \"error\")\n#> [1] \"error\"\n\nstop(\"!\") %>% \n  tryCatch(error = function(e) \"error\")\n#> [1] \"error\"\nrelatively wide class functions behaviour, including try(), suppressMessages(), suppressWarnings() base R.Functions use lazy evaluation.\nR, function arguments computed function uses , prior calling function.\npipe computes element turn, can’t rely behaviour.One place problem tryCatch(), lets capture handle errors:relatively wide class functions behaviour, including try(), suppressMessages(), suppressWarnings() base R.","code":"\nfoo_foo %>%\n  hop(through = forest) %>%\n  scoop(up = field_mice) %>%\n  bop(on = head)\nmy_pipe <- function(.) {\n  . <- hop(., through = forest)\n  . <- scoop(., up = field_mice)\n  bop(., on = head)\n}\nmy_pipe(foo_foo)\nassign(\"x\", 10)\nx\n#> [1] 10\n\n\"x\" %>% assign(100)\nx\n#> [1] 10\nenv <- environment()\n\"x\" %>% assign(100, envir = env)\nx\n#> [1] 100\ntryCatch(stop(\"!\"), error = function(e) \"An error\")\n#> [1] \"An error\"\n\nstop(\"!\") %>% \n  tryCatch(error = function(e) \"An error\")\n#> [1] \"An error\""},{"path":"pipes.html","id":"when-not-to-use-the-pipe","chapter":"33 Pipes","heading":"33.3 When not to use the pipe","text":"pipe powerful tool, ’s tool disposal, doesn’t solve every problem!\nPipes useful rewriting fairly short linear sequence operations.\nthink reach another tool :pipes longer (say) ten steps.\ncase, create intermediate objects meaningful names.\nmake debugging easier, can easily check intermediate results, makes easier understand code, variable names can help communicate intent.pipes longer (say) ten steps.\ncase, create intermediate objects meaningful names.\nmake debugging easier, can easily check intermediate results, makes easier understand code, variable names can help communicate intent.multiple inputs outputs.\nisn’t one primary object transformed, two objects combined together, don’t use pipe.multiple inputs outputs.\nisn’t one primary object transformed, two objects combined together, don’t use pipe.starting think directed graph complex dependency structure.\nPipes fundamentally linear expressing complex relationships typically yield confusing code.starting think directed graph complex dependency structure.\nPipes fundamentally linear expressing complex relationships typically yield confusing code.","code":""},{"path":"pipes.html","id":"other-tools-from-magrittr","chapter":"33 Pipes","heading":"33.4 Other tools from magrittr","text":"packages tidyverse automatically make %>% available , don’t normally load magrittr explicitly.\nHowever, useful tools inside magrittr might want try :working complex pipes, ’s sometimes useful call function side-effects.\nMaybe want print current object, plot , save disk.\nMany times, functions don’t return anything, effectively terminating pipe.\nwork around problem, can use “tee” pipe.\n%T>% works like %>% except returns left-hand side instead right-hand side.\n’s called “tee” ’s like literal T-shaped pipe.\n\nrnorm(100) %>%\n  matrix(ncol = 2) %>%\n  plot() %>%\n  str()\n#>  NULL\n\nrnorm(100) %>%\n  matrix(ncol = 2) %T>%\n  plot() %>%\n  str()\n#>  num [1:50, 1:2] -0.387 -0.785 -1.057 -0.796 -1.756 ...\nworking complex pipes, ’s sometimes useful call function side-effects.\nMaybe want print current object, plot , save disk.\nMany times, functions don’t return anything, effectively terminating pipe.work around problem, can use “tee” pipe.\n%T>% works like %>% except returns left-hand side instead right-hand side.\n’s called “tee” ’s like literal T-shaped pipe.’re working functions don’t data frame based API\n(.e. pass individual vectors, data frame expressions evaluated context data frame), might find %$% useful.\n“explodes” variables data frame can refer explicitly.\nuseful working many functions base R:\n\nmtcars %$%\n  cor(disp, mpg)\n#> [1] -0.8475514If ’re working functions don’t data frame based API\n(.e. pass individual vectors, data frame expressions evaluated context data frame), might find %$% useful.\n“explodes” variables data frame can refer explicitly.\nuseful working many functions base R:assignment magrittr provides %<>% operator allows replace code like:\n\nmtcars <- mtcars %>% \n  transform(cyl = cyl * 2)\n\n\nmtcars %<>% transform(cyl = cyl * 2)\n’m fan operator think assignment special operation always clear ’s occurring.\nopinion, little bit duplication (.e. repeating name object twice) fine return making assignment explicit.assignment magrittr provides %<>% operator allows replace code like:withI’m fan operator think assignment special operation always clear ’s occurring.\nopinion, little bit duplication (.e. repeating name object twice) fine return making assignment explicit.","code":"\nrnorm(100) %>%\n  matrix(ncol = 2) %>%\n  plot() %>%\n  str()\n#>  NULL\n\nrnorm(100) %>%\n  matrix(ncol = 2) %T>%\n  plot() %>%\n  str()\n#>  num [1:50, 1:2] -0.387 -0.785 -1.057 -0.796 -1.756 ...\nmtcars %$%\n  cor(disp, mpg)\n#> [1] -0.8475514\nmtcars <- mtcars %>% \n  transform(cyl = cyl * 2)\nmtcars %<>% transform(cyl = cyl * 2)"},{"path":"functions.html","id":"functions","chapter":"34 Functions","heading":"34 Functions","text":"","code":""},{"path":"functions.html","id":"introduction-19","chapter":"34 Functions","heading":"34.1 Introduction","text":"One best ways improve reach data scientist write functions.\nFunctions allow automate common tasks powerful general way copy--pasting.\nWriting function three big advantages using copy--paste:can give function evocative name makes code easier understand.can give function evocative name makes code easier understand.requirements change, need update code one place, instead many.requirements change, need update code one place, instead many.eliminate chance making incidental mistakes copy paste (.e. updating variable name one place, another).eliminate chance making incidental mistakes copy paste (.e. updating variable name one place, another).Writing good functions lifetime journey.\nEven using R many years still learn new techniques better ways approaching old problems.\ngoal chapter teach every esoteric detail functions get started pragmatic advice can apply immediately.well practical advice writing functions, chapter also gives suggestions style code.\nGood code style like correct punctuation.\nYoucanmanagewithoutit, sure makes things easier read!\nstyles punctuation, many possible variations.\npresent style use code, important thing consistent.","code":""},{"path":"functions.html","id":"prerequisites-16","chapter":"34 Functions","heading":"34.1.1 Prerequisites","text":"focus chapter writing functions base R, won’t need extra packages.","code":""},{"path":"functions.html","id":"when-should-you-write-a-function","chapter":"34 Functions","heading":"34.2 When should you write a function?","text":"consider writing function whenever ’ve copied pasted block code twice (.e. now three copies code).\nexample, take look code.\n?might able puzzle rescales column range 0 1.\nspot mistake?\nmade error copying--pasting code df$b: forgot change b.\nExtracting repeated code function good idea prevents making type mistake.write function need first analyse code.\nmany inputs ?code one input: df$.\n(’re surprised TRUE input, can explore exercise .) make inputs clear, ’s good idea rewrite code using temporary variables general names.\ncode requires single numeric vector, ’ll call x:duplication code.\n’re computing range data three times, makes sense one step:Pulling intermediate calculations named variables good practice makes clear code .\nNow ’ve simplified code, checked still works, can turn function:three key steps creating new function:need pick name function.\n’ve used rescale01 function rescales vector lie 0 1.need pick name function.\n’ve used rescale01 function rescales vector lie 0 1.list inputs, arguments, function inside function.\njust one argument.\ncall look like function(x, y, z).list inputs, arguments, function inside function.\njust one argument.\ncall look like function(x, y, z).place code developed body function, { block immediately follows function(...).place code developed body function, { block immediately follows function(...).Note overall process: made function ’d figured make work simple input.\n’s easier start working code turn function; ’s harder create function try make work.point ’s good idea check function different inputs:write functions ’ll eventually want convert informal, interactive tests formal, automated tests.\nprocess called unit testing.\nUnfortunately, ’s beyond scope book, can learn http://r-pkgs..co.nz/tests.html.can simplify original example now function:Compared original, code easier understand ’ve eliminated one class copy--paste errors.\nstill quite bit duplication since ’re thing multiple columns.\n’ll learn eliminate duplication iteration Chapter 36, ’ve learned R’s data structures Chapter 35.Another advantage functions requirements change, need make change one place.\nexample, might discover variables include infinite values, rescale01() fails:’ve extracted code function, need make fix one place:important part “repeat ” (DRY) principle.\nrepetition code, places need remember update things change (always !), likely create bugs time.","code":"\ndf <- tibble::tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf$a <- (df$a - min(df$a, na.rm = TRUE)) / \n  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\ndf$b <- (df$b - min(df$b, na.rm = TRUE)) / \n  (max(df$b, na.rm = TRUE) - min(df$a, na.rm = TRUE))\ndf$c <- (df$c - min(df$c, na.rm = TRUE)) / \n  (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))\ndf$d <- (df$d - min(df$d, na.rm = TRUE)) / \n  (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))\n(df$a - min(df$a, na.rm = TRUE)) /\n  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\nx <- df$a\n(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n#>  [1] 0.2892677 0.7509271 0.0000000 0.6781686 0.8530656 1.0000000 0.1716402\n#>  [8] 0.6107464 0.6116181 0.6008793\nrng <- range(x, na.rm = TRUE)\n(x - rng[1]) / (rng[2] - rng[1])\n#>  [1] 0.2892677 0.7509271 0.0000000 0.6781686 0.8530656 1.0000000 0.1716402\n#>  [8] 0.6107464 0.6116181 0.6008793\nrescale01 <- function(x) {\n  rng <- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\nrescale01(c(0, 5, 10))\n#> [1] 0.0 0.5 1.0\nrescale01(c(-10, 0, 10))\n#> [1] 0.0 0.5 1.0\nrescale01(c(1, 2, 3, NA, 5))\n#> [1] 0.00 0.25 0.50   NA 1.00\ndf$a <- rescale01(df$a)\ndf$b <- rescale01(df$b)\ndf$c <- rescale01(df$c)\ndf$d <- rescale01(df$d)\nx <- c(1:10, Inf)\nrescale01(x)\n#>  [1]   0   0   0   0   0   0   0   0   0   0 NaN\nrescale01 <- function(x) {\n  rng <- range(x, na.rm = TRUE, finite = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\nrescale01(x)\n#>  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n#>  [8] 0.7777778 0.8888889 1.0000000       Inf"},{"path":"functions.html","id":"exercises-50","chapter":"34 Functions","heading":"34.2.1 Exercises","text":"TRUE parameter rescale01()?\nhappen x contained single missing value, na.rm FALSE?TRUE parameter rescale01()?\nhappen x contained single missing value, na.rm FALSE?second variant rescale01(), infinite values left unchanged.\nRewrite rescale01() -Inf mapped 0, Inf mapped 1.second variant rescale01(), infinite values left unchanged.\nRewrite rescale01() -Inf mapped 0, Inf mapped 1.Practice turning following code snippets functions.\nThink function .\ncall ?\nmany arguments need?\nCan rewrite expressive less duplicative?\n\nmean(.na(x))\n\nx / sum(x, na.rm = TRUE)\n\nsd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)Practice turning following code snippets functions.\nThink function .\ncall ?\nmany arguments need?\nCan rewrite expressive less duplicative?Write functions compute variance skewness numeric vector.\nVariance defined \\[\n\\mathrm{Var}(x) = \\frac{1}{n - 1} \\sum_{=1}^n (x_i - \\bar{x}) ^2 \\text{,}\n\\] \\(\\bar{x} = (\\sum_i^n x_i) / n\\) sample mean.\nSkewness defined \\[\n\\mathrm{Skew}(x) = \\frac{\\frac{1}{n-2}\\left(\\sum_{=1}^n(x_i - \\bar x)^3\\right)}{\\mathrm{Var}(x)^{3/2}} \\text{.}\n\\]Write functions compute variance skewness numeric vector.\nVariance defined \\[\n\\mathrm{Var}(x) = \\frac{1}{n - 1} \\sum_{=1}^n (x_i - \\bar{x}) ^2 \\text{,}\n\\] \\(\\bar{x} = (\\sum_i^n x_i) / n\\) sample mean.\nSkewness defined \\[\n\\mathrm{Skew}(x) = \\frac{\\frac{1}{n-2}\\left(\\sum_{=1}^n(x_i - \\bar x)^3\\right)}{\\mathrm{Var}(x)^{3/2}} \\text{.}\n\\]Write both_na(), function takes two vectors length returns number positions NA vectors.Write both_na(), function takes two vectors length returns number positions NA vectors.following functions ?\nuseful even though short?\n\nis_directory <- function(x) file.info(x)$isdir\nis_readable <- function(x) file.access(x, 4) == 0What following functions ?\nuseful even though short?Read complete lyrics “Little Bunny Foo Foo”.\n’s lot duplication song.\nExtend initial piping example recreate complete song, use functions reduce duplication.Read complete lyrics “Little Bunny Foo Foo”.\n’s lot duplication song.\nExtend initial piping example recreate complete song, use functions reduce duplication.","code":"\nmean(is.na(x))\n\nx / sum(x, na.rm = TRUE)\n\nsd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)\nis_directory <- function(x) file.info(x)$isdir\nis_readable <- function(x) file.access(x, 4) == 0"},{"path":"functions.html","id":"functions-are-for-humans-and-computers","chapter":"34 Functions","heading":"34.3 Functions are for humans and computers","text":"’s important remember functions just computer, also humans.\nR doesn’t care function called, comments contains, important human readers.\nsection discusses things bear mind writing functions humans can understand.name function important.\nIdeally, name function short, clearly evoke function .\n’s hard!\n’s better clear short, RStudio’s autocomplete makes easy type long names.Generally, function names verbs, arguments nouns.\nexceptions: nouns ok function computes well known noun (.e. mean() better compute_mean()), accessing property object (.e. coef() better get_coefficients()).\ngood sign noun might better choice ’re using broad verb like “get”, “compute”, “calculate”, “determine”.\nUse best judgement don’t afraid rename function figure better name later.function name composed multiple words, recommend using “snake_case”, lowercase word separated underscore.\ncamelCase popular alternative.\ndoesn’t really matter one pick, important thing consistent: pick one stick .\nR consistent, ’s nothing can .\nMake sure don’t fall trap making code consistent possible.family functions similar things, make sure consistent names arguments.\nUse common prefix indicate connected.\n’s better common suffix autocomplete allows type prefix see members family.good example design stringr package: don’t remember exactly function need, can type str_ jog memory.possible, avoid overriding existing functions variables.\n’s impossible general many good names already taken packages, avoiding common names base R avoid confusion.Use comments, lines starting #, explain “” code.\ngenerally avoid comments explain “” “”.\ncan’t understand code reading , think rewrite clear.\nneed add intermediate variables useful names?\nneed break subcomponent large function can name ?\nHowever, code can never capture reasoning behind decisions: choose approach instead alternative?\nelse try didn’t work?\n’s great idea capture sort thinking comment.Another important use comments break file easily readable chunks.\nUse long lines - = make easy spot breaks.RStudio provides keyboard shortcut create headers (Cmd/Ctrl + Shift + R), display code navigation drop-bottom-left editor:","code":"\n# Too short\nf()\n\n# Not a verb, or descriptive\nmy_awesome_function()\n\n# Long, but clear\nimpute_missing()\ncollapse_years()\n# Never do this!\ncol_mins <- function(x, y) {}\nrowMaxes <- function(y, x) {}\n# Good\ninput_select()\ninput_checkbox()\ninput_text()\n\n# Not so good\nselect_input()\ncheckbox_input()\ntext_input()\n# Don't do this!\nT <- FALSE\nc <- 10\nmean <- function(x) sum(x)\n# Load data --------------------------------------\n\n# Plot data --------------------------------------"},{"path":"functions.html","id":"exercises-51","chapter":"34 Functions","heading":"34.3.1 Exercises","text":"Read source code following three functions, puzzle , brainstorm better names.\n\nf1 <- function(string, prefix) {\n  substr(string, 1, nchar(prefix)) == prefix\n}\nf2 <- function(x) {\n  (length(x) <= 1) return(NULL)\n  x[-length(x)]\n}\nf3 <- function(x, y) {\n  rep(y, length.= length(x))\n}Read source code following three functions, puzzle , brainstorm better names.Take function ’ve written recently spend 5 minutes brainstorming better name arguments.Take function ’ve written recently spend 5 minutes brainstorming better name arguments.Compare contrast rnorm() MASS::mvrnorm().\nmake consistent?Compare contrast rnorm() MASS::mvrnorm().\nmake consistent?Make case norm_r(), norm_d() etc better rnorm(), dnorm().\nMake case opposite.Make case norm_r(), norm_d() etc better rnorm(), dnorm().\nMake case opposite.","code":"\nf1 <- function(string, prefix) {\n  substr(string, 1, nchar(prefix)) == prefix\n}\nf2 <- function(x) {\n  if (length(x) <= 1) return(NULL)\n  x[-length(x)]\n}\nf3 <- function(x, y) {\n  rep(y, length.out = length(x))\n}"},{"path":"functions.html","id":"conditional-execution","chapter":"34 Functions","heading":"34.4 Conditional execution","text":"statement allows conditionally execute code.\nlooks like :get help need surround backticks: ?``.\nhelp isn’t particularly helpful ’re already experienced programmer, least know get !’s simple function uses statement.\ngoal function return logical vector describing whether element vector named.function takes advantage standard return rule: function returns last value computed.\neither one two branches statement.","code":"\nif (condition) {\n  # code executed when condition is TRUE\n} else {\n  # code executed when condition is FALSE\n}\nhas_name <- function(x) {\n  nms <- names(x)\n  if (is.null(nms)) {\n    rep(FALSE, length(x))\n  } else {\n    !is.na(nms) & nms != \"\"\n  }\n}"},{"path":"functions.html","id":"conditions","chapter":"34 Functions","heading":"34.4.1 Conditions","text":"condition must evaluate either TRUE FALSE.\n’s vector, ’ll get warning message; ’s NA, ’ll get error.\nWatch messages code:can use || () && () combine multiple logical expressions.\noperators “short-circuiting”: soon || sees first TRUE returns TRUE without computing anything else.\nsoon && sees first FALSE returns FALSE.\nnever use | & statement: vectorised operations apply multiple values (’s use filter()).\nlogical vector, can use () () collapse single value.careful testing equality.\n== vectorised, means ’s easy get one output.\nEither check length already 1, collapse () (), use non-vectorised identical().\nidentical() strict: always returns either single TRUE single FALSE, doesn’t coerce types.\nmeans need careful comparing integers doubles:also need wary floating point numbers:Instead use dplyr::near() comparisons, described [comparisons].remember, x == NA doesn’t anything useful!","code":"\nif (c(TRUE, FALSE)) {}\n#> Warning in if (c(TRUE, FALSE)) {: the condition has length > 1 and only the\n#> first element will be used\n#> NULL\n\nif (NA) {}\n#> Error in if (NA) {: missing value where TRUE/FALSE needed\nidentical(0L, 0)\n#> [1] FALSE\nx <- sqrt(2) ^ 2\nx\n#> [1] 2\nx == 2\n#> [1] FALSE\nx - 2\n#> [1] 4.440892e-16"},{"path":"functions.html","id":"multiple-conditions","chapter":"34 Functions","heading":"34.4.2 Multiple conditions","text":"can chain multiple statements together:end long series chained statements, consider rewriting.\nOne useful technique switch() function.\nallows evaluate selected code based position name.Another useful function can often eliminate long chains statements cut().\n’s used discretise continuous variables.","code":"\nif (this) {\n  # do that\n} else if (that) {\n  # do something else\n} else {\n  # \n}#> function(x, y, op) {\n#>   switch(op,\n#>     plus = x + y,\n#>     minus = x - y,\n#>     times = x * y,\n#>     divide = x / y,\n#>     stop(\"Unknown op!\")\n#>   )\n#> }"},{"path":"functions.html","id":"code-style","chapter":"34 Functions","heading":"34.4.3 Code style","text":"function (almost) always followed squiggly brackets ({}), contents indented two spaces.\nmakes easier see hierarchy code skimming left-hand margin.opening curly brace never go line always followed new line.\nclosing curly brace always go line, unless ’s followed else.\nAlways indent code inside curly braces.’s ok drop curly braces short statement can fit one line:recommend brief statements.\nOtherwise, full form easier read:","code":"# Good\nif (y < 0 && debug) {\n  message(\"Y is negative\")\n}\n\nif (y == 0) {\n  log(x)\n} else {\n  y ^ x\n}\n\n# Bad\nif (y < 0 && debug)\nmessage(\"Y is negative\")\n\nif (y == 0) {\n  log(x)\n} \nelse {\n  y ^ x\n}\ny <- 10\nx <- if (y < 20) \"Too low\" else \"Too high\"\nif (y < 20) {\n  x <- \"Too low\" \n} else {\n  x <- \"Too high\"\n}"},{"path":"functions.html","id":"exercises-52","chapter":"34 Functions","heading":"34.4.4 Exercises","text":"’s difference ifelse()?\nCarefully read help construct three examples illustrate key differences.’s difference ifelse()?\nCarefully read help construct three examples illustrate key differences.Write greeting function says “good morning”, “good afternoon”, “good evening”, depending time day.\n(Hint: use time argument defaults lubridate::now().\nmake easier test function.)Write greeting function says “good morning”, “good afternoon”, “good evening”, depending time day.\n(Hint: use time argument defaults lubridate::now().\nmake easier test function.)Implement fizzbuzz function.\ntakes single number input.\nnumber divisible three, returns “fizz”.\n’s divisible five returns “buzz”.\n’s divisible three five, returns “fizzbuzz”.\nOtherwise, returns number.\nMake sure first write working code create function.Implement fizzbuzz function.\ntakes single number input.\nnumber divisible three, returns “fizz”.\n’s divisible five returns “buzz”.\n’s divisible three five, returns “fizzbuzz”.\nOtherwise, returns number.\nMake sure first write working code create function.use cut() simplify set nested -else statements?\n\n(temp <= 0) {\n  \"freezing\"\n} else (temp <= 10) {\n  \"cold\"\n} else (temp <= 20) {\n  \"cool\"\n} else (temp <= 30) {\n  \"warm\"\n} else {\n  \"hot\"\n}\nchange call cut() ’d used < instead <=?\nchief advantage cut() problem?\n(Hint: happens many values temp?)use cut() simplify set nested -else statements?change call cut() ’d used < instead <=?\nchief advantage cut() problem?\n(Hint: happens many values temp?)happens use switch() numeric values?happens use switch() numeric values?switch() call ?\nhappens x “e”?\n\nswitch(x, \n  = ,\n  b = \"ab\",\n  c = ,\n  d = \"cd\"\n)\nExperiment, carefully read documentation.switch() call ?\nhappens x “e”?Experiment, carefully read documentation.","code":"\nif (temp <= 0) {\n  \"freezing\"\n} else if (temp <= 10) {\n  \"cold\"\n} else if (temp <= 20) {\n  \"cool\"\n} else if (temp <= 30) {\n  \"warm\"\n} else {\n  \"hot\"\n}\nswitch(x, \n  a = ,\n  b = \"ab\",\n  c = ,\n  d = \"cd\"\n)"},{"path":"functions.html","id":"function-arguments","chapter":"34 Functions","heading":"34.5 Function arguments","text":"arguments function typically fall two broad sets: one set supplies data compute , supplies arguments control details computation.\nexample:log(), data x, detail base logarithm.log(), data x, detail base logarithm.mean(), data x, details much data trim ends (trim) handle missing values (na.rm).mean(), data x, details much data trim ends (trim) handle missing values (na.rm).t.test(), data x y, details test alternative, mu, paired, var.equal, conf.level.t.test(), data x y, details test alternative, mu, paired, var.equal, conf.level.str_c() can supply number strings ..., details concatenation controlled sep collapse.str_c() can supply number strings ..., details concatenation controlled sep collapse.Generally, data arguments come first.\nDetail arguments go end, usually default values.\nspecify default value way call function named argument:default value almost always common value.\nexceptions rule safety.\nexample, makes sense na.rm default FALSE missing values important.\nEven though na.rm = TRUE usually put code, ’s bad idea silently ignore missing values default.call function, typically omit names data arguments, used commonly.\noverride default value detail argument, use full name:can refer argument unique prefix (e.g. mean(x, n = TRUE)), generally best avoided given possibilities confusion.Notice call function, place space around = function calls, always put space comma, (just like regular English).\nUsing whitespace makes easier skim function important components.","code":"\n# Compute confidence interval around mean using normal approximation\nmean_ci <- function(x, conf = 0.95) {\n  se <- sd(x) / sqrt(length(x))\n  alpha <- 1 - conf\n  mean(x) + se * qnorm(c(alpha / 2, 1 - alpha / 2))\n}\n\nx <- runif(100)\nmean_ci(x)\n#> [1] 0.4976111 0.6099594\nmean_ci(x, conf = 0.99)\n#> [1] 0.4799599 0.6276105\n# Good\nmean(1:10, na.rm = TRUE)\n\n# Bad\nmean(x = 1:10, , FALSE)\nmean(, TRUE, x = c(1:10, NA))\n# Good\naverage <- mean(feet / 12 + inches, na.rm = TRUE)\n\n# Bad\naverage<-mean(feet/12+inches,na.rm=TRUE)"},{"path":"functions.html","id":"choosing-names","chapter":"34 Functions","heading":"34.5.1 Choosing names","text":"names arguments also important.\nR doesn’t care, readers code (including future-!) .\nGenerally prefer longer, descriptive names, handful common, short names.\n’s worth memorising :x, y, z: vectors.w: vector weights.df: data frame., j: numeric indices (typically rows columns).n: length, number rows.p: number columns.Otherwise, consider matching names arguments existing R functions.\nexample, use na.rm determine missing values removed.","code":""},{"path":"functions.html","id":"checking-values","chapter":"34 Functions","heading":"34.5.2 Checking values","text":"start write functions, ’ll eventually get point don’t remember exactly function works.\npoint ’s easy call function invalid inputs.\navoid problem, ’s often useful make constraints explicit.\nexample, imagine ’ve written functions computing weighted summary statistics:happens x w length?case, R’s vector recycling rules, don’t get error.’s good practice check important preconditions, throw error (stop()), true:careful take far.\n’s tradeoff much time spend making function robust, versus long spend writing .\nexample, also added na.rm argument, probably wouldn’t check carefully:lot extra work little additional gain.\nuseful compromise built-stopifnot(): checks argument TRUE, produces generic error message .Note using stopifnot() assert true rather checking might wrong.","code":"\nwt_mean <- function(x, w) {\n  sum(x * w) / sum(w)\n}\nwt_var <- function(x, w) {\n  mu <- wt_mean(x, w)\n  sum(w * (x - mu) ^ 2) / sum(w)\n}\nwt_sd <- function(x, w) {\n  sqrt(wt_var(x, w))\n}\nwt_mean(1:6, 1:3)\n#> [1] 7.666667\nwt_mean <- function(x, w) {\n  if (length(x) != length(w)) {\n    stop(\"`x` and `w` must be the same length\", call. = FALSE)\n  }\n  sum(w * x) / sum(w)\n}\nwt_mean <- function(x, w, na.rm = FALSE) {\n  if (!is.logical(na.rm)) {\n    stop(\"`na.rm` must be logical\")\n  }\n  if (length(na.rm) != 1) {\n    stop(\"`na.rm` must be length 1\")\n  }\n  if (length(x) != length(w)) {\n    stop(\"`x` and `w` must be the same length\", call. = FALSE)\n  }\n  \n  if (na.rm) {\n    miss <- is.na(x) | is.na(w)\n    x <- x[!miss]\n    w <- w[!miss]\n  }\n  sum(w * x) / sum(w)\n}\nwt_mean <- function(x, w, na.rm = FALSE) {\n  stopifnot(is.logical(na.rm), length(na.rm) == 1)\n  stopifnot(length(x) == length(w))\n  \n  if (na.rm) {\n    miss <- is.na(x) | is.na(w)\n    x <- x[!miss]\n    w <- w[!miss]\n  }\n  sum(w * x) / sum(w)\n}\nwt_mean(1:6, 6:1, na.rm = \"foo\")\n#> Error in wt_mean(1:6, 6:1, na.rm = \"foo\"): is.logical(na.rm) is not TRUE"},{"path":"functions.html","id":"dot-dot-dot","chapter":"34 Functions","heading":"34.5.3 Dot-dot-dot (…)","text":"Many functions R take arbitrary number inputs:functions work?\nrely special argument: ... (pronounced dot-dot-dot).\nspecial argument captures number arguments aren’t otherwise matched.’s useful can send ... another function.\nuseful catch-function primarily wraps another function.\nexample, commonly create helper functions wrap around str_c():... lets forward arguments don’t want deal str_c().\n’s convenient technique.\ncome price: misspelled arguments raise error.\nmakes easy typos go unnoticed:just want capture values ..., use list(...).","code":"\nsum(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n#> [1] 55\nstringr::str_c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")\n#> [1] \"abcdef\"\ncommas <- function(...) stringr::str_c(..., collapse = \", \")\ncommas(letters[1:10])\n#> [1] \"a, b, c, d, e, f, g, h, i, j\"\n\nrule <- function(..., pad = \"-\") {\n  title <- paste0(...)\n  width <- getOption(\"width\") - nchar(title) - 5\n  cat(title, \" \", stringr::str_dup(pad, width), \"\\n\", sep = \"\")\n}\nrule(\"Important output\")\n#> Important output -----------------------------------------------------------\nx <- c(1, 2)\nsum(x, na.mr = TRUE)\n#> [1] 4"},{"path":"functions.html","id":"lazy-evaluation","chapter":"34 Functions","heading":"34.5.4 Lazy evaluation","text":"Arguments R lazily evaluated: ’re computed ’re needed.\nmeans ’re never used, ’re never called.\nimportant property R programming language, generally important ’re writing functions data analysis.\ncan read lazy evaluation http://adv-r..co.nz/Functions.html#lazy-evaluation.","code":""},{"path":"functions.html","id":"exercises-53","chapter":"34 Functions","heading":"34.5.5 Exercises","text":"commas(letters, collapse = \"-\") ?\n?commas(letters, collapse = \"-\") ?\n?’d nice supply multiple characters pad argument, e.g. rule(\"Title\", pad = \"-+\").\ndoesn’t currently work?\nfix ?’d nice supply multiple characters pad argument, e.g. rule(\"Title\", pad = \"-+\").\ndoesn’t currently work?\nfix ?trim argument mean() ?\nmight use ?trim argument mean() ?\nmight use ?default value method argument cor() c(\"pearson\", \"kendall\", \"spearman\").\nmean?\nvalue used default?default value method argument cor() c(\"pearson\", \"kendall\", \"spearman\").\nmean?\nvalue used default?","code":""},{"path":"functions.html","id":"return-values","chapter":"34 Functions","heading":"34.6 Return values","text":"Figuring function return usually straightforward: ’s created function first place!\ntwo things consider returning value:returning early make function easier read?returning early make function easier read?Can make function pipeable?Can make function pipeable?","code":""},{"path":"functions.html","id":"explicit-return-statements","chapter":"34 Functions","heading":"34.6.1 Explicit return statements","text":"value returned function usually last statement evaluates, can choose return early using return().\nthink ’s best save use return() signal can return early simpler solution.\ncommon reason inputs empty:Another reason statement one complex block one simple block.\nexample, might write statement like :first block long, time get else, ’ve forgotten condition.\nOne way rewrite use early return simple case:tends make code easier understand, don’t need quite much context understand .","code":"\ncomplicated_function <- function(x, y, z) {\n  if (length(x) == 0 || length(y) == 0) {\n    return(0)\n  }\n    \n  # Complicated code here\n}\nf <- function() {\n  if (x) {\n    # Do \n    # something\n    # that\n    # takes\n    # many\n    # lines\n    # to\n    # express\n  } else {\n    # return something short\n  }\n}\n\nf <- function() {\n  if (!x) {\n    return(something_short)\n  }\n\n  # Do \n  # something\n  # that\n  # takes\n  # many\n  # lines\n  # to\n  # express\n}"},{"path":"functions.html","id":"writing-pipeable-functions","chapter":"34 Functions","heading":"34.6.2 Writing pipeable functions","text":"want write pipeable functions, ’s important think return value.\nKnowing return value’s object type mean pipeline “just work”.\nexample, dplyr tidyr object type data frame.two basic types pipeable functions: transformations side-effects.\ntransformations, object passed function’s first argument modified object returned.\nside-effects, passed object transformed.\nInstead, function performs action object, like drawing plot saving file.\nSide-effects functions “invisibly” return first argument, ’re printed can still used pipeline.\nexample, simple function prints number missing values data frame:call interactively, invisible() means input df doesn’t get printed :’s still , ’s just printed default:can still use pipe:","code":"\nshow_missings <- function(df) {\n  n <- sum(is.na(df))\n  cat(\"Missing values: \", n, \"\\n\", sep = \"\")\n  \n  invisible(df)\n}\nshow_missings(mtcars)\n#> Missing values: 0\nx <- show_missings(mtcars) \n#> Missing values: 0\nclass(x)\n#> [1] \"data.frame\"\ndim(x)\n#> [1] 32 11\nmtcars %>% \n  show_missings() %>% \n  mutate(mpg = ifelse(mpg < 20, NA, mpg)) %>% \n  show_missings() \n#> Missing values: 0\n#> Missing values: 18"},{"path":"functions.html","id":"environment","chapter":"34 Functions","heading":"34.7 Environment","text":"last component function environment.\nsomething need understand deeply first start writing functions.\nHowever, ’s important know little bit environments crucial functions work.\nenvironment function controls R finds value associated name.\nexample, take function:many programming languages, error, y defined inside function.\nR, valid code R uses rules called lexical scoping find value associated name.\nSince y defined inside function, R look environment function defined:behaviour seems like recipe bugs, indeed avoid creating functions like deliberately, large doesn’t cause many problems (especially regularly restart R get clean slate).advantage behaviour language standpoint allows R consistent.\nEvery name looked using set rules.\nf() includes behaviour two things might expect: { +.\nallows devious things like:common phenomenon R.\nR places limits power.\ncan many things can’t programming languages.\ncan many things 99% time extremely ill-advised (like overriding addition works!).\npower flexibility makes tools like ggplot2 dplyr possible.\nLearning make best use flexibility beyond scope book, can read Advanced R.","code":"\nf <- function(x) {\n  x + y\n} \ny <- 100\nf(10)\n#> [1] 110\n\ny <- 1000\nf(10)\n#> [1] 1010\n`+` <- function(x, y) {\n  if (runif(1) < 0.1) {\n    sum(x, y)\n  } else {\n    sum(x, y) * 1.1\n  }\n}\ntable(replicate(1000, 1 + 2))\n#> \n#>   3 3.3 \n#> 100 900\nrm(`+`)"},{"path":"vectors.html","id":"vectors","chapter":"35 Vectors","heading":"35 Vectors","text":"","code":""},{"path":"vectors.html","id":"introduction-20","chapter":"35 Vectors","heading":"35.1 Introduction","text":"far book focussed tibbles packages work .\nstart write functions, dig deeper R, need learn vectors, objects underlie tibbles.\n’ve learned R traditional way, ’re probably already familiar vectors, R resources start vectors work way tibbles.\nthink ’s better start tibbles ’re immediately useful, work way underlying components.Vectors particularly important functions write work vectors.\npossible write functions work tibbles (like ggplot2, dplyr, tidyr), tools need write functions currently idiosyncratic immature.\nworking better approach, https://github.com/hadley/lazyeval, ready time publication book.\nEven complete, ’ll still need understand vectors, ’ll just make easier write user-friendly layer top.","code":""},{"path":"vectors.html","id":"prerequisites-17","chapter":"35 Vectors","heading":"35.1.1 Prerequisites","text":"focus chapter base R data structures, isn’t essential load packages.\n, however, use handful functions purrr package avoid inconsistencies base R.","code":"\nlibrary(tidyverse)"},{"path":"vectors.html","id":"vector-basics","chapter":"35 Vectors","heading":"35.2 Vector basics","text":"two types vectors:Atomic vectors, six types: logical, integer, double, character, complex, raw.\nInteger double vectors collectively known numeric vectors.Atomic vectors, six types: logical, integer, double, character, complex, raw.\nInteger double vectors collectively known numeric vectors.Lists, sometimes called recursive vectors lists can contain lists.Lists, sometimes called recursive vectors lists can contain lists.chief difference atomic vectors lists atomic vectors homogeneous, lists can heterogeneous.\n’s one related object: NULL.\nNULL often used represent absence vector (opposed NA used represent absence value vector).\nNULL typically behaves like vector length 0.\nFigure 35.1 summarises interrelationships.\nFigure 35.1: hierarchy R’s vector types\nEvery vector two key properties:type, can determine typeof().\n\ntypeof(letters)\n#> [1] \"character\"\ntypeof(1:10)\n#> [1] \"integer\"type, can determine typeof().length, can determine length().\n\nx <- list(\"\", \"b\", 1:10)\nlength(x)\n#> [1] 3Its length, can determine length().Vectors can also contain arbitrary additional metadata form attributes.\nattributes used create augmented vectors build additional behaviour.\nthree important types augmented vector:Factors built top integer vectors.Dates date-times built top numeric vectors.Data frames tibbles built top lists.chapter introduce important vectors simplest complicated.\n’ll start atomic vectors, build lists, finish augmented vectors.","code":"\ntypeof(letters)\n#> [1] \"character\"\ntypeof(1:10)\n#> [1] \"integer\"\nx <- list(\"a\", \"b\", 1:10)\nlength(x)\n#> [1] 3"},{"path":"vectors.html","id":"important-types-of-atomic-vector","chapter":"35 Vectors","heading":"35.3 Important types of atomic vector","text":"four important types atomic vector logical, integer, double, character.\nRaw complex rarely used data analysis, won’t discuss .","code":""},{"path":"vectors.html","id":"logical","chapter":"35 Vectors","heading":"35.3.1 Logical","text":"Logical vectors simplest type atomic vector can take three possible values: FALSE, TRUE, NA.\nLogical vectors usually constructed comparison operators, described [comparisons].\ncan also create hand c():","code":"\n1:10 %% 3 == 0\n#>  [1] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE\n\nc(TRUE, TRUE, FALSE, NA)\n#> [1]  TRUE  TRUE FALSE    NA"},{"path":"vectors.html","id":"numeric","chapter":"35 Vectors","heading":"35.3.2 Numeric","text":"Integer double vectors known collectively numeric vectors.\nR, numbers doubles default.\nmake integer, place L number:distinction integers doubles usually important, two important differences aware :Doubles approximations.\nDoubles represent floating point numbers can always precisely represented fixed amount memory.\nmeans consider doubles approximations.\nexample, square square root two?\n\nx <- sqrt(2) ^ 2\nx\n#> [1] 2\nx - 2\n#> [1] 4.440892e-16\nbehaviour common working floating point numbers: calculations include approximation error.\nInstead comparing floating point numbers using ==, use dplyr::near() allows numerical tolerance.Doubles approximations.\nDoubles represent floating point numbers can always precisely represented fixed amount memory.\nmeans consider doubles approximations.\nexample, square square root two?behaviour common working floating point numbers: calculations include approximation error.\nInstead comparing floating point numbers using ==, use dplyr::near() allows numerical tolerance.Integers one special value: NA, doubles four: NA, NaN, Inf -Inf.\nthree special values NaN, Inf -Inf can arise division:\n\nc(-1, 0, 1) / 0\n#> [1] -Inf  NaN  Inf\nAvoid using == check special values.\nInstead use helper functions .finite(), .infinite(), .nan():\n\n0\nInf\nNA\nNaN\n.finite()\nx\n\n\n\n.infinite()\n\nx\n\n\n.na()\n\n\nx\nx\n.nan()\n\n\n\nx\nIntegers one special value: NA, doubles four: NA, NaN, Inf -Inf.\nthree special values NaN, Inf -Inf can arise division:Avoid using == check special values.\nInstead use helper functions .finite(), .infinite(), .nan():","code":"\ntypeof(1)\n#> [1] \"double\"\ntypeof(1L)\n#> [1] \"integer\"\n1.5L\n#> [1] 1.5\nx <- sqrt(2) ^ 2\nx\n#> [1] 2\nx - 2\n#> [1] 4.440892e-16\nc(-1, 0, 1) / 0\n#> [1] -Inf  NaN  Inf"},{"path":"vectors.html","id":"character","chapter":"35 Vectors","heading":"35.3.3 Character","text":"Character vectors complex type atomic vector, element character vector string, string can contain arbitrary amount data.’ve already learned lot working strings strings.\nwanted mention one important feature underlying string implementation: R uses global string pool.\nmeans unique string stored memory , every use string points representation.\nreduces amount memory needed duplicated strings.\ncan see behaviour practice pryr::object_size():y doesn’t take 1,000x much memory x, element y just pointer string.\npointer 8 bytes, 1000 pointers 152 B string 8 * 1000 + 152 = 8.14 kB.","code":"\nx <- \"This is a reasonably long string.\"\npryr::object_size(x)\n#> 152 B\n\ny <- rep(x, 1000)\npryr::object_size(y)\n#> 8,144 B"},{"path":"vectors.html","id":"missing-values-vectors","chapter":"35 Vectors","heading":"35.3.4 Missing values","text":"Note type atomic vector missing value:Normally don’t need know different types can always use NA converted correct type using implicit coercion rules described next.\nHowever, functions strict inputs, ’s useful knowledge sitting back pocket can specific needed.","code":"\nNA            # logical\n#> [1] NA\nNA_integer_   # integer\n#> [1] NA\nNA_real_      # double\n#> [1] NA\nNA_character_ # character\n#> [1] NA"},{"path":"vectors.html","id":"exercises-54","chapter":"35 Vectors","heading":"35.3.5 Exercises","text":"Describe difference .finite(x) !.infinite(x).Describe difference .finite(x) !.infinite(x).Read source code dplyr::near() (Hint: see source code, drop ()).\nwork?Read source code dplyr::near() (Hint: see source code, drop ()).\nwork?logical vector can take 3 possible values.\nmany possible values can integer vector take?\nmany possible values can double take?\nUse google research.logical vector can take 3 possible values.\nmany possible values can integer vector take?\nmany possible values can double take?\nUse google research.Brainstorm least four functions allow convert double integer.\ndiffer?\nprecise.Brainstorm least four functions allow convert double integer.\ndiffer?\nprecise.functions readr package allow turn string logical, integer, double vector?functions readr package allow turn string logical, integer, double vector?","code":""},{"path":"vectors.html","id":"using-atomic-vectors","chapter":"35 Vectors","heading":"35.4 Using atomic vectors","text":"Now understand different types atomic vector, ’s useful review important tools working .\ninclude:convert one type another, happens automatically.convert one type another, happens automatically.tell object specific type vector.tell object specific type vector.happens work vectors different lengths.happens work vectors different lengths.name elements vector.name elements vector.pull elements interest.pull elements interest.","code":""},{"path":"vectors.html","id":"coercion","chapter":"35 Vectors","heading":"35.4.1 Coercion","text":"two ways convert, coerce, one type vector another:Explicit coercion happens call function like .logical(), .integer(), .double(), .character().\nWhenever find using explicit coercion, always check whether can make fix upstream, vector never wrong type first place.\nexample, may need tweak readr col_types specification.Explicit coercion happens call function like .logical(), .integer(), .double(), .character().\nWhenever find using explicit coercion, always check whether can make fix upstream, vector never wrong type first place.\nexample, may need tweak readr col_types specification.Implicit coercion happens use vector specific context expects certain type vector.\nexample, use logical vector numeric summary function, use double vector integer vector expected.Implicit coercion happens use vector specific context expects certain type vector.\nexample, use logical vector numeric summary function, use double vector integer vector expected.explicit coercion used relatively rarely, largely easy understand, ’ll focus implicit coercion .’ve already seen important type implicit coercion: using logical vector numeric context.\ncase TRUE converted 1 FALSE converted 0.\nmeans sum logical vector number trues, mean logical vector proportion trues:may see code (typically older) relies implicit coercion opposite direction, integer logical:case, 0 converted FALSE everything else converted TRUE.\nthink makes harder understand code, don’t recommend .\nInstead explicit: length(x) > 0.’s also important understand happens try create vector containing multiple types c(): complex type always wins.atomic vector can mix different types type property complete vector, individual elements.\nneed mix multiple types vector, use list, ’ll learn shortly.","code":"\nx <- sample(20, 100, replace = TRUE)\ny <- x > 10\nsum(y)  # how many are greater than 10?\n#> [1] 38\nmean(y) # what proportion are greater than 10?\n#> [1] 0.38\nif (length(x)) {\n  # do something\n}\ntypeof(c(TRUE, 1L))\n#> [1] \"integer\"\ntypeof(c(1L, 1.5))\n#> [1] \"double\"\ntypeof(c(1.5, \"a\"))\n#> [1] \"character\""},{"path":"vectors.html","id":"test-functions","chapter":"35 Vectors","heading":"35.4.2 Test functions","text":"Sometimes want different things based type vector.\nOne option use typeof().\nAnother use test function returns TRUE FALSE.\nBase R provides many functions like .vector() .atomic(), often return surprising results.\nInstead, ’s safer use is_* functions provided purrr, summarised table .","code":""},{"path":"vectors.html","id":"scalars-and-recycling-rules","chapter":"35 Vectors","heading":"35.4.3 Scalars and recycling rules","text":"well implicitly coercing types vectors compatible, R also implicitly coerce length vectors.\ncalled vector recycling, shorter vector repeated, recycled, length longer vector.generally useful mixing vectors “scalars”.\nput scalars quotes R doesn’t actually scalars: instead, single number vector length 1.\nscalars, built-functions vectorised, meaning operate vector numbers.\n’s , example, code works:R, basic mathematical operations work vectors.\nmeans never need perform explicit iteration performing simple mathematical computations.’s intuitive happen add two vectors length, vector “scalar”, happens add two vectors different lengths?, R expand shortest vector length longest, called recycling.\nsilent except length longer integer multiple length shorter:vector recycling can used create succinct, clever code, can also silently conceal problems.\nreason, vectorised functions tidyverse throw errors recycle anything scalar.\nwant recycle, ’ll need rep():","code":"\nsample(10) + 100\n#>  [1] 107 104 103 109 102 101 106 110 105 108\nrunif(10) > 0.5\n#>  [1] FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n1:10 + 1:2\n#>  [1]  2  4  4  6  6  8  8 10 10 12\n1:10 + 1:3\n#> Warning in 1:10 + 1:3: longer object length is not a multiple of shorter object\n#> length\n#>  [1]  2  4  6  5  7  9  8 10 12 11\ntibble(x = 1:4, y = 1:2)\n#> Error: Tibble columns must have compatible sizes.\n#> * Size 4: Existing data.\n#> * Size 2: Column `y`.\n#> <U+2029>[34mi<U+2029>[39m Only values of size one are recycled.NAtibble(x = 1:4, y = rep(1:2, 2))\n#> <U+2029>[90m# A tibble: 4 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     1NA#> <U+2029>[90m2<U+2029>[39m     2     2NA#> <U+2029>[90m3<U+2029>[39m     3     1NA#> <U+2029>[90m4<U+2029>[39m     4     2NAtibble(x = 1:4, y = rep(1:2, each = 2))\n#> <U+2029>[90m# A tibble: 4 x 2<U+2029>[39mNA#>       <U+2029>[1mx<U+2029>[22m     <U+2029>[1my<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<int><U+2029>[39m<U+2029>[23mNA#> <U+2029>[90m1<U+2029>[39m     1     1NA#> <U+2029>[90m2<U+2029>[39m     2     1NA#> <U+2029>[90m3<U+2029>[39m     3     2NA#> <U+2029>[90m4<U+2029>[39m     4     2NA"},{"path":"vectors.html","id":"naming-vectors","chapter":"35 Vectors","heading":"35.4.4 Naming vectors","text":"types vectors can named.\ncan name creation c():fact purrr::set_names():Named vectors useful subsetting, described next.","code":"\nc(x = 1, y = 2, z = 4)\n#> x y z \n#> 1 2 4\nset_names(1:3, c(\"a\", \"b\", \"c\"))\n#> a b c \n#> 1 2 3"},{"path":"vectors.html","id":"vector-subsetting","chapter":"35 Vectors","heading":"35.4.5 Subsetting","text":"far ’ve used dplyr::filter() filter rows tibble.\nfilter() works tibble, ’ll need new tool vectors: [.\n[ subsetting function, called like x[].\nfour types things can subset vector :numeric vector containing integers.\nintegers must either positive, negative, zero.\nSubsetting positive integers keeps elements positions:\n\nx <- c(\"one\", \"two\", \"three\", \"four\", \"five\")\nx[c(3, 2, 5)]\n#> [1] \"three\" \"two\"   \"five\"\nrepeating position, can actually make longer output input:\n\nx[c(1, 1, 5, 5, 5, 2)]\n#> [1] \"one\"  \"one\"  \"five\" \"five\" \"five\" \"two\"\nNegative values drop elements specified positions:\n\nx[c(-1, -3, -5)]\n#> [1] \"two\"  \"four\"\n’s error mix positive negative values:\n\nx[c(1, -1)]\n#> Error x[c(1, -1)]: 0's may mixed negative subscripts\nerror message mentions subsetting zero, returns values:\n\nx[0]\n#> character(0)\nuseful often, can helpful want create unusual data structures test functions .numeric vector containing integers.\nintegers must either positive, negative, zero.Subsetting positive integers keeps elements positions:repeating position, can actually make longer output input:Negative values drop elements specified positions:’s error mix positive negative values:error message mentions subsetting zero, returns values:useful often, can helpful want create unusual data structures test functions .Subsetting logical vector keeps values corresponding TRUE value.\noften useful conjunction comparison functions.\n\nx <- c(10, 3, NA, 5, 8, 1, NA)\n\n# non-missing values x\nx[!.na(x)]\n#> [1] 10  3  5  8  1\n\n# even (missing!) values x\nx[x %% 2 == 0]\n#> [1] 10 NA  8 NASubsetting logical vector keeps values corresponding TRUE value.\noften useful conjunction comparison functions.named vector, can subset character vector:\n\nx <- c(abc = 1, def = 2, xyz = 5)\nx[c(\"xyz\", \"def\")]\n#> xyz def \n#>   5   2\nLike positive integers, can also use character vector duplicate individual entries.named vector, can subset character vector:Like positive integers, can also use character vector duplicate individual entries.simplest type subsetting nothing, x[], returns complete x.\nuseful subsetting vectors, useful subsetting matrices (high dimensional structures) lets select rows columns, leaving index blank.\nexample, x 2d, x[1, ] selects first row columns, x[, -1] selects rows columns except first.simplest type subsetting nothing, x[], returns complete x.\nuseful subsetting vectors, useful subsetting matrices (high dimensional structures) lets select rows columns, leaving index blank.\nexample, x 2d, x[1, ] selects first row columns, x[, -1] selects rows columns except first.learn applications subsetting, reading “Subsetting” chapter Advanced R: http://adv-r..co.nz/Subsetting.html#applications.important variation [ called [[.\n[[ ever extracts single element, always drops names.\n’s good idea use whenever want make clear ’re extracting single item, loop.\ndistinction [ [[ important lists, ’ll see shortly.","code":"\nx <- c(\"one\", \"two\", \"three\", \"four\", \"five\")\nx[c(3, 2, 5)]\n#> [1] \"three\" \"two\"   \"five\"\nx[c(1, 1, 5, 5, 5, 2)]\n#> [1] \"one\"  \"one\"  \"five\" \"five\" \"five\" \"two\"\nx[c(-1, -3, -5)]\n#> [1] \"two\"  \"four\"\nx[c(1, -1)]\n#> Error in x[c(1, -1)]: only 0's may be mixed with negative subscripts\nx[0]\n#> character(0)\nx <- c(10, 3, NA, 5, 8, 1, NA)\n\n# All non-missing values of x\nx[!is.na(x)]\n#> [1] 10  3  5  8  1\n\n# All even (or missing!) values of x\nx[x %% 2 == 0]\n#> [1] 10 NA  8 NA\nx <- c(abc = 1, def = 2, xyz = 5)\nx[c(\"xyz\", \"def\")]\n#> xyz def \n#>   5   2"},{"path":"vectors.html","id":"exercises-55","chapter":"35 Vectors","heading":"35.4.6 Exercises","text":"mean(.na(x)) tell vector x?\nsum(!.finite(x))?mean(.na(x)) tell vector x?\nsum(!.finite(x))?Carefully read documentation .vector().\nactually test ?\n.atomic() agree definition atomic vectors ?Carefully read documentation .vector().\nactually test ?\n.atomic() agree definition atomic vectors ?Compare contrast setNames() purrr::set_names().Compare contrast setNames() purrr::set_names().Create functions take vector input return:\nlast value. use [ [[?\nelements even numbered positions.\nEvery element except last value.\neven numbers (missing values).\nCreate functions take vector input return:last value. use [ [[?elements even numbered positions.Every element except last value.even numbers (missing values).x[-(x > 0)] x[x <= 0]?x[-(x > 0)] x[x <= 0]?happens subset positive integer ’s bigger length vector?\nhappens subset name doesn’t exist?happens subset positive integer ’s bigger length vector?\nhappens subset name doesn’t exist?","code":""},{"path":"vectors.html","id":"lists","chapter":"35 Vectors","heading":"35.5 Recursive vectors (lists)","text":"Lists step complexity atomic vectors, lists can contain lists.\nmakes suitable representing hierarchical tree-like structures.\ncreate list list():useful tool working lists str() focusses structure, contents.Unlike atomic vectors, list() can contain mix objects:Lists can even contain lists!","code":"\nx <- list(1, 2, 3)\nx\n#> [[1]]\n#> [1] 1\n#> \n#> [[2]]\n#> [1] 2\n#> \n#> [[3]]\n#> [1] 3\nstr(x)\n#> List of 3\n#>  $ : num 1\n#>  $ : num 2\n#>  $ : num 3\n\nx_named <- list(a = 1, b = 2, c = 3)\nstr(x_named)\n#> List of 3\n#>  $ a: num 1\n#>  $ b: num 2\n#>  $ c: num 3\ny <- list(\"a\", 1L, 1.5, TRUE)\nstr(y)\n#> List of 4\n#>  $ : chr \"a\"\n#>  $ : int 1\n#>  $ : num 1.5\n#>  $ : logi TRUE\nz <- list(list(1, 2), list(3, 4))\nstr(z)\n#> List of 2\n#>  $ :List of 2\n#>   ..$ : num 1\n#>   ..$ : num 2\n#>  $ :List of 2\n#>   ..$ : num 3\n#>   ..$ : num 4"},{"path":"vectors.html","id":"visualising-lists","chapter":"35 Vectors","heading":"35.5.1 Visualising lists","text":"explain complicated list manipulation functions, ’s helpful visual representation lists.\nexample, take three lists:’ll draw follows:three principles:Lists rounded corners.\nAtomic vectors square corners.Lists rounded corners.\nAtomic vectors square corners.Children drawn inside parent, slightly darker background make easier see hierarchy.Children drawn inside parent, slightly darker background make easier see hierarchy.orientation children (.e. rows columns) isn’t important, ’ll pick row column orientation either save space illustrate important property example.orientation children (.e. rows columns) isn’t important, ’ll pick row column orientation either save space illustrate important property example.","code":"\nx1 <- list(c(1, 2), c(3, 4))\nx2 <- list(list(1, 2), list(3, 4))\nx3 <- list(1, list(2, list(3)))"},{"path":"vectors.html","id":"subsetting-1","chapter":"35 Vectors","heading":"35.5.2 Subsetting","text":"three ways subset list, ’ll illustrate list named :[ extracts sub-list.\nresult always list.\n\nstr([1:2])\n#> List 2\n#>  $ : int [1:3] 1 2 3\n#>  $ b: chr \"string\"\nstr([4])\n#> List 1\n#>  $ d:List 2\n#>   ..$ : num -1\n#>   ..$ : num -5\nLike vectors, can subset logical, integer, character vector.[ extracts sub-list.\nresult always list.Like vectors, can subset logical, integer, character vector.[[ extracts single component list.\nremoves level hierarchy list.\n\nstr([[1]])\n#>  int [1:3] 1 2 3\nstr([[4]])\n#> List 2\n#>  $ : num -1\n#>  $ : num -5[[ extracts single component list.\nremoves level hierarchy list.$ shorthand extracting named elements list.\nworks similarly [[ except don’t need use quotes.\n\n$\n#> [1] 1 2 3\n[[\"\"]]\n#> [1] 1 2 3$ shorthand extracting named elements list.\nworks similarly [[ except don’t need use quotes.distinction [ [[ really important lists, [[ drills list [ returns new, smaller list.\nCompare code output visual representation Figure 35.2.\nFigure 35.2: Subsetting list, visually.\n","code":"\na <- list(a = 1:3, b = \"a string\", c = pi, d = list(-1, -5))\nstr(a[1:2])\n#> List of 2\n#>  $ a: int [1:3] 1 2 3\n#>  $ b: chr \"a string\"\nstr(a[4])\n#> List of 1\n#>  $ d:List of 2\n#>   ..$ : num -1\n#>   ..$ : num -5\nstr(a[[1]])\n#>  int [1:3] 1 2 3\nstr(a[[4]])\n#> List of 2\n#>  $ : num -1\n#>  $ : num -5\na$a\n#> [1] 1 2 3\na[[\"a\"]]\n#> [1] 1 2 3"},{"path":"vectors.html","id":"lists-of-condiments","chapter":"35 Vectors","heading":"35.5.3 Lists of condiments","text":"difference [ [[ important, ’s easy get confused.\nhelp remember, let show unusual pepper shaker.pepper shaker list x, , x[1] pepper shaker containing single pepper packet:x[2] look , contain second packet.\nx[1:2] pepper shaker containing two pepper packets.x[[1]] :wanted get content pepper package, ’d need x[[1]][[1]]:","code":""},{"path":"vectors.html","id":"exercises-56","chapter":"35 Vectors","heading":"35.5.4 Exercises","text":"Draw following lists nested sets:\nlist(, b, list(c, d), list(e, f))\nlist(list(list(list(list(list())))))\nDraw following lists nested sets:list(, b, list(c, d), list(e, f))list(list(list(list(list(list())))))happens subset tibble ’re subsetting list?\nkey differences list tibble?happens subset tibble ’re subsetting list?\nkey differences list tibble?","code":""},{"path":"vectors.html","id":"attributes","chapter":"35 Vectors","heading":"35.6 Attributes","text":"vector can contain arbitrary additional metadata attributes.\ncan think attributes named list vectors can attached object.\ncan get set individual attribute values attr() see attributes().three important attributes used implement fundamental parts R:Names used name elements vector.Dimensions (dims, short) make vector behave like matrix array.Class used implement S3 object oriented system.’ve seen names , won’t cover dimensions don’t use matrices book.\nremains describe class, controls generic functions work.\nGeneric functions key object oriented programming R, make functions behave differently different classes input.\ndetailed discussion object oriented programming beyond scope book, can read Advanced R http://adv-r..co.nz/OO-essentials.html#s3.’s typical generic function looks like:call “UseMethod” means generic function, call specific method, function, based class first argument.\n(methods functions; functions methods).\ncan list methods generic methods():example, x character vector, .Date() call .Date.character(); ’s factor, ’ll call .Date.factor().can see specific implementation method getS3method():important S3 generic print(): controls object printed type name console.\nimportant generics subsetting functions [, [[, $.","code":"\nx <- 1:10\nattr(x, \"greeting\")\n#> NULL\nattr(x, \"greeting\") <- \"Hi!\"\nattr(x, \"farewell\") <- \"Bye!\"\nattributes(x)\n#> $greeting\n#> [1] \"Hi!\"\n#> \n#> $farewell\n#> [1] \"Bye!\"\nas.Date\n#> function (x, ...) \n#> UseMethod(\"as.Date\")\n#> <bytecode: 0x00000000146425a0>\n#> <environment: namespace:base>\nmethods(\"as.Date\")\n#> [1] as.Date.character   as.Date.default     as.Date.factor     \n#> [4] as.Date.numeric     as.Date.POSIXct     as.Date.POSIXlt    \n#> [7] as.Date.vctrs_sclr* as.Date.vctrs_vctr*\n#> see '?methods' for accessing help and source code\ngetS3method(\"as.Date\", \"default\")\n#> function (x, ...) \n#> {\n#>     if (inherits(x, \"Date\")) \n#>         x\n#>     else if (is.null(x)) \n#>         .Date(numeric())\n#>     else if (is.logical(x) && all(is.na(x))) \n#>         .Date(as.numeric(x))\n#>     else stop(gettextf(\"do not know how to convert '%s' to class %s\", \n#>         deparse1(substitute(x)), dQuote(\"Date\")), domain = NA)\n#> }\n#> <bytecode: 0x0000000013841ab0>\n#> <environment: namespace:base>\ngetS3method(\"as.Date\", \"numeric\")\n#> function (x, origin, ...) \n#> {\n#>     if (missing(origin)) {\n#>         if (!length(x)) \n#>             return(.Date(numeric()))\n#>         if (!any(is.finite(x))) \n#>             return(.Date(x))\n#>         stop(\"'origin' must be supplied\")\n#>     }\n#>     as.Date(origin, ...) + x\n#> }\n#> <bytecode: 0x000000002addb9c0>\n#> <environment: namespace:base>"},{"path":"vectors.html","id":"augmented-vectors","chapter":"35 Vectors","heading":"35.7 Augmented vectors","text":"Atomic vectors lists building blocks important vector types like factors dates.\ncall augmented vectors, vectors additional attributes, including class.\naugmented vectors class, behave differently atomic vector built.\nbook, make use four important augmented vectors:FactorsDatesDate-timesTibblesThese described .","code":""},{"path":"vectors.html","id":"factors-1","chapter":"35 Vectors","heading":"35.7.1 Factors","text":"Factors designed represent categorical data can take fixed set possible values.\nFactors built top integers, levels attribute:","code":"\nx <- factor(c(\"ab\", \"cd\", \"ab\"), levels = c(\"ab\", \"cd\", \"ef\"))\ntypeof(x)\n#> [1] \"integer\"\nattributes(x)\n#> $levels\n#> [1] \"ab\" \"cd\" \"ef\"\n#> \n#> $class\n#> [1] \"factor\""},{"path":"vectors.html","id":"dates-and-date-times","chapter":"35 Vectors","heading":"35.7.2 Dates and date-times","text":"Dates R numeric vectors represent number days since 1 January 1970.Date-times numeric vectors class POSIXct represent number seconds since 1 January 1970.\n(case wondering, “POSIXct” stands “Portable Operating System Interface”, calendar time.)tzone attribute optional.\ncontrols time printed, absolute time refers .another type date-times called POSIXlt.\nbuilt top named lists:POSIXlts rare inside tidyverse.\ncrop base R, needed extract specific components date, like year month.\nSince lubridate provides helpers instead, don’t need .\nPOSIXct’s always easier work , find POSIXlt, always convert regular date time lubridate::as_date_time().","code":"\nx <- as.Date(\"1971-01-01\")\nunclass(x)\n#> [1] 365\n\ntypeof(x)\n#> [1] \"double\"\nattributes(x)\n#> $class\n#> [1] \"Date\"\nx <- lubridate::ymd_hm(\"1970-01-01 01:00\")\nunclass(x)\n#> [1] 3600\n#> attr(,\"tzone\")\n#> [1] \"UTC\"\n\ntypeof(x)\n#> [1] \"double\"\nattributes(x)\n#> $class\n#> [1] \"POSIXct\" \"POSIXt\" \n#> \n#> $tzone\n#> [1] \"UTC\"\nattr(x, \"tzone\") <- \"US/Pacific\"\nx\n#> [1] \"1969-12-31 17:00:00 PST\"\n\nattr(x, \"tzone\") <- \"US/Eastern\"\nx\n#> [1] \"1969-12-31 20:00:00 EST\"\ny <- as.POSIXlt(x)\ntypeof(y)\n#> [1] \"list\"\nattributes(y)\n#> $names\n#>  [1] \"sec\"    \"min\"    \"hour\"   \"mday\"   \"mon\"    \"year\"   \"wday\"   \"yday\"  \n#>  [9] \"isdst\"  \"zone\"   \"gmtoff\"\n#> \n#> $class\n#> [1] \"POSIXlt\" \"POSIXt\" \n#> \n#> $tzone\n#> [1] \"US/Eastern\" \"EST\"        \"EDT\""},{"path":"vectors.html","id":"tibbles-1","chapter":"35 Vectors","heading":"35.7.3 Tibbles","text":"Tibbles augmented lists: class “tbl_df” + “tbl” + “data.frame”, names (column) row.names attributes:difference tibble list elements data frame must vectors length.\nfunctions work tibbles enforce constraint.Traditional data.frames similar structure:main difference class.\nclass tibble includes “data.frame” means tibbles inherit regular data frame behaviour default.","code":"\ntb <- tibble::tibble(x = 1:5, y = 5:1)\ntypeof(tb)\n#> [1] \"list\"\nattributes(tb)\n#> $names\n#> [1] \"x\" \"y\"\n#> \n#> $row.names\n#> [1] 1 2 3 4 5\n#> \n#> $class\n#> [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\ndf <- data.frame(x = 1:5, y = 5:1)\ntypeof(df)\n#> [1] \"list\"\nattributes(df)\n#> $names\n#> [1] \"x\" \"y\"\n#> \n#> $class\n#> [1] \"data.frame\"\n#> \n#> $row.names\n#> [1] 1 2 3 4 5"},{"path":"vectors.html","id":"exercises-57","chapter":"35 Vectors","heading":"35.7.4 Exercises","text":"hms::hms(3600) return?\nprint?\nprimitive type augmented vector built top ?\nattributes use?hms::hms(3600) return?\nprint?\nprimitive type augmented vector built top ?\nattributes use?Try make tibble columns different lengths.\nhappens?Try make tibble columns different lengths.\nhappens?Based definition , ok list column tibble?Based definition , ok list column tibble?","code":""},{"path":"iteration.html","id":"iteration","chapter":"36 Iteration","heading":"36 Iteration","text":"","code":""},{"path":"iteration.html","id":"introduction-21","chapter":"36 Iteration","heading":"36.1 Introduction","text":"Chapter 34, talked important reduce duplication code creating functions instead copying--pasting.\nReducing code duplication three main benefits:’s easier see intent code, eyes drawn ’s different, stays .’s easier see intent code, eyes drawn ’s different, stays .’s easier respond changes requirements.\nneeds change, need make changes one place, rather remembering change every place copied--pasted code.’s easier respond changes requirements.\nneeds change, need make changes one place, rather remembering change every place copied--pasted code.’re likely fewer bugs line code used places.’re likely fewer bugs line code used places.One tool reducing duplication functions, reduce duplication identifying repeated patterns code extract independent pieces can easily reused updated.\nAnother tool reducing duplication iteration, helps need thing multiple inputs: repeating operation different columns, different datasets.\nchapter ’ll learn two important iteration paradigms: imperative programming functional programming.\nimperative side tools like loops loops, great place start make iteration explicit, ’s obvious ’s happening.\nHowever, loops quite verbose, require quite bit bookkeeping code duplicated every loop.\nFunctional programming (FP) offers tools extract duplicated code, common loop pattern gets function.\nmaster vocabulary FP, can solve many common iteration problems less code, ease, fewer errors.","code":""},{"path":"iteration.html","id":"prerequisites-18","chapter":"36 Iteration","heading":"36.1.1 Prerequisites","text":"’ve mastered loops provided base R, ’ll learn powerful programming tools provided purrr, one tidyverse core packages.","code":"\nlibrary(tidyverse)"},{"path":"iteration.html","id":"for-loops","chapter":"36 Iteration","heading":"36.2 For loops","text":"Imagine simple tibble:want compute median column.\ncopy--paste:breaks rule thumb: never copy paste twice.\nInstead, use loop:Every loop three components:output: output <- vector(\"double\", length(x)).\nstart loop, must always allocate sufficient space output.\nimportant efficiency: grow loop iteration using c() (example), loop slow.\ngeneral way creating empty vector given length vector() function.\ntwo arguments: type vector (“logical”, “integer”, “double”, “character”, etc) length vector.output: output <- vector(\"double\", length(x)).\nstart loop, must always allocate sufficient space output.\nimportant efficiency: grow loop iteration using c() (example), loop slow.general way creating empty vector given length vector() function.\ntwo arguments: type vector (“logical”, “integer”, “double”, “character”, etc) length vector.sequence: seq_along(df).\ndetermines loop : run loop assign different value seq_along(df).\n’s useful think pronoun, like “”.\nmight seen seq_along() .\n’s safe version familiar 1:length(l), important difference: zero-length vector, seq_along() right thing:\n\ny <- vector(\"double\", 0)\nseq_along(y)\n#> integer(0)\n1:length(y)\n#> [1] 1 0\nprobably won’t create zero-length vector deliberately, ’s easy create accidentally.\nuse 1:length(x) instead seq_along(x), ’re likely get confusing error message.sequence: seq_along(df).\ndetermines loop : run loop assign different value seq_along(df).\n’s useful think pronoun, like “”.might seen seq_along() .\n’s safe version familiar 1:length(l), important difference: zero-length vector, seq_along() right thing:probably won’t create zero-length vector deliberately, ’s easy create accidentally.\nuse 1:length(x) instead seq_along(x), ’re likely get confusing error message.body: output[[]] <- median(df[[]]).\ncode work.\n’s run repeatedly, time different value .\nfirst iteration run output[[1]] <- median(df[[1]]), second run output[[2]] <- median(df[[2]]), .body: output[[]] <- median(df[[]]).\ncode work.\n’s run repeatedly, time different value .\nfirst iteration run output[[1]] <- median(df[[1]]), second run output[[2]] <- median(df[[2]]), .’s loop!\nNow good time practice creating basic (basic) loops using exercises .\n’ll move variations loop help solve problems crop practice.","code":"\ndf <- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\nmedian(df$a)\n#> [1] -0.2457625\nmedian(df$b)\n#> [1] -0.2873072\nmedian(df$c)\n#> [1] -0.05669771\nmedian(df$d)\n#> [1] 0.1442633\noutput <- vector(\"double\", ncol(df))  # 1. output\nfor (i in seq_along(df)) {            # 2. sequence\n  output[[i]] <- median(df[[i]])      # 3. body\n}\noutput\n#> [1] -0.24576245 -0.28730721 -0.05669771  0.14426335\ny <- vector(\"double\", 0)\nseq_along(y)\n#> integer(0)\n1:length(y)\n#> [1] 1 0"},{"path":"iteration.html","id":"exercises-58","chapter":"36 Iteration","heading":"36.2.1 Exercises","text":"Write loops :\nCompute mean every column mtcars.\nDetermine type column nycflights13::flights.\nCompute number unique values column palmerpenguins::penguins.\nGenerate 10 random normals distributions means -10, 0, 10, 100.\nThink output, sequence, body start writing loop.Write loops :Compute mean every column mtcars.Determine type column nycflights13::flights.Compute number unique values column palmerpenguins::penguins.Generate 10 random normals distributions means -10, 0, 10, 100.Think output, sequence, body start writing loop.Eliminate loop following examples taking advantage existing function works vectors:\n\n<- \"\"\n(x letters) {\n  <- stringr::str_c(, x)\n}\n\nx <- sample(100)\nsd <- 0\n(seq_along(x)) {\n  sd <- sd + (x[] - mean(x)) ^ 2\n}\nsd <- sqrt(sd / (length(x) - 1))\n\nx <- runif(100)\n<- vector(\"numeric\", length(x))\n[1] <- x[1]\n(2:length(x)) {\n  [] <- [- 1] + x[]\n}Eliminate loop following examples taking advantage existing function works vectors:Combine function writing loop skills:\nWrite loop prints() lyrics children’s song “Alice camel”.\nConvert nursery rhyme “ten bed” function. Generalise number people sleeping structure.\nConvert song “99 bottles beer wall” function. Generalise number vessel containing liquid surface.\nCombine function writing loop skills:Write loop prints() lyrics children’s song “Alice camel”.Convert nursery rhyme “ten bed” function. Generalise number people sleeping structure.Convert song “99 bottles beer wall” function. Generalise number vessel containing liquid surface.’s common see loops don’t preallocate output instead increase length vector step:\n\noutput <- vector(\"integer\", 0)\n(seq_along(x)) {\n  output <- c(output, lengths(x[[]]))\n}\noutput\naffect performance?\nDesign execute experiment.’s common see loops don’t preallocate output instead increase length vector step:affect performance?\nDesign execute experiment.","code":"\nout <- \"\"\nfor (x in letters) {\n  out <- stringr::str_c(out, x)\n}\n\nx <- sample(100)\nsd <- 0\nfor (i in seq_along(x)) {\n  sd <- sd + (x[i] - mean(x)) ^ 2\n}\nsd <- sqrt(sd / (length(x) - 1))\n\nx <- runif(100)\nout <- vector(\"numeric\", length(x))\nout[1] <- x[1]\nfor (i in 2:length(x)) {\n  out[i] <- out[i - 1] + x[i]\n}\noutput <- vector(\"integer\", 0)\nfor (i in seq_along(x)) {\n  output <- c(output, lengths(x[[i]]))\n}\noutput"},{"path":"iteration.html","id":"for-loop-variations","chapter":"36 Iteration","heading":"36.3 For loop variations","text":"basic loop belt, variations aware .\nvariations important regardless iteration, don’t forget ’ve mastered FP techniques ’ll learn next section.four variations basic theme loop:Modifying existing object, instead creating new object.Looping names values, instead indices.Handling outputs unknown length.Handling sequences unknown length.","code":""},{"path":"iteration.html","id":"modifying-an-existing-object","chapter":"36 Iteration","heading":"36.3.1 Modifying an existing object","text":"Sometimes want use loop modify existing object.\nexample, remember challenge Chapter 34 functions.\nwanted rescale every column data frame:solve loop think three components:Output: already output — ’s input!Output: already output — ’s input!Sequence: can think data frame list columns, can iterate column seq_along(df).Sequence: can think data frame list columns, can iterate column seq_along(df).Body: apply rescale01().Body: apply rescale01().gives us:Typically ’ll modifying list data frame sort loop, remember use [[, [.\nmight spotted used [[ loops: think ’s better use [[ even atomic vectors makes clear want work single element.","code":"\ndf <- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\nrescale01 <- function(x) {\n  rng <- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\ndf$a <- rescale01(df$a)\ndf$b <- rescale01(df$b)\ndf$c <- rescale01(df$c)\ndf$d <- rescale01(df$d)\nfor (i in seq_along(df)) {\n  df[[i]] <- rescale01(df[[i]])\n}"},{"path":"iteration.html","id":"looping-patterns","chapter":"36 Iteration","heading":"36.3.2 Looping patterns","text":"three basic ways loop vector.\nfar ’ve shown general: looping numeric indices (seq_along(xs)), extracting value x[[]].\ntwo forms:Loop elements: (x xs).\nuseful care side-effects, like plotting saving file, ’s difficult save output efficiently.Loop elements: (x xs).\nuseful care side-effects, like plotting saving file, ’s difficult save output efficiently.Loop names: (nm names(xs)).\ngives name, can use access value x[[nm]].\nuseful want use name plot title file name.\n’re creating named output, make sure name results vector like :\n\nresults <- vector(\"list\", length(x))\nnames(results) <- names(x)Loop names: (nm names(xs)).\ngives name, can use access value x[[nm]].\nuseful want use name plot title file name.\n’re creating named output, make sure name results vector like :Iteration numeric indices general form, given position can extract name value:","code":"\nresults <- vector(\"list\", length(x))\nnames(results) <- names(x)\nfor (i in seq_along(x)) {\n  name <- names(x)[[i]]\n  value <- x[[i]]\n}"},{"path":"iteration.html","id":"unknown-output-length","chapter":"36 Iteration","heading":"36.3.3 Unknown output length","text":"Sometimes might know long output .\nexample, imagine want simulate random vectors random lengths.\nmight tempted solve problem progressively growing vector:efficient iteration, R copy data previous iterations.\ntechnical terms get “quadratic” (\\(O(n^2)\\)) behaviour means loop three times many elements take nine (\\(3^2\\)) times long run.better solution save results list, combine single vector loop done:’ve used unlist() flatten list vectors single vector.\nstricter option use purrr::flatten_dbl() — throw error input isn’t list doubles.pattern occurs places :might generating long string.\nInstead paste()ing together iteration previous, save output character vector combine vector single string paste(output, collapse = \"\").might generating long string.\nInstead paste()ing together iteration previous, save output character vector combine vector single string paste(output, collapse = \"\").might generating big data frame.\nInstead sequentially rbind()ing iteration, save output list, use dplyr::bind_rows(output) combine output single data frame.might generating big data frame.\nInstead sequentially rbind()ing iteration, save output list, use dplyr::bind_rows(output) combine output single data frame.Watch pattern.\nWhenever see , switch complex result object, combine one step end.","code":"\nmeans <- c(0, 1, 2)\n\noutput <- double()\nfor (i in seq_along(means)) {\n  n <- sample(100, 1)\n  output <- c(output, rnorm(n, means[[i]]))\n}\nstr(output)\n#>  num [1:138] 0.912 0.205 2.584 -0.789 0.588 ...\nout <- vector(\"list\", length(means))\nfor (i in seq_along(means)) {\n  n <- sample(100, 1)\n  out[[i]] <- rnorm(n, means[[i]])\n}\nstr(out)\n#> List of 3\n#>  $ : num [1:76] -0.3389 -0.0756 0.0402 0.1243 -0.9984 ...\n#>  $ : num [1:17] -0.11 1.149 0.614 0.77 1.392 ...\n#>  $ : num [1:41] 1.88 2.46 2.62 1.82 1.88 ...\nstr(unlist(out))\n#>  num [1:134] -0.3389 -0.0756 0.0402 0.1243 -0.9984 ..."},{"path":"iteration.html","id":"unknown-sequence-length","chapter":"36 Iteration","heading":"36.3.4 Unknown sequence length","text":"Sometimes don’t even know long input sequence run .\ncommon simulations.\nexample, might want loop get three heads row.\ncan’t sort iteration loop.\nInstead, can use loop.\nloop simpler loop two components, condition body:loop also general loop, can rewrite loop loop, can’t rewrite every loop loop:’s use loop find many tries takes get three heads row:mention loops briefly, hardly ever use .\n’re often used simulation, outside scope book.\nHowever, good know exist ’re prepared problems number iterations known advance.","code":"\nwhile (condition) {\n  # body\n}\nfor (i in seq_along(x)) {\n  # body\n}\n\n# Equivalent to\ni <- 1\nwhile (i <= length(x)) {\n  # body\n  i <- i + 1 \n}\nflip <- function() sample(c(\"T\", \"H\"), 1)\n\nflips <- 0\nnheads <- 0\n\nwhile (nheads < 3) {\n  if (flip() == \"H\") {\n    nheads <- nheads + 1\n  } else {\n    nheads <- 0\n  }\n  flips <- flips + 1\n}\nflips\n#> [1] 21"},{"path":"iteration.html","id":"exercises-59","chapter":"36 Iteration","heading":"36.3.5 Exercises","text":"Imagine directory full CSV files want read .\npaths vector, files <- dir(\"data/\", pattern = \"\\\\.csv$\", full.names = TRUE), now want read one read_csv().\nWrite loop load single data frame.Imagine directory full CSV files want read .\npaths vector, files <- dir(\"data/\", pattern = \"\\\\.csv$\", full.names = TRUE), now want read one read_csv().\nWrite loop load single data frame.happens use (nm names(x)) x names?\nelements named?\nnames unique?happens use (nm names(x)) x names?\nelements named?\nnames unique?Write function prints mean numeric column data frame, along name.\nexample, show_mean(mpg) print:\n\nshow_mean(mpg)\n#> displ:   3.47\n#> year: 2004\n#> cyl:     5.89\n#> cty:    16.86\n(Extra challenge: function use make sure numbers lined nicely, even though variable names different lengths?)Write function prints mean numeric column data frame, along name.\nexample, show_mean(mpg) print:(Extra challenge: function use make sure numbers lined nicely, even though variable names different lengths?)code ?\nwork?\n\ntrans <- list( \n  disp = function(x) x * 0.0163871,\n  = function(x) {\n    factor(x, labels = c(\"auto\", \"manual\"))\n  }\n)\n(var names(trans)) {\n  mtcars[[var]] <- trans[[var]](mtcars[[var]])\n}code ?\nwork?","code":"\nshow_mean(mpg)\n#> displ:   3.47\n#> year: 2004\n#> cyl:     5.89\n#> cty:    16.86\ntrans <- list( \n  disp = function(x) x * 0.0163871,\n  am = function(x) {\n    factor(x, labels = c(\"auto\", \"manual\"))\n  }\n)\nfor (var in names(trans)) {\n  mtcars[[var]] <- trans[[var]](mtcars[[var]])\n}"},{"path":"iteration.html","id":"for-loops-vs.-functionals","chapter":"36 Iteration","heading":"36.4 For loops vs. functionals","text":"loops important R languages R functional programming language.\nmeans ’s possible wrap loops function, call function instead using loop directly.see important, consider () simple data frame:Imagine want compute mean every column.\nloop:realise ’re going want compute means every column pretty frequently, extract function:think ’d also helpful able compute median, standard deviation, copy paste col_mean() function replace mean() median() sd():Uh oh!\n’ve copied--pasted code twice, ’s time think generalise .\nNotice code -loop boilerplate ’s hard see one thing (mean(), median(), sd()) different functions.saw set functions like :Hopefully, ’d notice ’s lot duplication, extract additional argument:’ve reduced chance bugs (now 1/3 original code), made easy generalise new situations.can exactly thing col_mean(), col_median() col_sd() adding argument supplies function apply column:idea passing function another function extremely powerful idea, ’s one behaviours makes R functional programming language.\nmight take wrap head around idea, ’s worth investment.\nrest chapter, ’ll learn use purrr package, provides functions eliminate need many common loops.\napply family functions base R (apply(), lapply(), tapply(), etc) solve similar problem, purrr consistent thus easier learn.goal using purrr functions instead loops allow break common list manipulation challenges independent pieces:can solve problem single element list?\n’ve solved problem, purrr takes care generalising solution every element list.can solve problem single element list?\n’ve solved problem, purrr takes care generalising solution every element list.’re solving complex problem, can break bite-sized pieces allow advance one small step towards solution?\npurrr, get lots small pieces can compose together pipe.’re solving complex problem, can break bite-sized pieces allow advance one small step towards solution?\npurrr, get lots small pieces can compose together pipe.structure makes easier solve new problems.\nalso makes easier understand solutions old problems re-read old code.","code":"\ndf <- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\noutput <- vector(\"double\", length(df))\nfor (i in seq_along(df)) {\n  output[[i]] <- mean(df[[i]])\n}\noutput\n#> [1] -0.3260369  0.1356639  0.4291403 -0.2498034\ncol_mean <- function(df) {\n  output <- vector(\"double\", length(df))\n  for (i in seq_along(df)) {\n    output[i] <- mean(df[[i]])\n  }\n  output\n}\ncol_median <- function(df) {\n  output <- vector(\"double\", length(df))\n  for (i in seq_along(df)) {\n    output[i] <- median(df[[i]])\n  }\n  output\n}\ncol_sd <- function(df) {\n  output <- vector(\"double\", length(df))\n  for (i in seq_along(df)) {\n    output[i] <- sd(df[[i]])\n  }\n  output\n}\nf1 <- function(x) abs(x - mean(x)) ^ 1\nf2 <- function(x) abs(x - mean(x)) ^ 2\nf3 <- function(x) abs(x - mean(x)) ^ 3\nf <- function(x, i) abs(x - mean(x)) ^ i\ncol_summary <- function(df, fun) {\n  out <- vector(\"double\", length(df))\n  for (i in seq_along(df)) {\n    out[i] <- fun(df[[i]])\n  }\n  out\n}\ncol_summary(df, median)\n#> [1] -0.51850298  0.02779864  0.17295591 -0.61163819\ncol_summary(df, mean)\n#> [1] -0.3260369  0.1356639  0.4291403 -0.2498034"},{"path":"iteration.html","id":"exercises-60","chapter":"36 Iteration","heading":"36.4.1 Exercises","text":"Read documentation apply().\n2d case, two loops generalise?Read documentation apply().\n2d case, two loops generalise?Adapt col_summary() applies numeric columns might want start is_numeric() function returns logical vector TRUE corresponding numeric column.Adapt col_summary() applies numeric columns might want start is_numeric() function returns logical vector TRUE corresponding numeric column.","code":""},{"path":"iteration.html","id":"the-map-functions","chapter":"36 Iteration","heading":"36.5 The map functions","text":"pattern looping vector, something element saving results common purrr package provides family functions .\none function type output:map() makes list.map_lgl() makes logical vector.map_int() makes integer vector.map_dbl() makes double vector.map_chr() makes character vector.function takes vector input, applies function piece, returns new vector ’s length (names) input.\ntype vector determined suffix map function.master functions, ’ll find takes much less time solve iteration problems.\nnever feel bad using loop instead map function.\nmap functions step tower abstraction, can take long time get head around work.\nimportant thing solve problem ’re working , write concise elegant code (although ’s definitely something want strive towards!).people tell avoid loops slow.\n’re wrong!\n(Well least ’re rather date, loops haven’t slow many years.) chief benefits using functions like map() speed, clarity: make code easier write read.can use functions perform computations last loop.\nsummary functions returned doubles, need use map_dbl():Compared using loop, focus operation performed (.e. mean(), median(), sd()), bookkeeping required loop every element store output.\neven apparent use pipe:differences map_*() col_summary():purrr functions implemented C.\nmakes little faster expense readability.purrr functions implemented C.\nmakes little faster expense readability.second argument, .f, function apply, can formula, character vector, integer vector.\n’ll learn handy shortcuts next section.second argument, .f, function apply, can formula, character vector, integer vector.\n’ll learn handy shortcuts next section.map_*() uses … ([dot dot dot]) pass along additional arguments .f time ’s called:\n\nmap_dbl(df, mean, trim = 0.5)\n#>                     b           c           d \n#> -0.51850298  0.02779864  0.17295591 -0.61163819map_*() uses … ([dot dot dot]) pass along additional arguments .f time ’s called:map functions also preserve names:\n\nz <- list(x = 1:3, y = 4:5)\nmap_int(z, length)\n#> x y \n#> 3 2The map functions also preserve names:","code":"\nmap_dbl(df, mean)\n#>          a          b          c          d \n#> -0.3260369  0.1356639  0.4291403 -0.2498034\nmap_dbl(df, median)\n#>           a           b           c           d \n#> -0.51850298  0.02779864  0.17295591 -0.61163819\nmap_dbl(df, sd)\n#>         a         b         c         d \n#> 0.9214834 0.4848945 0.9816016 1.1563324\ndf %>% map_dbl(mean)\n#>          a          b          c          d \n#> -0.3260369  0.1356639  0.4291403 -0.2498034\ndf %>% map_dbl(median)\n#>           a           b           c           d \n#> -0.51850298  0.02779864  0.17295591 -0.61163819\ndf %>% map_dbl(sd)\n#>         a         b         c         d \n#> 0.9214834 0.4848945 0.9816016 1.1563324\nmap_dbl(df, mean, trim = 0.5)\n#>           a           b           c           d \n#> -0.51850298  0.02779864  0.17295591 -0.61163819\nz <- list(x = 1:3, y = 4:5)\nmap_int(z, length)\n#> x y \n#> 3 2"},{"path":"iteration.html","id":"shortcuts","chapter":"36 Iteration","heading":"36.5.1 Shortcuts","text":"shortcuts can use .f order save little typing.\nImagine want fit linear model group dataset.\nfollowing toy example splits mtcars dataset three pieces (one value cylinder) fits linear model piece:syntax creating anonymous function R quite verbose purrr provides convenient shortcut: one-sided formula.’ve used .x pronoun: refers current list element (way referred current index loop).\n.x one-sided formula corresponds argument anonymous function.’re looking many models, might want extract summary statistic like \\(R^2\\).\nneed first run summary() extract component called r.squared.\nusing shorthand anonymous functions:extracting named components common operation, purrr provides even shorter shortcut: can use string.can also use integer select elements position:","code":"\nmodels <- mtcars %>% \n  split(.$cyl) %>% \n  map(function(df) lm(mpg ~ wt, data = df))\nmodels <- mtcars %>% \n  split(.$cyl) %>% \n  map(~lm(mpg ~ wt, data = .x))\nmodels %>% \n  map(summary) %>% \n  map_dbl(~.x$r.squared)\n#>         4         6         8 \n#> 0.5086326 0.4645102 0.4229655\nmodels %>% \n  map(summary) %>% \n  map_dbl(\"r.squared\")\n#>         4         6         8 \n#> 0.5086326 0.4645102 0.4229655\nx <- list(list(1, 2, 3), list(4, 5, 6), list(7, 8, 9))\nx %>% map_dbl(2)\n#> [1] 2 5 8"},{"path":"iteration.html","id":"base-r","chapter":"36 Iteration","heading":"36.5.2 Base R","text":"’re familiar apply family functions base R, might noticed similarities purrr functions:lapply() basically identical map(), except map() consistent functions purrr, can use shortcuts .f.lapply() basically identical map(), except map() consistent functions purrr, can use shortcuts .f.Base sapply() wrapper around lapply() automatically simplifies output.\nuseful interactive work problematic function never know sort output ’ll get:\n\nx1 <- list(\n  c(0.27, 0.37, 0.57, 0.91, 0.20),\n  c(0.90, 0.94, 0.66, 0.63, 0.06), \n  c(0.21, 0.18, 0.69, 0.38, 0.77)\n)\nx2 <- list(\n  c(0.50, 0.72, 0.99, 0.38, 0.78), \n  c(0.93, 0.21, 0.65, 0.13, 0.27), \n  c(0.39, 0.01, 0.38, 0.87, 0.34)\n)\n\nthreshold <- function(x, cutoff = 0.8) x[x > cutoff]\nx1 %>% sapply(threshold) %>% str()\n#> List 3\n#>  $ : num 0.91\n#>  $ : num [1:2] 0.9 0.94\n#>  $ : num(0)\nx2 %>% sapply(threshold) %>% str()\n#>  num [1:3] 0.99 0.93 0.87Base sapply() wrapper around lapply() automatically simplifies output.\nuseful interactive work problematic function never know sort output ’ll get:vapply() safe alternative sapply() supply additional argument defines type.\nproblem vapply() ’s lot typing: vapply(df, .numeric, logical(1)) equivalent map_lgl(df, .numeric).\nOne advantage vapply() purrr’s map functions can also produce matrices — map functions ever produce vectors.vapply() safe alternative sapply() supply additional argument defines type.\nproblem vapply() ’s lot typing: vapply(df, .numeric, logical(1)) equivalent map_lgl(df, .numeric).\nOne advantage vapply() purrr’s map functions can also produce matrices — map functions ever produce vectors.focus purrr functions consistent names arguments, helpful shortcuts, future provide easy parallelism progress bars.","code":"\nx1 <- list(\n  c(0.27, 0.37, 0.57, 0.91, 0.20),\n  c(0.90, 0.94, 0.66, 0.63, 0.06), \n  c(0.21, 0.18, 0.69, 0.38, 0.77)\n)\nx2 <- list(\n  c(0.50, 0.72, 0.99, 0.38, 0.78), \n  c(0.93, 0.21, 0.65, 0.13, 0.27), \n  c(0.39, 0.01, 0.38, 0.87, 0.34)\n)\n\nthreshold <- function(x, cutoff = 0.8) x[x > cutoff]\nx1 %>% sapply(threshold) %>% str()\n#> List of 3\n#>  $ : num 0.91\n#>  $ : num [1:2] 0.9 0.94\n#>  $ : num(0)\nx2 %>% sapply(threshold) %>% str()\n#>  num [1:3] 0.99 0.93 0.87"},{"path":"iteration.html","id":"exercises-61","chapter":"36 Iteration","heading":"36.5.3 Exercises","text":"Write code uses one map functions :\nCompute mean every column mtcars.\nDetermine type column nycflights13::flights.\nCompute number unique values column palmerpenguins::penguins.\nGenerate 10 random normals distributions means -10, 0, 10, 100.\nWrite code uses one map functions :Compute mean every column mtcars.Determine type column nycflights13::flights.Compute number unique values column palmerpenguins::penguins.Generate 10 random normals distributions means -10, 0, 10, 100.can create single vector column data frame indicates whether ’s factor?can create single vector column data frame indicates whether ’s factor?happens use map functions vectors aren’t lists?\nmap(1:5, runif) ?\n?happens use map functions vectors aren’t lists?\nmap(1:5, runif) ?\n?map(-2:2, rnorm, n = 5) ?\n?\nmap_dbl(-2:2, rnorm, n = 5) ?\n?map(-2:2, rnorm, n = 5) ?\n?\nmap_dbl(-2:2, rnorm, n = 5) ?\n?Rewrite map(x, function(df) lm(mpg ~ wt, data = df)) eliminate anonymous function.Rewrite map(x, function(df) lm(mpg ~ wt, data = df)) eliminate anonymous function.","code":""},{"path":"iteration.html","id":"dealing-with-failure","chapter":"36 Iteration","heading":"36.6 Dealing with failure","text":"use map functions repeat many operations, chances much higher one operations fail.\nhappens, ’ll get error message, output.\nannoying: one failure prevent accessing successes?\nensure one bad apple doesn’t ruin whole barrel?section ’ll learn deal situation new function: safely().\nsafely() adverb: takes function (verb) returns modified version.\ncase, modified function never throw error.\nInstead, always returns list two elements:result original result.\nerror, NULL.result original result.\nerror, NULL.error error object.\noperation successful, NULL.error error object.\noperation successful, NULL.(might familiar try() function base R.\n’s similar, sometimes returns original result sometimes returns error object ’s difficult work .)Let’s illustrate simple example: log():function succeeds, result element contains result error element NULL.\nfunction fails, result element NULL error element contains error object.safely() designed work map:easier work two lists: one errors one output.\n’s easy get purrr::transpose():’s deal errors, typically ’ll either look values x y error, work values y ok:Purrr provides two useful adverbs:Like safely(), possibly() always succeeds.\n’s simpler safely(), give default value return error.\n\nx <- list(1, 10, \"\")\nx %>% map_dbl(possibly(log, NA_real_))\n#> [1] 0.000000 2.302585       NALike safely(), possibly() always succeeds.\n’s simpler safely(), give default value return error.quietly() performs similar role safely(), instead capturing errors, captures printed output, messages, warnings:\n\nx <- list(1, -1)\nx %>% map(quietly(log)) %>% str()\n#> List 2\n#>  $ :List 4\n#>   ..$ result  : num 0\n#>   ..$ output  : chr \"\"\n#>   ..$ warnings: chr(0) \n#>   ..$ messages: chr(0) \n#>  $ :List 4\n#>   ..$ result  : num NaN\n#>   ..$ output  : chr \"\"\n#>   ..$ warnings: chr \"NaNs produced\"\n#>   ..$ messages: chr(0)quietly() performs similar role safely(), instead capturing errors, captures printed output, messages, warnings:","code":"\nsafe_log <- safely(log)\nstr(safe_log(10))\n#> List of 2\n#>  $ result: num 2.3\n#>  $ error : NULL\nstr(safe_log(\"a\"))\n#> List of 2\n#>  $ result: NULL\n#>  $ error :List of 2\n#>   ..$ message: chr \"non-numeric argument to mathematical function\"\n#>   ..$ call   : language .Primitive(\"log\")(x, base)\n#>   ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\nx <- list(1, 10, \"a\")\ny <- x %>% map(safely(log))\nstr(y)\n#> List of 3\n#>  $ :List of 2\n#>   ..$ result: num 0\n#>   ..$ error : NULL\n#>  $ :List of 2\n#>   ..$ result: num 2.3\n#>   ..$ error : NULL\n#>  $ :List of 2\n#>   ..$ result: NULL\n#>   ..$ error :List of 2\n#>   .. ..$ message: chr \"non-numeric argument to mathematical function\"\n#>   .. ..$ call   : language .Primitive(\"log\")(x, base)\n#>   .. ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\ny <- y %>% transpose()\nstr(y)\n#> List of 2\n#>  $ result:List of 3\n#>   ..$ : num 0\n#>   ..$ : num 2.3\n#>   ..$ : NULL\n#>  $ error :List of 3\n#>   ..$ : NULL\n#>   ..$ : NULL\n#>   ..$ :List of 2\n#>   .. ..$ message: chr \"non-numeric argument to mathematical function\"\n#>   .. ..$ call   : language .Primitive(\"log\")(x, base)\n#>   .. ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\nis_ok <- y$error %>% map_lgl(is_null)\nx[!is_ok]\n#> [[1]]\n#> [1] \"a\"\ny$result[is_ok] %>% flatten_dbl()\n#> [1] 0.000000 2.302585\nx <- list(1, 10, \"a\")\nx %>% map_dbl(possibly(log, NA_real_))\n#> [1] 0.000000 2.302585       NA\nx <- list(1, -1)\nx %>% map(quietly(log)) %>% str()\n#> List of 2\n#>  $ :List of 4\n#>   ..$ result  : num 0\n#>   ..$ output  : chr \"\"\n#>   ..$ warnings: chr(0) \n#>   ..$ messages: chr(0) \n#>  $ :List of 4\n#>   ..$ result  : num NaN\n#>   ..$ output  : chr \"\"\n#>   ..$ warnings: chr \"NaNs produced\"\n#>   ..$ messages: chr(0)"},{"path":"iteration.html","id":"mapping-over-multiple-arguments","chapter":"36 Iteration","heading":"36.7 Mapping over multiple arguments","text":"far ’ve mapped along single input.\noften multiple related inputs need iterate along parallel.\n’s job map2() pmap() functions.\nexample, imagine want simulate random normals different means.\nknow map():also want vary standard deviation?\nOne way iterate indices index vectors means sds:obfuscates intent code.\nInstead use map2() iterates two vectors parallel:map2() generates series function calls:Note arguments vary call come function; arguments every call come .Like map(), map2() just wrapper around loop:also imagine map3(), map4(), map5(), map6() etc, get tedious quickly.\nInstead, purrr provides pmap() takes list arguments.\nmight use wanted vary mean, standard deviation, number samples:looks like:don’t name list’s elements, pmap() use positional matching calling function.\n’s little fragile, makes code harder read, ’s better name arguments:generates longer, safer, calls:Since arguments length, makes sense store data frame:soon code gets complicated, think data frame good approach ensures column name length columns.","code":"\nmu <- list(5, 10, -3)\nmu %>% \n  map(rnorm, n = 5) %>% \n  str()\n#> List of 3\n#>  $ : num [1:5] 5.63 7.1 4.39 3.37 4.99\n#>  $ : num [1:5] 9.34 9.33 9.52 11.32 10.64\n#>  $ : num [1:5] -2.49 -4.75 -2.11 -2.78 -2.42\nsigma <- list(1, 5, 10)\nseq_along(mu) %>% \n  map(~rnorm(5, mu[[.x]], sigma[[.x]])) %>% \n  str()\n#> List of 3\n#>  $ : num [1:5] 4.82 5.74 4 2.06 5.72\n#>  $ : num [1:5] 6.51 0.529 10.381 14.377 12.269\n#>  $ : num [1:5] -11.51 2.66 8.52 -10.56 -7.89\nmap2(mu, sigma, rnorm, n = 5) %>% str()\n#> List of 3\n#>  $ : num [1:5] 3.83 4.52 5.12 3.23 3.59\n#>  $ : num [1:5] 13.55 3.8 8.16 12.31 8.39\n#>  $ : num [1:5] -15.872 -13.3 12.141 0.469 14.794\nmap2 <- function(x, y, f, ...) {\n  out <- vector(\"list\", length(x))\n  for (i in seq_along(x)) {\n    out[[i]] <- f(x[[i]], y[[i]], ...)\n  }\n  out\n}\nn <- list(1, 3, 5)\nargs1 <- list(n, mu, sigma)\nargs1 %>%\n  pmap(rnorm) %>% \n  str()\n#> List of 3\n#>  $ : num 5.39\n#>  $ : num [1:3] 5.41 2.08 9.58\n#>  $ : num [1:5] -23.85 -2.96 -6.56 8.46 -5.21\nargs2 <- list(mean = mu, sd = sigma, n = n)\nargs2 %>% \n  pmap(rnorm) %>% \n  str()\nparams <- tribble(\n  ~mean, ~sd, ~n,\n    5,     1,  1,\n   10,     5,  3,\n   -3,    10,  5\n)\nparams %>% \n  pmap(rnorm)\n#> [[1]]\n#> [1] 6.018179\n#> \n#> [[2]]\n#> [1]  8.681404 18.292712  6.129566\n#> \n#> [[3]]\n#> [1] -12.239379  -5.755334  -8.933997  -4.222859   8.797842"},{"path":"iteration.html","id":"invoking-different-functions","chapter":"36 Iteration","heading":"36.7.1 Invoking different functions","text":"’s one step complexity - well varying arguments function might also vary function :handle case, can use invoke_map():first argument list functions character vector function names.\nsecond argument list lists giving arguments vary function.\nsubsequent arguments passed every function., can use tribble() make creating matching pairs little easier:","code":"\nf <- c(\"runif\", \"rnorm\", \"rpois\")\nparam <- list(\n  list(min = -1, max = 1), \n  list(sd = 5), \n  list(lambda = 10)\n)\ninvoke_map(f, param, n = 5) %>% str()\n#> List of 3\n#>  $ : num [1:5] 0.479 0.439 -0.471 0.348 -0.581\n#>  $ : num [1:5] 2.48 3.9 7.54 -9.12 3.94\n#>  $ : int [1:5] 6 11 5 8 9\nsim <- tribble(\n  ~f,      ~params,\n  \"runif\", list(min = -1, max = 1),\n  \"rnorm\", list(sd = 5),\n  \"rpois\", list(lambda = 10)\n)\nsim %>% \n  mutate(sim = invoke_map(f, params, n = 10))"},{"path":"iteration.html","id":"walk","chapter":"36 Iteration","heading":"36.8 Walk","text":"Walk alternative map use want call function side effects, rather return value.\ntypically want render output screen save files disk - important thing action, return value.\n’s simple example:walk() generally useful compared walk2() pwalk().\nexample, list plots vector file names, use pwalk() save file corresponding location disk:walk(), walk2() pwalk() invisibly return ., first argument.\nmakes suitable use middle pipelines.","code":"\nx <- list(1, \"a\", 3)\n\nx %>% \n  walk(print)\n#> [1] 1\n#> [1] \"a\"\n#> [1] 3\nlibrary(ggplot2)\nplots <- mtcars %>% \n  split(.$cyl) %>% \n  map(~ggplot(.x, aes(mpg, wt)) + geom_point())\npaths <- stringr::str_c(names(plots), \".pdf\")\n\npwalk(list(paths, plots), ggsave, path = tempdir())"},{"path":"iteration.html","id":"other-patterns-of-for-loops","chapter":"36 Iteration","heading":"36.9 Other patterns of for loops","text":"Purrr provides number functions abstract types loops.\n’ll use less frequently map functions, ’re useful know .\ngoal briefly illustrate function, hopefully come mind see similar problem future.\ncan go look documentation details.","code":""},{"path":"iteration.html","id":"predicate-functions","chapter":"36 Iteration","heading":"36.9.1 Predicate functions","text":"number functions work predicate functions return either single TRUE FALSE.keep() discard() keep elements input predicate TRUE FALSE respectively:() every() determine predicate true elements.detect() finds first element predicate true; detect_index() returns position.head_while() tail_while() take elements start end vector predicate true:","code":"\ngss_cat %>% \n  keep(is.factor) %>% \n  str()\n#> tibble [21,483 x 6] (S3: tbl_df/tbl/data.frame)\n#>  $ marital: Factor w/ 6 levels \"No answer\",\"Never married\",..: 2 4 5 2 4 6 2 4 6 6 ...\n#>  $ race   : Factor w/ 4 levels \"Other\",\"Black\",..: 3 3 3 3 3 3 3 3 3 3 ...\n#>  $ rincome: Factor w/ 16 levels \"No answer\",\"Don't know\",..: 8 8 16 16 16 5 4 9 4 4 ...\n#>  $ partyid: Factor w/ 10 levels \"No answer\",\"Don't know\",..: 6 5 7 6 9 10 5 8 9 4 ...\n#>  $ relig  : Factor w/ 16 levels \"No answer\",\"Don't know\",..: 15 15 15 6 12 15 5 15 15 15 ...\n#>  $ denom  : Factor w/ 30 levels \"No answer\",\"Don't know\",..: 25 23 3 30 30 25 30 15 4 25 ...\n\ngss_cat %>% \n  discard(is.factor) %>% \n  str()\n#> tibble [21,483 x 3] (S3: tbl_df/tbl/data.frame)\n#>  $ year   : int [1:21483] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n#>  $ age    : int [1:21483] 26 48 67 39 25 25 36 44 44 47 ...\n#>  $ tvhours: int [1:21483] 12 NA 2 4 1 NA 3 NA 0 3 ...\nx <- list(1:5, letters, list(10))\n\nx %>% \n  some(is_character)\n#> [1] TRUE\n\nx %>% \n  every(is_vector)\n#> [1] TRUE\nx <- sample(10)\nx\n#>  [1] 10  6  1  3  2  4  5  8  9  7\n\nx %>% \n  detect(~ .x > 5)\n#> [1] 10\n\nx %>% \n  detect_index(~ .x > 5)\n#> [1] 1\nx %>% \n  head_while(~ .x > 5)\n#> [1] 10  6\n\nx %>% \n  tail_while(~ .x > 5)\n#> [1] 8 9 7"},{"path":"iteration.html","id":"reduce-and-accumulate","chapter":"36 Iteration","heading":"36.9.2 Reduce and accumulate","text":"Sometimes complex list want reduce simple list repeatedly applying function reduces pair singleton.\nuseful want apply two-table dplyr verb multiple tables.\nexample, might list data frames, want reduce single data frame joining elements together:maybe list vectors, want find intersection:reduce() takes “binary” function (.e. function two primary inputs), applies repeatedly list single element left.accumulate() similar keeps interim results.\nuse implement cumulative sum:","code":"\ndfs <- list(\n  age = tibble(name = \"John\", age = 30),\n  sex = tibble(name = c(\"John\", \"Mary\"), sex = c(\"M\", \"F\")),\n  trt = tibble(name = \"Mary\", treatment = \"A\")\n)\n\ndfs %>% reduce(full_join)\n#> Joining, by = \"name\"\n#> Joining, by = \"name\"\n#> <U+2029>[90m# A tibble: 2 x 4<U+2029>[39mNA#>   <U+2029>[1mname<U+2029>[22m    <U+2029>[1mage<U+2029>[22m <U+2029>[1msex<U+2029>[22m   <U+2029>[1mtreatment<U+2029>[22mNA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<dbl><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m    NA#> <U+2029>[90m1<U+2029>[39m John     30 M     <U+2029>[31mNA<U+2029>[39m       NA#> <U+2029>[90m2<U+2029>[39m Mary     <U+2029>[31mNA<U+2029>[39m F     ANA\nvs <- list(\n  c(1, 3, 5, 6, 10),\n  c(1, 2, 3, 7, 8, 10),\n  c(1, 2, 3, 4, 8, 9, 10)\n)\n\nvs %>% reduce(intersect)\n#> [1]  1  3 10\nx <- sample(10)\nx\n#>  [1]  7  5 10  9  8  3  1  4  2  6\nx %>% accumulate(`+`)\n#>  [1]  7 12 22 31 39 42 43 47 49 55"},{"path":"iteration.html","id":"exercises-62","chapter":"36 Iteration","heading":"36.9.3 Exercises","text":"Implement version every() using loop.\nCompare purrr::every().\npurrr’s version version doesn’t?Implement version every() using loop.\nCompare purrr::every().\npurrr’s version version doesn’t?Create enhanced col_summary() applies summary function every numeric column data frame.Create enhanced col_summary() applies summary function every numeric column data frame.possible base R equivalent col_summary() :\n\ncol_sum3 <- function(df, f) {\n  is_num <- sapply(df, .numeric)\n  df_num <- df[, is_num]\n\n  sapply(df_num, f)\n}\nnumber bugs illustrated following inputs:\n\ndf <- tibble(\n  x = 1:3, \n  y = 3:1,\n  z = c(\"\", \"b\", \"c\")\n)\n# OK\ncol_sum3(df, mean)\n# problems: always return numeric vector\ncol_sum3(df[1:2], mean)\ncol_sum3(df[1], mean)\ncol_sum3(df[0], mean)\ncauses bugs?possible base R equivalent col_summary() :number bugs illustrated following inputs:causes bugs?","code":"\ncol_sum3 <- function(df, f) {\n  is_num <- sapply(df, is.numeric)\n  df_num <- df[, is_num]\n\n  sapply(df_num, f)\n}\ndf <- tibble(\n  x = 1:3, \n  y = 3:1,\n  z = c(\"a\", \"b\", \"c\")\n)\n# OK\ncol_sum3(df, mean)\n# Has problems: don't always return numeric vector\ncol_sum3(df[1:2], mean)\ncol_sum3(df[1], mean)\ncol_sum3(df[0], mean)"},{"path":"iteration.html","id":"case-study-1","chapter":"36 Iteration","heading":"36.10 Case study","text":"","code":""},{"path":"programming-with-strings.html","id":"programming-with-strings","chapter":"37 Programming with strings","heading":"37 Programming with strings","text":"reading work--progress second edition R Data Science. chapter currently currently dumping ground ideas, don’t recommend reading . can find polished first edition https://r4ds..co.nz.","code":"\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(tibble)"},{"path":"programming-with-strings.html","id":"str_c","chapter":"37 Programming with strings","heading":"37.0.1 str_c","text":"NULLs silently dropped.\nparticularly useful conjunction :","code":"\nname <- \"Hadley\"\ntime_of_day <- \"morning\"\nbirthday <- FALSE\n\nstr_c(\n  \"Good \", time_of_day, \" \", name,\n  if (birthday) \" and HAPPY BIRTHDAY\",\n  \".\"\n)\n#> [1] \"Good morning Hadley.\""},{"path":"programming-with-strings.html","id":"performance","chapter":"37 Programming with strings","heading":"37.1 Performance","text":"fixed(): matches exactly specified sequence bytes.\nignores special regular expressions operates low level.\nallows avoid complex escaping can much faster regular expressions.\nfollowing microbenchmark shows ’s 3x faster simple example.saw str_split() can use boundary() match boundaries.\ncan also use functions:","code":"\nmicrobenchmark::microbenchmark(\n  fixed = str_detect(sentences, fixed(\"the\")),\n  regex = str_detect(sentences, \"the\"),\n  times = 20\n)\n#> Unit: microseconds\n#>   expr   min     lq    mean  median     uq    max neval\n#>  fixed 194.8 263.70 448.350  348.65  440.8 2459.5    20\n#>  regex 527.8 761.45 946.625 1013.35 1106.4 1280.4    20\nx <- \"This is a sentence.\"\nstr_view_all(x, boundary(\"word\"))\n#> <U+2029>[36m<This><U+2029>[39m <U+2029>[36m<is><U+2029>[39m <U+2029>[36m<a><U+2029>[39m <U+2029>[36m<sentence><U+2029>[39m.NAstr_extract_all(x, boundary(\"word\"))\n#> [[1]]\n#> [1] \"This\"     \"is\"       \"a\"        \"sentence\""},{"path":"programming-with-strings.html","id":"section","chapter":"37 Programming with strings","heading":"37.1.1 ","text":"","code":""},{"path":"programming-with-strings.html","id":"extract","chapter":"37 Programming with strings","heading":"37.1.2 Extract","text":"use simplify = TRUE, str_extract_all() return matrix short matches expanded length longest:don’t talk matrices , useful elsewhere.","code":"\ncolours <- c(\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\")\ncolour_match <- str_c(colours, collapse = \"|\")\ncolour_match\n#> [1] \"red|orange|yellow|green|blue|purple\"\n\nmore <- sentences[str_count(sentences, colour_match) > 1]\nstr_extract_all(more, colour_match)\n#> [[1]]\n#> [1] \"blue\" \"red\" \n#> \n#> [[2]]\n#> [1] \"green\" \"red\"  \n#> \n#> [[3]]\n#> [1] \"orange\" \"red\"\n\nstr_extract_all(more, colour_match, simplify = TRUE)\n#>      [,1]     [,2] \n#> [1,] \"blue\"   \"red\"\n#> [2,] \"green\"  \"red\"\n#> [3,] \"orange\" \"red\"\n\nx <- c(\"a\", \"a b\", \"a b c\")\nstr_extract_all(x, \"[a-z]\", simplify = TRUE)\n#>      [,1] [,2] [,3]\n#> [1,] \"a\"  \"\"   \"\"  \n#> [2,] \"a\"  \"b\"  \"\"  \n#> [3,] \"a\"  \"b\"  \"c\""},{"path":"programming-with-strings.html","id":"exercises-63","chapter":"37 Programming with strings","heading":"37.1.3 Exercises","text":"Harvard sentences data, extract:\nfirst word sentence.\nwords ending ing.\nplurals.\nHarvard sentences data, extract:first word sentence.words ending ing.plurals.","code":""},{"path":"programming-with-strings.html","id":"grouped-matches","chapter":"37 Programming with strings","heading":"37.2 Grouped matches","text":"Earlier chapter talked use parentheses clarifying precedence backreferences matching.\ncan also use parentheses extract parts complex match.\nexample, imagine want extract nouns sentences.\nheuristic, ’ll look word comes “” “”.\nDefining “word” regular expression little tricky, use simple approximation: sequence least one character isn’t space.str_extract() gives us complete match; str_match() gives individual component.\nInstead character vector, returns matrix, one column complete match followed one column group:(Unsurprisingly, heuristic detecting nouns poor, also picks adjectives like smooth parked.)","code":"\nnoun <- \"(a|the) ([^ ]+)\"\n\nhas_noun <- sentences %>%\n  str_subset(noun) %>%\n  head(10)\nhas_noun %>% \n  str_extract(noun)\n#>  [1] \"the smooth\" \"the sheet\"  \"the depth\"  \"a chicken\"  \"the parked\"\n#>  [6] \"the sun\"    \"the huge\"   \"the ball\"   \"the woman\"  \"a helps\"\nhas_noun %>% \n  str_match(noun)\n#>       [,1]         [,2]  [,3]     \n#>  [1,] \"the smooth\" \"the\" \"smooth\" \n#>  [2,] \"the sheet\"  \"the\" \"sheet\"  \n#>  [3,] \"the depth\"  \"the\" \"depth\"  \n#>  [4,] \"a chicken\"  \"a\"   \"chicken\"\n#>  [5,] \"the parked\" \"the\" \"parked\" \n#>  [6,] \"the sun\"    \"the\" \"sun\"    \n#>  [7,] \"the huge\"   \"the\" \"huge\"   \n#>  [8,] \"the ball\"   \"the\" \"ball\"   \n#>  [9,] \"the woman\"  \"the\" \"woman\"  \n#> [10,] \"a helps\"    \"a\"   \"helps\""},{"path":"programming-with-strings.html","id":"spitting","chapter":"37 Programming with strings","heading":"37.3 Spitting","text":"Use str_split() split string pieces.\nexample, split sentences words:component might contain different number pieces, returns list.\n’re working length-1 vector, easiest thing just extract first element list:Otherwise, like stringr functions return list, can use simplify = TRUE return matrix:can also request maximum number pieces:Instead splitting strings patterns, can also split character, line, sentence word boundary()s:Show separate_rows() special case str_split() + summarise().","code":"\nsentences %>%\n  head(5) %>% \n  str_split(\" \")\n#> [[1]]\n#> [1] \"The\"     \"birch\"   \"canoe\"   \"slid\"    \"on\"      \"the\"     \"smooth\" \n#> [8] \"planks.\"\n#> \n#> [[2]]\n#> [1] \"Glue\"        \"the\"         \"sheet\"       \"to\"          \"the\"        \n#> [6] \"dark\"        \"blue\"        \"background.\"\n#> \n#> [[3]]\n#> [1] \"It's\"  \"easy\"  \"to\"    \"tell\"  \"the\"   \"depth\" \"of\"    \"a\"     \"well.\"\n#> \n#> [[4]]\n#> [1] \"These\"   \"days\"    \"a\"       \"chicken\" \"leg\"     \"is\"      \"a\"      \n#> [8] \"rare\"    \"dish.\"  \n#> \n#> [[5]]\n#> [1] \"Rice\"   \"is\"     \"often\"  \"served\" \"in\"     \"round\"  \"bowls.\"\n\"a|b|c|d\" %>% \n  str_split(\"\\\\|\") %>% \n  .[[1]]\n#> [1] \"a\" \"b\" \"c\" \"d\"\nsentences %>%\n  head(5) %>% \n  str_split(\" \", simplify = TRUE)\n#>      [,1]    [,2]    [,3]    [,4]      [,5]  [,6]    [,7]     [,8]         \n#> [1,] \"The\"   \"birch\" \"canoe\" \"slid\"    \"on\"  \"the\"   \"smooth\" \"planks.\"    \n#> [2,] \"Glue\"  \"the\"   \"sheet\" \"to\"      \"the\" \"dark\"  \"blue\"   \"background.\"\n#> [3,] \"It's\"  \"easy\"  \"to\"    \"tell\"    \"the\" \"depth\" \"of\"     \"a\"          \n#> [4,] \"These\" \"days\"  \"a\"     \"chicken\" \"leg\" \"is\"    \"a\"      \"rare\"       \n#> [5,] \"Rice\"  \"is\"    \"often\" \"served\"  \"in\"  \"round\" \"bowls.\" \"\"           \n#>      [,9]   \n#> [1,] \"\"     \n#> [2,] \"\"     \n#> [3,] \"well.\"\n#> [4,] \"dish.\"\n#> [5,] \"\"\nfields <- c(\"Name: Hadley\", \"Country: NZ\", \"Age: 35\")\nfields %>% str_split(\": \", n = 2, simplify = TRUE)\n#>      [,1]      [,2]    \n#> [1,] \"Name\"    \"Hadley\"\n#> [2,] \"Country\" \"NZ\"    \n#> [3,] \"Age\"     \"35\"\nx <- \"This is a sentence.  This is another sentence.\"\nstr_view_all(x, boundary(\"word\"))\n#> <U+2029>[36m<This><U+2029>[39m <U+2029>[36m<is><U+2029>[39m <U+2029>[36m<a><U+2029>[39m <U+2029>[36m<sentence><U+2029>[39m.  <U+2029>[36m<This><U+2029>[39m <U+2029>[36m<is><U+2029>[39m <U+2029>[36m<another><U+2029>[39m <U+2029>[36m<sentence><U+2029>[39m.NAstr_split(x, \" \")[[1]]\n#> [1] \"This\"      \"is\"        \"a\"         \"sentence.\" \"\"          \"This\"     \n#> [7] \"is\"        \"another\"   \"sentence.\"\nstr_split(x, boundary(\"word\"))[[1]]\n#> [1] \"This\"     \"is\"       \"a\"        \"sentence\" \"This\"     \"is\"       \"another\" \n#> [8] \"sentence\""},{"path":"programming-with-strings.html","id":"replace-with-function","chapter":"37 Programming with strings","heading":"37.4 Replace with function","text":"","code":""},{"path":"programming-with-strings.html","id":"locations","chapter":"37 Programming with strings","heading":"37.5 Locations","text":"str_locate() str_locate_all() give starting ending positions match.\nparticularly useful none functions exactly want.\ncan use str_locate() find matching pattern, str_sub() extract /modify .","code":""},{"path":"programming-with-strings.html","id":"stringi","chapter":"37 Programming with strings","heading":"37.6 stringi","text":"stringr built top stringi package.\nstringr useful ’re learning exposes minimal set functions, carefully picked handle common string manipulation functions.\nstringi, hand, designed comprehensive.\ncontains almost every function might ever need: stringi 256 functions stringr’s 53.find struggling something stringr, ’s worth taking look stringi.\npackages work similarly, able translate stringr knowledge natural way.\nmain difference prefix: str_ vs. stri_.","code":""},{"path":"programming-with-strings.html","id":"exercises-64","chapter":"37 Programming with strings","heading":"37.6.1 Exercises","text":"Find stringi functions :\nCount number words.\nFind duplicated strings.\nGenerate random text.\nFind stringi functions :Count number words.Find duplicated strings.Generate random text.control language stri_sort() uses sorting?control language stri_sort() uses sorting?","code":""},{"path":"programming-with-strings.html","id":"exercises-65","chapter":"37 Programming with strings","heading":"37.6.2 Exercises","text":"extra fill arguments separate()?\nExperiment various options following two toy datasets.\n\ntibble(x = c(\",b,c\", \"d,e,f,g\", \"h,,j\")) %>%\n  separate(x, c(\"one\", \"two\", \"three\"))\n\ntibble(x = c(\",b,c\", \"d,e\", \"f,g,\")) %>%\n  separate(x, c(\"one\", \"two\", \"three\"))extra fill arguments separate()?\nExperiment various options following two toy datasets.unite() separate() remove argument.\n?\nset FALSE?unite() separate() remove argument.\n?\nset FALSE?Compare contrast separate() extract().\nthree variations separation (position, separator, groups), one unite?Compare contrast separate() extract().\nthree variations separation (position, separator, groups), one unite?following example ’re using unite() create date column month day columns.\nachieve outcome using mutate() paste() instead unite?\n\nevents <- tribble(\n  ~month, ~day,\n  1     , 20,\n  1     , 21,\n  1     , 22\n)\n\nevents %>%\n  unite(\"date\", month:day, sep = \"-\", remove = FALSE)following example ’re using unite() create date column month day columns.\nachieve outcome using mutate() paste() instead unite?Write function turns (e.g.) vector c(\"\", \"b\", \"c\") string , b, c.\nThink carefully given vector length 0, 1, 2.Write function turns (e.g.) vector c(\"\", \"b\", \"c\") string , b, c.\nThink carefully given vector length 0, 1, 2.","code":"\ntibble(x = c(\"a,b,c\", \"d,e,f,g\", \"h,i,j\")) %>%\n  separate(x, c(\"one\", \"two\", \"three\"))\n\ntibble(x = c(\"a,b,c\", \"d,e\", \"f,g,i\")) %>%\n  separate(x, c(\"one\", \"two\", \"three\"))\nevents <- tribble(\n  ~month, ~day,\n  1     , 20,\n  1     , 21,\n  1     , 22\n)\n\nevents %>%\n  unite(\"date\", month:day, sep = \"-\", remove = FALSE)"},{"path":"communicate-intro.html","id":"communicate-intro","chapter":"38 Introduction","heading":"38 Introduction","text":"far, ’ve learned tools get data R, tidy form convenient analysis, understand data transformation, visualisation.\nHowever, doesn’t matter great analysis unless can explain others: need communicate results.Communication theme following four chapters:R Markdown, learn R Markdown, tool integrating prose, code, results.\ncan use R Markdown notebook mode analyst--analyst communication, report mode analyst--decision-maker communication.\nThanks power R Markdown formats, can even use document purposes.R Markdown, learn R Markdown, tool integrating prose, code, results.\ncan use R Markdown notebook mode analyst--analyst communication, report mode analyst--decision-maker communication.\nThanks power R Markdown formats, can even use document purposes.Graphics communication, learn take exploratory graphics turn expository graphics, graphics help newcomer analysis understand ’s going quickly easily possible.Graphics communication, learn take exploratory graphics turn expository graphics, graphics help newcomer analysis understand ’s going quickly easily possible.R Markdown formats, ’ll learn little many varieties outputs can produce using R Markdown, including dashboards, websites, books.R Markdown formats, ’ll learn little many varieties outputs can produce using R Markdown, including dashboards, websites, books.’ll finish R Markdown workflow, ’ll learn “analysis notebook” systematically record successes failures can learn .’ll finish R Markdown workflow, ’ll learn “analysis notebook” systematically record successes failures can learn .Unfortunately, chapters focus mostly technical mechanics communication, really hard problems communicating thoughts humans.\nHowever, lot great books communication, ’ll point end chapter.","code":""},{"path":"r-markdown.html","id":"r-markdown","chapter":"39 R Markdown","heading":"39 R Markdown","text":"","code":""},{"path":"r-markdown.html","id":"introduction-22","chapter":"39 R Markdown","heading":"39.1 Introduction","text":"R Markdown provides unified authoring framework data science, combining code, results, prose commentary.\nR Markdown documents fully reproducible support dozens output formats, like PDFs, Word files, slideshows, .R Markdown files designed used three ways:communicating decision makers, want focus conclusions, code behind analysis.communicating decision makers, want focus conclusions, code behind analysis.collaborating data scientists (including future !), interested conclusions, reached (.e. code).collaborating data scientists (including future !), interested conclusions, reached (.e. code).environment data science, modern day lab notebook can capture , also thinking.environment data science, modern day lab notebook can capture , also thinking.R Markdown integrates number R packages external tools.\nmeans help , --large, available ?.\nInstead, work chapter, use R Markdown future, keep resources close hand:R Markdown Cheat Sheet: Help > Cheatsheets > R Markdown Cheat Sheet,R Markdown Cheat Sheet: Help > Cheatsheets > R Markdown Cheat Sheet,R Markdown Reference Guide: Help > Cheatsheets > R Markdown Reference Guide.R Markdown Reference Guide: Help > Cheatsheets > R Markdown Reference Guide.cheatsheets also available https://rstudio.com/resources/cheatsheets/.","code":""},{"path":"r-markdown.html","id":"prerequisites-19","chapter":"39 R Markdown","heading":"39.1.1 Prerequisites","text":"need rmarkdown package, don’t need explicitly install load , RStudio automatically needed.","code":""},{"path":"r-markdown.html","id":"r-markdown-basics","chapter":"39 R Markdown","heading":"39.2 R Markdown basics","text":"R Markdown file, plain text file extension .Rmd:contains three important types content:(optional) YAML header surrounded ---s.Chunks R code surrounded ```.Text mixed simple text formatting like # heading _italics_.open .Rmd, get notebook interface code output interleaved.\ncan run code chunk clicking Run icon (looks like play button top chunk), pressing Cmd/Ctrl + Shift + Enter.\nRStudio executes code displays results inline code:produce complete report containing text, code, results, click “Knit” press Cmd/Ctrl + Shift + K.\ncan also programmatically rmarkdown::render(\"1-example.Rmd\").\ndisplay report viewer pane, create self-contained HTML file can share others.knit document, R Markdown sends .Rmd file knitr, http://yihui.name/knitr/, executes code chunks creates new markdown (.md) document includes code output.\nmarkdown file generated knitr processed pandoc, http://pandoc.org/, responsible creating finished file.\nadvantage two step workflow can create wide range output formats, ’ll learn R markdown formats.get started .Rmd file, select File > New File > R Markdown… menubar.\nRStudio launch wizard can use pre-populate file useful content reminds key features R Markdown work.following sections dive three components R Markdown document details: markdown text, code chunks, YAML header.","code":"---\ntitle: \"Diamond sizes\"\ndate: 2016-08-25\noutput: html_document\n---\n\n```{r setup, include = FALSE}\nlibrary(ggplot2)\nlibrary(dplyr)\n\nsmaller <- diamonds %>% \n  filter(carat <= 2.5)\n```\n\nWe have data about `r nrow(diamonds)` diamonds. Only \n`r nrow(diamonds) - nrow(smaller)` are larger than\n2.5 carats. The distribution of the remainder is shown\nbelow:\n\n```{r, echo = FALSE}\nsmaller %>% \n  ggplot(aes(carat)) + \n  geom_freqpoly(binwidth = 0.01)\n```"},{"path":"r-markdown.html","id":"exercises-66","chapter":"39 R Markdown","heading":"39.2.1 Exercises","text":"Create new notebook using File > New File > R Notebook.\nRead instructions.\nPractice running chunks.\nVerify can modify code, re-run , see modified output.Create new notebook using File > New File > R Notebook.\nRead instructions.\nPractice running chunks.\nVerify can modify code, re-run , see modified output.Create new R Markdown document File > New File > R Markdown… Knit clicking appropriate button.\nKnit using appropriate keyboard short cut.\nVerify can modify input see output update.Create new R Markdown document File > New File > R Markdown… Knit clicking appropriate button.\nKnit using appropriate keyboard short cut.\nVerify can modify input see output update.Compare contrast R notebook R markdown files created .\noutputs similar?\ndifferent?\ninputs similar?\ndifferent?\nhappens copy YAML header one ?Compare contrast R notebook R markdown files created .\noutputs similar?\ndifferent?\ninputs similar?\ndifferent?\nhappens copy YAML header one ?Create one new R Markdown document three built-formats: HTML, PDF Word.\nKnit three documents.\noutput differ?\ninput differ?\n(may need install LaTeX order build PDF output — RStudio prompt necessary.)Create one new R Markdown document three built-formats: HTML, PDF Word.\nKnit three documents.\noutput differ?\ninput differ?\n(may need install LaTeX order build PDF output — RStudio prompt necessary.)","code":""},{"path":"r-markdown.html","id":"text-formatting-with-markdown","chapter":"39 R Markdown","heading":"39.3 Text formatting with Markdown","text":"Prose .Rmd files written Markdown, lightweight set conventions formatting plain text files.\nMarkdown designed easy read easy write.\nalso easy learn.\nguide shows use Pandoc’s Markdown, slightly extended version Markdown R Markdown understands.best way learn simply try .\ntake days, soon become second nature, won’t need think .\nforget, can get handy reference sheet Help > Markdown Quick Reference.","code":"Text formatting \n------------------------------------------------------------\n\n*italic*  or _italic_\n**bold**   __bold__\n`code`\nsuperscript^2^ and subscript~2~\n\nHeadings\n------------------------------------------------------------\n\n# 1st Level Header\n\n## 2nd Level Header\n\n### 3rd Level Header\n\nLists\n------------------------------------------------------------\n\n*   Bulleted list item 1\n\n*   Item 2\n\n    * Item 2a\n\n    * Item 2b\n\n1.  Numbered list item 1\n\n1.  Item 2. The numbers are incremented automatically in the output.\n\nLinks and images\n------------------------------------------------------------\n\n<http://example.com>\n\n[linked phrase](http://example.com)\n\n![optional caption text](path/to/img.png)\n\nTables \n------------------------------------------------------------\n\nFirst Header  | Second Header\n------------- | -------------\nContent Cell  | Content Cell\nContent Cell  | Content Cell"},{"path":"r-markdown.html","id":"exercises-67","chapter":"39 R Markdown","heading":"39.3.1 Exercises","text":"Practice ’ve learned creating brief CV.\ntitle name, include headings (least) education employment.\nsections include bulleted list jobs/degrees.\nHighlight year bold.Practice ’ve learned creating brief CV.\ntitle name, include headings (least) education employment.\nsections include bulleted list jobs/degrees.\nHighlight year bold.Using R Markdown quick reference, figure :\nAdd footnote.\nAdd horizontal rule.\nAdd block quote.\nUsing R Markdown quick reference, figure :Add footnote.Add horizontal rule.Add block quote.Copy paste contents diamond-sizes.Rmd https://github.com/hadley/r4ds/tree/master/rmarkdown local R markdown document.\nCheck can run , add text frequency polygon describes striking features.Copy paste contents diamond-sizes.Rmd https://github.com/hadley/r4ds/tree/master/rmarkdown local R markdown document.\nCheck can run , add text frequency polygon describes striking features.","code":""},{"path":"r-markdown.html","id":"code-chunks","chapter":"39 R Markdown","heading":"39.4 Code chunks","text":"run code inside R Markdown document, need insert chunk.\nthree ways :keyboard shortcut Cmd/Ctrl + Alt + IThe keyboard shortcut Cmd/Ctrl + Alt + IThe “Insert” button icon editor toolbar.“Insert” button icon editor toolbar.manually typing chunk delimiters ```{r} ```.manually typing chunk delimiters ```{r} ```.Obviously, ’d recommend learn keyboard shortcut.\nsave lot time long run!can continue run code using keyboard shortcut now (hope!) know love: Cmd/Ctrl + Enter.\nHowever, chunks get new keyboard shortcut: Cmd/Ctrl + Shift + Enter, runs code chunk.\nThink chunk like function.\nchunk relatively self-contained, focussed around single task.following sections describe chunk header consists ```{r, followed optional chunk name, followed comma separated options, followed }.\nNext comes R code chunk end indicated final ```.","code":""},{"path":"r-markdown.html","id":"chunk-name","chapter":"39 R Markdown","heading":"39.4.1 Chunk name","text":"Chunks can given optional name: ```{r -name}.\nthree advantages:can easily navigate specific chunks using drop-code navigator bottom-left script editor:\ncan easily navigate specific chunks using drop-code navigator bottom-left script editor:Graphics produced chunks useful names make easier use elsewhere.\nimportant options.Graphics produced chunks useful names make easier use elsewhere.\nimportant options.can set networks cached chunks avoid re-performing expensive computations every run.\n.can set networks cached chunks avoid re-performing expensive computations every run.\n.one chunk name imbues special behaviour: setup.\n’re notebook mode, chunk named setup run automatically , code run.","code":""},{"path":"r-markdown.html","id":"chunk-options","chapter":"39 R Markdown","heading":"39.4.2 Chunk options","text":"Chunk output can customised options, arguments supplied chunk header.\nKnitr provides almost 60 options can use customize code chunks.\n’ll cover important chunk options ’ll use frequently.\ncan see full list http://yihui.name/knitr/options/.important set options controls code block executed results inserted finished report:eval = FALSE prevents code evaluated.\n(obviously code run, results generated).\nuseful displaying example code, disabling large block code without commenting line.eval = FALSE prevents code evaluated.\n(obviously code run, results generated).\nuseful displaying example code, disabling large block code without commenting line.include = FALSE runs code, doesn’t show code results final document.\nUse setup code don’t want cluttering report.include = FALSE runs code, doesn’t show code results final document.\nUse setup code don’t want cluttering report.echo = FALSE prevents code, results appearing finished file.\nUse writing reports aimed people don’t want see underlying R code.echo = FALSE prevents code, results appearing finished file.\nUse writing reports aimed people don’t want see underlying R code.message = FALSE warning = FALSE prevents messages warnings appearing finished file.message = FALSE warning = FALSE prevents messages warnings appearing finished file.results = 'hide' hides printed output; fig.show = 'hide' hides plots.results = 'hide' hides printed output; fig.show = 'hide' hides plots.error = TRUE causes render continue even code returns error.\nrarely something ’ll want include final version report, can useful need debug exactly going inside .Rmd.\n’s also useful ’re teaching R want deliberately include error.\ndefault, error = FALSE causes knitting fail single error document.error = TRUE causes render continue even code returns error.\nrarely something ’ll want include final version report, can useful need debug exactly going inside .Rmd.\n’s also useful ’re teaching R want deliberately include error.\ndefault, error = FALSE causes knitting fail single error document.following table summarises types output option suppresses:","code":""},{"path":"r-markdown.html","id":"table","chapter":"39 R Markdown","heading":"39.4.3 Table","text":"default, R Markdown prints data frames matrices ’d see console:prefer data displayed additional formatting can use knitr::kable function.\ncode generates Table 39.1.Table 39.1: knitr kable.Read documentation ?knitr::kable see ways can customise table.\neven deeper customisation, consider xtable, stargazer, pander, tables, ascii packages.\nprovides set tools returning formatted tables R code.also rich set options controlling figures embedded.\n’ll learn saving plots.","code":"\nmtcars[1:5, ]\n#>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nknitr::kable(\n  mtcars[1:5, ], \n  caption = \"A knitr kable.\"\n)"},{"path":"r-markdown.html","id":"caching","chapter":"39 R Markdown","heading":"39.4.4 Caching","text":"Normally, knit document starts completely clean slate.\ngreat reproducibility, ensures ’ve captured every important computation code.\nHowever, can painful computations take long time.\nsolution cache = TRUE.\nset, save output chunk specially named file disk.\nsubsequent runs, knitr check see code changed, hasn’t, reuse cached results.caching system must used care, default based code , dependencies.\nexample, processed_data chunk depends raw_data chunk:Caching processed_data chunk means get re-run dplyr pipeline changed, won’t get rerun read_csv() call changes.\ncan avoid problem dependson chunk option:dependson contain character vector every chunk cached chunk depends .\nKnitr update results cached chunk whenever detects one dependencies changed.Note chunks won’t update a_very_large_file.csv changes, knitr caching tracks changes within .Rmd file.\nwant also track changes file can use cache.extra option.\narbitrary R expression invalidate cache whenever changes.\ngood function use file.info(): returns bunch information file including last modified.\ncan write:caching strategies get progressively complicated, ’s good idea regularly clear caches knitr::clean_cache().’ve used advice David Robinson name chunks: chunk named primary object creates.\nmakes easier understand dependson specification.","code":"```{r raw_data}\nrawdata <- readr::read_csv(\"a_very_large_file.csv\")\n```\n\n```{r processed_data, cache = TRUE}\nprocessed_data <- rawdata %>% \n  filter(!is.na(import_var)) %>% \n  mutate(new_variable = complicated_transformation(x, y, z))\n``````{r processed_data, cache = TRUE, dependson = \"raw_data\"}\nprocessed_data <- rawdata %>% \n  filter(!is.na(import_var)) %>% \n  mutate(new_variable = complicated_transformation(x, y, z))\n``````{r raw_data, cache.extra = file.info(\"a_very_large_file.csv\")}\nrawdata <- readr::read_csv(\"a_very_large_file.csv\")\n```"},{"path":"r-markdown.html","id":"global-options","chapter":"39 R Markdown","heading":"39.4.5 Global options","text":"work knitr, discover default chunk options don’t fit needs want change .\ncan calling knitr::opts_chunk$set() code chunk.\nexample, writing books tutorials set:uses preferred comment formatting, ensures code output kept closely entwined.\nhand, preparing report, might set:hide code default, showing chunks deliberately choose show (echo = TRUE).\nmight consider setting message = FALSE warning = FALSE, make harder debug problems wouldn’t see messages final document.","code":"\nknitr::opts_chunk$set(\n  comment = \"#>\",\n  collapse = TRUE\n)\nknitr::opts_chunk$set(\n  echo = FALSE\n)"},{"path":"r-markdown.html","id":"inline-code","chapter":"39 R Markdown","heading":"39.4.6 Inline code","text":"one way embed R code R Markdown document: directly text, : `r `.\ncan useful mention properties data text.\nexample, example document used start chapter :data `r nrow(diamonds)` diamonds.\n`r nrow(diamonds) - nrow(smaller)` larger 2.5 carats.\ndistribution remainder shown :report knit, results computations inserted text:data 53940 diamonds.\n126 larger 2.5 carats.\ndistribution remainder shown :inserting numbers text, format() friend.\nallows set number digits don’t print ridiculous degree accuracy, big.mark make numbers easier read.\n’ll often combine helper function:","code":"\ncomma <- function(x) format(x, digits = 2, big.mark = \",\")\ncomma(3452345)\n#> [1] \"3,452,345\"\ncomma(.12358124331)\n#> [1] \"0.12\""},{"path":"r-markdown.html","id":"exercises-68","chapter":"39 R Markdown","heading":"39.4.7 Exercises","text":"Add section explores diamond sizes vary cut, colour, clarity.\nAssume ’re writing report someone doesn’t know R, instead setting echo = FALSE chunk, set global option.Add section explores diamond sizes vary cut, colour, clarity.\nAssume ’re writing report someone doesn’t know R, instead setting echo = FALSE chunk, set global option.Download diamond-sizes.Rmd https://github.com/hadley/r4ds/tree/master/rmarkdown.\nAdd section describes largest 20 diamonds, including table displays important attributes.Download diamond-sizes.Rmd https://github.com/hadley/r4ds/tree/master/rmarkdown.\nAdd section describes largest 20 diamonds, including table displays important attributes.Modify diamonds-sizes.Rmd use comma() produce nicely formatted output.\nAlso include percentage diamonds larger 2.5 carats.Modify diamonds-sizes.Rmd use comma() produce nicely formatted output.\nAlso include percentage diamonds larger 2.5 carats.Set network chunks d depends c b, b c depend .\nchunk print lubridate::now(), set cache = TRUE, verify understanding caching.Set network chunks d depends c b, b c depend .\nchunk print lubridate::now(), set cache = TRUE, verify understanding caching.","code":""},{"path":"r-markdown.html","id":"troubleshooting","chapter":"39 R Markdown","heading":"39.5 Troubleshooting","text":"Troubleshooting R Markdown documents can challenging longer interactive R environment, need learn new tricks.\nfirst thing always try recreate problem interactive session.\nRestart R, “Run chunks” (either Code menu, Run region), keyboard shortcut Ctrl + Alt + R.\n’re lucky, recreate problem, can figure ’s going interactively.doesn’t help, must something different interactive environment R markdown environment.\n’re going need systematically explore options.\ncommon difference working directory: working directory R Markdown directory lives.\nCheck working directory expect including getwd() chunk.Next, brainstorm things might cause bug.\n’ll need systematically check ’re R session R markdown session.\neasiest way set error = TRUE chunk causing problem, use print() str() check settings expect.","code":""},{"path":"r-markdown.html","id":"yaml-header","chapter":"39 R Markdown","heading":"39.6 YAML header","text":"can control many “whole document” settings tweaking parameters YAML header.\nmight wonder YAML stands : ’s “yet another markup language”, designed representing hierarchical data way ’s easy humans read write.\nR Markdown uses control many details output.\n’ll discuss two: document parameters bibliographies.","code":""},{"path":"r-markdown.html","id":"parameters","chapter":"39 R Markdown","heading":"39.6.1 Parameters","text":"R Markdown documents can include one parameters whose values can set render report.\nParameters useful want re-render report distinct values various key inputs.\nexample, might producing sales reports per branch, exam results student, demographic summaries country.\ndeclare one parameters, use params field.example uses my_class parameter determine class cars display:can see, parameters available within code chunks read-list named params.can write atomic vectors directly YAML header.\ncan also run arbitrary R expressions prefacing parameter value !r.\ngood way specify date/time parameters.RStudio, can click “Knit Parameters” option Knit dropdown menu set parameters, render, preview report single user friendly step.\ncan customise dialog setting options header.\nSee http://rmarkdown.rstudio.com/developer_parameterized_reports.html#parameter_user_interfaces details.Alternatively, need produce many parameterised reports, can call rmarkdown::render() list params:particularly powerful conjunction purrr:pwalk().\nfollowing example creates report value class found mpg.\nFirst create data frame one row class, giving filename report params:match column names argument names render(), use purrr’s parallel walk call render() row:","code":"---\noutput: html_document\nparams:\n  my_class: \"suv\"\n---\n\n```{r setup, include = FALSE}\nlibrary(ggplot2)\nlibrary(dplyr)\n\nclass <- mpg %>% filter(class == params$my_class)\n```\n\n# Fuel economy for `r params$my_class`s\n\n```{r, message = FALSE}\nggplot(class, aes(displ, hwy)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n```\nparams:\n  start: !r lubridate::ymd(\"2015-01-01\")\n  snapshot: !r lubridate::ymd_hms(\"2015-01-01 12:30:00\")\nrmarkdown::render(\"fuel-economy.Rmd\", params = list(my_class = \"suv\"))\nreports <- tibble(\n  class = unique(mpg$class),\n  filename = stringr::str_c(\"fuel-economy-\", class, \".html\"),\n  params = purrr::map(class, ~ list(my_class = .))\n)\nreports\n#> <U+2029>[90m# A tibble: 7 x 3<U+2029>[39mNA#>   <U+2029>[1mclass<U+2029>[22m   <U+2029>[1mfilename<U+2029>[22m                  <U+2029>[1mparams<U+2029>[22m          NA#>   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m   <U+2029>[3m<U+2029>[90m<chr><U+2029>[39m<U+2029>[23m                     <U+2029>[3m<U+2029>[90m<list><U+2029>[39m<U+2029>[23m          NA#> <U+2029>[90m1<U+2029>[39m compact fuel-economy-compact.html <U+2029>[90m<named list [1]><U+2029>[39mNA#> <U+2029>[90m2<U+2029>[39m midsize fuel-economy-midsize.html <U+2029>[90m<named list [1]><U+2029>[39mNA#> <U+2029>[90m3<U+2029>[39m suv     fuel-economy-suv.html     <U+2029>[90m<named list [1]><U+2029>[39mNA#> <U+2029>[90m4<U+2029>[39m 2seater fuel-economy-2seater.html <U+2029>[90m<named list [1]><U+2029>[39mNA#> <U+2029>[90m5<U+2029>[39m minivan fuel-economy-minivan.html <U+2029>[90m<named list [1]><U+2029>[39mNA#> <U+2029>[90m6<U+2029>[39m pickup  fuel-economy-pickup.html  <U+2029>[90m<named list [1]><U+2029>[39mNA#> <U+2029>[90m# ... with 1 more row<U+2029>[39mNA\nreports %>% \n  select(output_file = filename, params) %>% \n  purrr::pwalk(rmarkdown::render, input = \"fuel-economy.Rmd\")"},{"path":"r-markdown.html","id":"bibliographies-and-citations","chapter":"39 R Markdown","heading":"39.6.2 Bibliographies and Citations","text":"Pandoc can automatically generate citations bibliography number styles.\nuse feature, specify bibliography file using bibliography field file’s header.\nfield contain path directory contains .Rmd file file contains bibliography file:can use many common bibliography formats including BibLaTeX, BibTeX, endnote, medline.create citation within .Rmd file, use key composed ‘@’ + citation identifier bibliography file.\nplace citation square brackets.\nexamples:R Markdown renders file, build append bibliography end document.\nbibliography contain cited references bibliography file, contain section heading.\nresult common practice end file section header bibliography, # References # Bibliography.can change style citations bibliography referencing CSL (citation style language) file csl field:bibliography field, csl file contain path file.\nassume csl file directory .Rmd file.\ngood place find CSL style files common bibliography styles http://github.com/citation-style-language/styles.","code":"bibliography: rmarkdown.bibSeparate multiple citations with a `;`: Blah blah [@smith04; @doe99].\n\nYou can add arbitrary comments inside the square brackets: \nBlah blah [see @doe99, pp. 33-35; also @smith04, ch. 1].\n\nRemove the square brackets to create an in-text citation: @smith04 \nsays blah, or @smith04 [p. 33] says blah.\n\nAdd a `-` before the citation to suppress the author's name: \nSmith says blah [-@smith04].bibliography: rmarkdown.bib\ncsl: apa.csl"},{"path":"r-markdown.html","id":"learning-more-3","chapter":"39 R Markdown","heading":"39.7 Learning more","text":"R Markdown still relatively young, still growing rapidly.\nbest place stay top innovations official R Markdown website: http://rmarkdown.rstudio.com.two important topics haven’t covered : collaboration, details accurately communicating ideas humans.\nCollaboration vital part modern data science, can make life much easier using version control tools, like Git GitHub.\nrecommend two free resources teach Git:“Happy Git R”: user friendly introduction Git GitHub R users, Jenny Bryan.\nbook freely available online: http://happygitwithr.com“Happy Git R”: user friendly introduction Git GitHub R users, Jenny Bryan.\nbook freely available online: http://happygitwithr.comThe “Git GitHub” chapter R Packages, Hadley.\ncan also read free online: http://r-pkgs..co.nz/git.html.“Git GitHub” chapter R Packages, Hadley.\ncan also read free online: http://r-pkgs..co.nz/git.html.also touched actually write order clearly communicate results analysis.\nimprove writing, highly recommend reading either Style: Lessons Clarity Grace Joseph M. Williams & Joseph Bizup, Sense Structure: Writing Reader’s Perspective George Gopen.\nbooks help understand structure sentences paragraphs, give tools make writing clear.\n(books rather expensive purchased new, ’re used many English classes plenty cheap second-hand copies).\nGeorge Gopen also number short articles writing https://www.georgegopen.com/-litigation-articles.html.\naimed lawyers, almost everything applies data scientists .","code":""},{"path":"graphics-for-communication.html","id":"graphics-for-communication","chapter":"40 Graphics for communication","heading":"40 Graphics for communication","text":"","code":""},{"path":"graphics-for-communication.html","id":"introduction-23","chapter":"40 Graphics for communication","heading":"40.1 Introduction","text":"exploratory data analysis, learned use plots tools exploration.\nmake exploratory plots, know—even looking—variables plot display.\nmade plot purpose, quickly look , move next plot.\ncourse analyses, ’ll produce tens hundreds plots, immediately thrown away.Now understand data, need communicate understanding others.\naudience likely share background knowledge deeply invested data.\nhelp others quickly build good mental model data, need invest considerable effort making plots self-explanatory possible.\nchapter, ’ll learn tools ggplot2 provides .chapter focuses tools need create good graphics.\nassume know want, just need know .\nreason, highly recommend pairing chapter good general visualisation book.\nparticularly like Truthful Art, Albert Cairo.\ndoesn’t teach mechanics creating visualisations, instead focuses need think order create effective graphics.","code":""},{"path":"graphics-for-communication.html","id":"prerequisites-20","chapter":"40 Graphics for communication","heading":"40.1.1 Prerequisites","text":"chapter, ’ll focus ggplot2.\n’ll also use little dplyr data manipulation, ggplot2 extension packages, including ggrepel viridis.\nRather loading extensions , ’ll refer functions explicitly, using :: notation.\nhelp make clear functions built ggplot2, come packages.\nDon’t forget ’ll need install packages install.packages() don’t already .","code":"\nlibrary(tidyverse)"},{"path":"graphics-for-communication.html","id":"label","chapter":"40 Graphics for communication","heading":"40.2 Label","text":"easiest place start turning exploratory graphic expository graphic good labels.\nadd labels labs() function.\nexample adds plot title:purpose plot title summarise main finding.\nAvoid titles just describe plot , e.g. “scatterplot engine displacement vs. fuel economy”.need add text, two useful labels can use ggplot2 2.2.0 (available time ’re reading book):subtitle adds additional detail smaller font beneath title.subtitle adds additional detail smaller font beneath title.caption adds text bottom right plot, often used describe source data.caption adds text bottom right plot, often used describe source data.can also use labs() replace axis legend titles.\n’s usually good idea replace short variable names detailed descriptions, include units.’s possible use mathematical equations instead text strings.\nJust switch \"\" quote() read available options ?plotmath:","code":"\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Fuel efficiency generally decreases with engine size\")\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  labs(\n    title = \"Fuel efficiency generally decreases with engine size\",\n    subtitle = \"Two seaters (sports cars) are an exception because of their light weight\",\n    caption = \"Data from fueleconomy.gov\"\n  )\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(colour = class)) +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"Engine displacement (L)\",\n    y = \"Highway fuel economy (mpg)\",\n    colour = \"Car type\"\n  )\ndf <- tibble(\n  x = runif(10),\n  y = runif(10)\n)\nggplot(df, aes(x, y)) +\n  geom_point() +\n  labs(\n    x = quote(sum(x[i] ^ 2, i == 1, n)),\n    y = quote(alpha + beta + frac(delta, theta))\n  )"},{"path":"graphics-for-communication.html","id":"exercises-69","chapter":"40 Graphics for communication","heading":"40.2.1 Exercises","text":"Create one plot fuel economy data customised title, subtitle, caption, x, y, colour labels.Create one plot fuel economy data customised title, subtitle, caption, x, y, colour labels.geom_smooth() somewhat misleading hwy large engines skewed upwards due inclusion lightweight sports cars big engines.\nUse modelling tools fit display better model.\ngeom_smooth() somewhat misleading hwy large engines skewed upwards due inclusion lightweight sports cars big engines.\nUse modelling tools fit display better model.\nTake exploratory graphic ’ve created last month, add informative titles make easier others understand.Take exploratory graphic ’ve created last month, add informative titles make easier others understand.","code":""},{"path":"graphics-for-communication.html","id":"annotations","chapter":"40 Graphics for communication","heading":"40.3 Annotations","text":"addition labelling major components plot, ’s often useful label individual observations groups observations.\nfirst tool disposal geom_text().\ngeom_text() similar geom_point(), additional aesthetic: label.\nmakes possible add textual labels plots.two possible sources labels.\nFirst, might tibble provides labels.\nplot isn’t terribly useful, illustrates useful approach: pull efficient car class dplyr, label plot:hard read labels overlap , points.\ncan make things little better switching geom_label() draws rectangle behind text.\nalso use nudge_y parameter move labels slightly corresponding points:helps bit, look closely top-left hand corner, ’ll notice two labels practically top .\nhappens highway mileage displacement best cars compact subcompact categories exactly .\n’s way can fix applying transformation every label.\nInstead, can use ggrepel package Kamil Slowikowski.\nuseful package automatically adjust labels don’t overlap:Note another handy technique used : added second layer large, hollow points highlight points ’ve labelled.can sometimes use idea replace legend labels placed directly plot.\n’s wonderful plot, isn’t bad.\n(theme(legend.position = \"none\") turns legend — ’ll talk shortly.)Alternatively, might just want add single label plot, ’ll still need create data frame.\nOften, want label corner plot, ’s convenient create new data frame using summarise() compute maximum values x y.want place text exactly borders plot, can use +Inf -Inf.\nSince ’re longer computing positions mpg, can use tibble() create data frame:examples, manually broke label lines using \"\\n\".\nAnother approach use stringr::str_wrap() automatically add line breaks, given number characters want per line:Note use hjust vjust control alignment label.\nFigure 40.1 shows nine possible combinations.\nFigure 40.1: nine combinations hjust vjust.\nRemember, addition geom_text(), many geoms ggplot2 available help annotate plot.\nideas:Use geom_hline() geom_vline() add reference lines.\noften make thick (size = 2) white (colour = white), draw underneath primary data layer.\nmakes easy see, without drawing attention away data.Use geom_hline() geom_vline() add reference lines.\noften make thick (size = 2) white (colour = white), draw underneath primary data layer.\nmakes easy see, without drawing attention away data.Use geom_rect() draw rectangle around points interest.\nboundaries rectangle defined aesthetics xmin, xmax, ymin, ymax.Use geom_rect() draw rectangle around points interest.\nboundaries rectangle defined aesthetics xmin, xmax, ymin, ymax.Use geom_segment() arrow argument draw attention point arrow.\nUse aesthetics x y define starting location, xend yend define end location.Use geom_segment() arrow argument draw attention point arrow.\nUse aesthetics x y define starting location, xend yend define end location.limit imagination (patience positioning annotations aesthetically pleasing)!","code":"\nbest_in_class <- mpg %>%\n  group_by(class) %>%\n  filter(row_number(desc(hwy)) == 1)\n\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(colour = class)) +\n  geom_text(aes(label = model), data = best_in_class)\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(colour = class)) +\n  geom_label(aes(label = model), data = best_in_class, nudge_y = 2, alpha = 0.5)\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(colour = class)) +\n  geom_point(size = 3, shape = 1, data = best_in_class) +\n  ggrepel::geom_label_repel(aes(label = model), data = best_in_class)\nclass_avg <- mpg %>%\n  group_by(class) %>%\n  summarise(\n    displ = median(displ),\n    hwy = median(hwy)\n  )\n\nggplot(mpg, aes(displ, hwy, colour = class)) +\n  ggrepel::geom_label_repel(aes(label = class),\n    data = class_avg,\n    size = 6,\n    label.size = 0,\n    segment.color = NA\n  ) +\n  geom_point() +\n  theme(legend.position = \"none\")\nlabel <- mpg %>%\n  summarise(\n    displ = max(displ),\n    hwy = max(hwy),\n    label = \"Increasing engine size is \\nrelated to decreasing fuel economy.\"\n  )\n\nggplot(mpg, aes(displ, hwy)) +\n  geom_point() +\n  geom_text(aes(label = label), data = label, vjust = \"top\", hjust = \"right\")\nlabel <- tibble(\n  displ = Inf,\n  hwy = Inf,\n  label = \"Increasing engine size is \\nrelated to decreasing fuel economy.\"\n)\n\nggplot(mpg, aes(displ, hwy)) +\n  geom_point() +\n  geom_text(aes(label = label), data = label, vjust = \"top\", hjust = \"right\")\n\"Increasing engine size is related to decreasing fuel economy.\" %>%\n  stringr::str_wrap(width = 40) %>%\n  writeLines()\n#> Increasing engine size is related to\n#> decreasing fuel economy."},{"path":"graphics-for-communication.html","id":"exercises-70","chapter":"40 Graphics for communication","heading":"40.3.1 Exercises","text":"Use geom_text() infinite positions place text four corners plot.Use geom_text() infinite positions place text four corners plot.Read documentation annotate().\ncan use add text label plot without create tibble?Read documentation annotate().\ncan use add text label plot without create tibble?labels geom_text() interact faceting?\ncan add label single facet?\ncan put different label facet?\n(Hint: think underlying data.)labels geom_text() interact faceting?\ncan add label single facet?\ncan put different label facet?\n(Hint: think underlying data.)arguments geom_label() control appearance background box?arguments geom_label() control appearance background box?four arguments arrow()?\nwork?\nCreate series plots demonstrate important options.four arguments arrow()?\nwork?\nCreate series plots demonstrate important options.","code":""},{"path":"graphics-for-communication.html","id":"scales","chapter":"40 Graphics for communication","heading":"40.4 Scales","text":"third way can make plot better communication adjust scales.\nScales control mapping data values things can perceive.\nNormally, ggplot2 automatically adds scales .\nexample, type:ggplot2 automatically adds default scales behind scenes:Note naming scheme scales: scale_ followed name aesthetic, _, name scale.\ndefault scales named according type variable align : continuous, discrete, datetime, date.\nlots non-default scales ’ll learn .default scales carefully chosen good job wide range inputs.\nNevertheless, might want override defaults two reasons:might want tweak parameters default scale.\nallows things like change breaks axes, key labels legend.might want tweak parameters default scale.\nallows things like change breaks axes, key labels legend.might want replace scale altogether, use completely different algorithm.\nOften can better default know data.might want replace scale altogether, use completely different algorithm.\nOften can better default know data.","code":"\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(colour = class))\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(colour = class)) +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  scale_colour_discrete()"},{"path":"graphics-for-communication.html","id":"axis-ticks-and-legend-keys","chapter":"40 Graphics for communication","heading":"40.4.1 Axis ticks and legend keys","text":"two primary arguments affect appearance ticks axes keys legend: breaks labels.\nBreaks controls position ticks, values associated keys.\nLabels controls text label associated tick/key.\ncommon use breaks override default choice:can use labels way (character vector length breaks), can also set NULL suppress labels altogether.\nuseful maps, publishing plots can’t share absolute numbers.can also use breaks labels control appearance legends.\nCollectively axes legends called guides.\nAxes used x y aesthetics; legends used everything else.Another use breaks relatively data points want highlight exactly observations occur.\nexample, take plot shows US president started ended term.Note specification breaks labels date datetime scales little different:date_labels takes format specification, form parse_datetime().date_labels takes format specification, form parse_datetime().date_breaks (shown ), takes string like “2 days” “1 month”.date_breaks (shown ), takes string like “2 days” “1 month”.","code":"\nggplot(mpg, aes(displ, hwy)) +\n  geom_point() +\n  scale_y_continuous(breaks = seq(15, 40, by = 5))\nggplot(mpg, aes(displ, hwy)) +\n  geom_point() +\n  scale_x_continuous(labels = NULL) +\n  scale_y_continuous(labels = NULL)\npresidential %>%\n  mutate(id = 33 + row_number()) %>%\n  ggplot(aes(start, id)) +\n    geom_point() +\n    geom_segment(aes(xend = end, yend = id)) +\n    scale_x_date(NULL, breaks = presidential$start, date_labels = \"'%y\")"},{"path":"graphics-for-communication.html","id":"legend-layout","chapter":"40 Graphics for communication","heading":"40.4.2 Legend layout","text":"often use breaks labels tweak axes.\nalso work legends, techniques likely use.control overall position legend, need use theme() setting.\n’ll come back themes end chapter, brief, control non-data parts plot.\ntheme setting legend.position controls legend drawn:can also use legend.position = \"none\" suppress display legend altogether.control display individual legends, use guides() along guide_legend() guide_colourbar().\nfollowing example shows two important settings: controlling number rows legend uses nrow, overriding one aesthetics make points bigger.\nparticularly useful used low alpha display many points plot.","code":"\nbase <- ggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(colour = class))\n\nbase + theme(legend.position = \"left\")\nbase + theme(legend.position = \"top\")\nbase + theme(legend.position = \"bottom\")\nbase + theme(legend.position = \"right\") # the default\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(colour = class)) +\n  geom_smooth(se = FALSE) +\n  theme(legend.position = \"bottom\") +\n  guides(colour = guide_legend(nrow = 1, override.aes = list(size = 4)))\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"graphics-for-communication.html","id":"replacing-a-scale","chapter":"40 Graphics for communication","heading":"40.4.3 Replacing a scale","text":"Instead just tweaking details little, can instead replace scale altogether.\ntwo types scales ’re mostly likely want switch : continuous position scales colour scales.\nFortunately, principles apply aesthetics, ’ve mastered position colour, ’ll able quickly pick scale replacements.’s useful plot transformations variable.\nexample, ’ve seen diamond prices ’s easier see precise relationship carat price log transform :However, disadvantage transformation axes now labelled transformed values, making hard interpret plot.\nInstead transformation aesthetic mapping, can instead scale.\nvisually identical, except axes labelled original data scale.Another scale frequently customised colour.\ndefault categorical scale picks colours evenly spaced around colour wheel.\nUseful alternatives ColorBrewer scales hand tuned work better people common types colour blindness.\ntwo plots look similar, enough difference shades red green dots right can distinguished even people red-green colour blindness.Don’t forget simpler techniques.\njust colours, can add redundant shape mapping.\nalso help ensure plot interpretable black white.ColorBrewer scales documented online http://colorbrewer2.org/ made available R via RColorBrewer package, Erich Neuwirth.\nFigure 40.2 shows complete list palettes.\nsequential (top) diverging (bottom) palettes particularly useful categorical values ordered, “middle”.\noften arises ’ve used cut() make continuous variable categorical variable.\nFigure 40.2: ColourBrewer scales.\npredefined mapping values colours, use scale_colour_manual().\nexample, map presidential party colour, want use standard mapping red Republicans blue Democrats:continuous colour, can use built-scale_colour_gradient() scale_fill_gradient().\ndiverging scale, can use scale_colour_gradient2().\nallows give, example, positive negative values different colours.\n’s sometimes also useful want distinguish points mean.Another option scale_colour_viridis() provided viridis package.\n’s continuous analog categorical ColorBrewer scales.\ndesigners, Nathaniel Smith Stéfan van der Walt, carefully tailored continuous colour scheme good perceptual properties.\n’s example viridis vignette.Note colour scales come two variety: scale_colour_x() scale_fill_x() colour fill aesthetics respectively (colour scales available UK US spellings).","code":"\nggplot(diamonds, aes(carat, price)) +\n  geom_bin2d()\n\nggplot(diamonds, aes(log10(carat), log10(price))) +\n  geom_bin2d()\nggplot(diamonds, aes(carat, price)) +\n  geom_bin2d() + \n  scale_x_log10() + \n  scale_y_log10()\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(color = drv))\n\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(color = drv)) +\n  scale_colour_brewer(palette = \"Set1\")\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(color = drv, shape = drv)) +\n  scale_colour_brewer(palette = \"Set1\")\npresidential %>%\n  mutate(id = 33 + row_number()) %>%\n  ggplot(aes(start, id, colour = party)) +\n    geom_point() +\n    geom_segment(aes(xend = end, yend = id)) +\n    scale_colour_manual(values = c(Republican = \"red\", Democratic = \"blue\"))\ndf <- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed()\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  viridis::scale_fill_viridis() +\n  coord_fixed()"},{"path":"graphics-for-communication.html","id":"exercises-71","chapter":"40 Graphics for communication","heading":"40.4.4 Exercises","text":"doesn’t following code override default scale?\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  scale_colour_gradient(low = \"white\", high = \"red\") +\n  coord_fixed()doesn’t following code override default scale?first argument every scale?\ncompare labs()?first argument every scale?\ncompare labs()?Change display presidential terms :\nCombining two variants shown .\nImproving display y axis.\nLabelling term name president.\nAdding informative plot labels.\nPlacing breaks every 4 years (trickier seems!).\nChange display presidential terms :Combining two variants shown .Improving display y axis.Labelling term name president.Adding informative plot labels.Placing breaks every 4 years (trickier seems!).Use override.aes make legend following plot easier see.\n\nggplot(diamonds, aes(carat, price)) +\n  geom_point(aes(colour = cut), alpha = 1/20)\nUse override.aes make legend following plot easier see.","code":"\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  scale_colour_gradient(low = \"white\", high = \"red\") +\n  coord_fixed()\nggplot(diamonds, aes(carat, price)) +\n  geom_point(aes(colour = cut), alpha = 1/20)"},{"path":"graphics-for-communication.html","id":"zooming","chapter":"40 Graphics for communication","heading":"40.5 Zooming","text":"three ways control plot limits:Adjusting data plottedSetting limits scaleSetting xlim ylim coord_cartesian()zoom region plot, ’s generally best use coord_cartesian().\nCompare following two plots:can also set limits individual scales.\nReducing limits basically equivalent subsetting data.\ngenerally useful want expand limits, example, match scales across different plots.\nexample, extract two classes cars plot separately, ’s difficult compare plots three scales (x-axis, y-axis, colour aesthetic) different ranges.One way overcome problem share scales across multiple plots, training scales limits full data.particular case, simply used faceting, technique useful generally, instance, want spread plots multiple pages report.","code":"\nggplot(mpg, mapping = aes(displ, hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth() +\n  coord_cartesian(xlim = c(5, 7), ylim = c(10, 30))\n\nmpg %>%\n  filter(displ >= 5, displ <= 7, hwy >= 10, hwy <= 30) %>%\n  ggplot(aes(displ, hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth()\nsuv <- mpg %>% filter(class == \"suv\")\ncompact <- mpg %>% filter(class == \"compact\")\n\nggplot(suv, aes(displ, hwy, colour = drv)) +\n  geom_point()\n\nggplot(compact, aes(displ, hwy, colour = drv)) +\n  geom_point()\nx_scale <- scale_x_continuous(limits = range(mpg$displ))\ny_scale <- scale_y_continuous(limits = range(mpg$hwy))\ncol_scale <- scale_colour_discrete(limits = unique(mpg$drv))\n\nggplot(suv, aes(displ, hwy, colour = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\nggplot(compact, aes(displ, hwy, colour = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale"},{"path":"graphics-for-communication.html","id":"themes","chapter":"40 Graphics for communication","heading":"40.6 Themes","text":"Finally, can customise non-data elements plot theme:ggplot2 includes eight themes default, shown Figure 40.3.\nMany included add-packages like ggthemes (https://github.com/jrnold/ggthemes), Jeffrey Arnold.\nFigure 40.3: eight themes built-ggplot2.\nMany people wonder default theme grey background.\ndeliberate choice puts data forward still making grid lines visible.\nwhite grid lines visible (important significantly aid position judgements), little visual impact can easily tune .\ngrey background gives plot similar typographic colour text, ensuring graphics fit flow document without jumping bright white background.\nFinally, grey background creates continuous field colour ensures plot perceived single visual entity.’s also possible control individual components theme, like size colour font used y axis.\nUnfortunately, level detail outside scope book, ’ll need read ggplot2 book full details.\ncan also create themes, trying match particular corporate journal style.","code":"\nggplot(mpg, aes(displ, hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme_bw()"},{"path":"graphics-for-communication.html","id":"saving-your-plots","chapter":"40 Graphics for communication","heading":"40.7 Saving your plots","text":"two main ways get plots R final write-: ggsave() knitr.\nggsave() save recent plot disk:don’t specify width height taken dimensions current plotting device.\nreproducible code, ’ll want specify .Generally, however, think assembling final reports using R Markdown, want focus important code chunk options know graphics.\ncan learn ggsave() documentation.","code":"\nggplot(mpg, aes(displ, hwy)) + geom_point()\nggsave(\"my-plot.pdf\")\n#> Saving 7 x 4.32 in image"},{"path":"graphics-for-communication.html","id":"figure-sizing","chapter":"40 Graphics for communication","heading":"40.7.1 Figure sizing","text":"biggest challenge graphics R Markdown getting figures right size shape.\nfive main options control figure sizing: fig.width, fig.height, fig.asp, .width .height.\nImage sizing challenging two sizes (size figure created R size inserted output document), multiple ways specifying size (.e., height, width, aspect ratio: pick two three).ever use three five options:find aesthetically pleasing plots consistent width.\nenforce , set fig.width = 6 (6\") fig.asp = 0.618 (golden ratio) defaults.\nindividual chunks, adjust fig.asp.find aesthetically pleasing plots consistent width.\nenforce , set fig.width = 6 (6\") fig.asp = 0.618 (golden ratio) defaults.\nindividual chunks, adjust fig.asp.control output size .width set percentage line width.\ndefault .width = \"70%\" fig.align = \"center\".\ngive plots room breathe, without taking much space.control output size .width set percentage line width.\ndefault .width = \"70%\" fig.align = \"center\".\ngive plots room breathe, without taking much space.put multiple plots single row set .width 50% two plots, 33% 3 plots, 25% 4 plots, set fig.align = \"default\".\nDepending ’m trying illustrate (e.g. show data show plot variations), ’ll also tweak fig.width, discussed .put multiple plots single row set .width 50% two plots, 33% 3 plots, 25% 4 plots, set fig.align = \"default\".\nDepending ’m trying illustrate (e.g. show data show plot variations), ’ll also tweak fig.width, discussed .find ’re squint read text plot, need tweak fig.width.\nfig.width larger size figure rendered final doc, text small; fig.width smaller, text big.\n’ll often need little experimentation figure right ratio fig.width eventual width document.\nillustrate principle, following three plots fig.width 4, 6, 8 respectively:want make sure font size consistent across figures, whenever set .width, ’ll also need adjust fig.width maintain ratio default .width.\nexample, default fig.width 6 .width 0.7, set .width = \"50%\" ’ll need set fig.width 4.3 (6 * 0.5 / 0.7).","code":""},{"path":"graphics-for-communication.html","id":"other-important-options","chapter":"40 Graphics for communication","heading":"40.7.2 Other important options","text":"mingling code text, like book, recommend setting fig.show = \"hold\" plots shown code.\npleasant side effect forcing break large blocks code explanations.add caption plot, use fig.cap.\nR Markdown change figure inline “floating”.’re producing PDF output, default graphics type PDF.\ngood default PDFs high quality vector graphics.\nHowever, can produce large slow plots displaying thousands points.\ncase, set dev = \"png\" force use PNGs.\nslightly lower quality, much compact.’s good idea name code chunks produce figures, even don’t routinely label chunks.\nchunk label used generate file name graphic disk, naming chunks makes much easier pick plots reuse circumstances (.e. want quickly drop single plot email tweet).","code":""},{"path":"graphics-for-communication.html","id":"learning-more-4","chapter":"40 Graphics for communication","heading":"40.8 Learning more","text":"absolute best place learn ggplot2 book: ggplot2: Elegant graphics data analysis.\ngoes much depth underlying theory, many examples combine individual pieces solve practical problems.\nUnfortunately, book available online free, although can find source code https://github.com/hadley/ggplot2-book.Another great resource ggplot2 extensions gallery https://exts.ggplot2.tidyverse.org/gallery/.\nsite lists many packages extend ggplot2 new geoms scales.\n’s great place start ’re trying something seems hard ggplot2.","code":""},{"path":"r-markdown-formats.html","id":"r-markdown-formats","chapter":"41 R Markdown formats","heading":"41 R Markdown formats","text":"","code":""},{"path":"r-markdown-formats.html","id":"introduction-24","chapter":"41 R Markdown formats","heading":"41.1 Introduction","text":"far ’ve seen R Markdown used produce HTML documents.\nchapter gives brief overview many types output can produce R Markdown.\ntwo ways set output document:Permanently, modifying YAML header:\ntitle: \"Viridis Demo\"\noutput: html_documentPermanently, modifying YAML header:Transiently, calling rmarkdown::render() hand:\n\nrmarkdown::render(\"diamond-sizes.Rmd\", output_format = \"word_document\")\nuseful want programmatically produce multiple types output.Transiently, calling rmarkdown::render() hand:useful want programmatically produce multiple types output.RStudio’s knit button renders file first format listed output field.\ncan render additional formats clicking dropdown menu beside knit button.","code":"title: \"Viridis Demo\"\noutput: html_document\nrmarkdown::render(\"diamond-sizes.Rmd\", output_format = \"word_document\")"},{"path":"r-markdown-formats.html","id":"output-options","chapter":"41 R Markdown formats","heading":"41.2 Output options","text":"output format associated R function.\ncan either write foo pkg::foo.\nomit pkg, default assumed rmarkdown.\n’s important know name function makes output ’s get help.\nexample, figure parameters can set html_document, look ?rmarkdown::html_document.override default parameter values, need use expanded output field.\nexample, wanted render html_document floating table contents, ’d use:can even render multiple outputs supplying list formats:Note special syntax don’t want override default options.","code":"output:\n  html_document:\n    toc: true\n    toc_float: trueoutput:\n  html_document:\n    toc: true\n    toc_float: true\n  pdf_document: default"},{"path":"r-markdown-formats.html","id":"documents","chapter":"41 R Markdown formats","heading":"41.3 Documents","text":"previous chapter focused default html_document output.\nnumber basic variations theme, generating different types documents:pdf_document makes PDF LaTeX (open source document layout system), ’ll need install.\nRStudio prompt don’t already .pdf_document makes PDF LaTeX (open source document layout system), ’ll need install.\nRStudio prompt don’t already .word_document Microsoft Word documents (.docx).word_document Microsoft Word documents (.docx).odt_document OpenDocument Text documents (.odt).odt_document OpenDocument Text documents (.odt).rtf_document Rich Text Format (.rtf) documents.rtf_document Rich Text Format (.rtf) documents.md_document Markdown document.\nisn’t typically useful , might use , example, corporate CMS lab wiki uses markdown.md_document Markdown document.\nisn’t typically useful , might use , example, corporate CMS lab wiki uses markdown.github_document: tailored version md_document designed sharing GitHub.github_document: tailored version md_document designed sharing GitHub.Remember, generating document share decision makers, can turn default display code setting global options setup chunk:html_documents another option make code chunks hidden default, visible click:","code":"\nknitr::opts_chunk$set(echo = FALSE)output:\n  html_document:\n    code_folding: hide"},{"path":"r-markdown-formats.html","id":"notebooks","chapter":"41 R Markdown formats","heading":"41.4 Notebooks","text":"notebook, html_notebook, variation html_document.\nrendered outputs similar, purpose different.\nhtml_document focused communicating decision makers, notebook focused collaborating data scientists.\ndifferent purposes lead using HTML output different ways.\nHTML outputs contain fully rendered output, notebook also contains full source code.\nmeans can use .nb.html generated notebook two ways:can view web browser, see rendered output.\nUnlike html_document, rendering always includes embedded copy source code generated .can view web browser, see rendered output.\nUnlike html_document, rendering always includes embedded copy source code generated .can edit RStudio.\nopen .nb.html file, RStudio automatically recreate .Rmd file generated .\nfuture, also able include supporting files (e.g. .csv data files), automatically extracted needed.can edit RStudio.\nopen .nb.html file, RStudio automatically recreate .Rmd file generated .\nfuture, also able include supporting files (e.g. .csv data files), automatically extracted needed.Emailing .nb.html files simple way share analyses colleagues.\nthings get painful soon want make changes.\nstarts happen, ’s good time learn Git GitHub.\nLearning Git GitHub definitely painful first, collaboration payoff huge.\nmentioned earlier, Git GitHub outside scope book, ’s one tip ’s useful ’re already using : use html_notebook github_document outputs:html_notebook gives local preview, file can share via email.\ngithub_document creates minimal md file can check git.\ncan easily see results analysis (just code) change time, GitHub render nicely online.","code":"output:\n  html_notebook: default\n  github_document: default"},{"path":"r-markdown-formats.html","id":"presentations","chapter":"41 R Markdown formats","heading":"41.5 Presentations","text":"can also use R Markdown produce presentations.\nget less visual control tool like Keynote PowerPoint, automatically inserting results R code presentation can save huge amount time.\nPresentations work dividing content slides, new slide beginning first (#) second (##) level header.\ncan also insert horizontal rule (***) create new slide without header.R Markdown comes three presentation formats built-:ioslides_presentation - HTML presentation ioslidesioslides_presentation - HTML presentation ioslidesslidy_presentation - HTML presentation W3C Slidyslidy_presentation - HTML presentation W3C Slidybeamer_presentation - PDF presentation LaTeX Beamer.beamer_presentation - PDF presentation LaTeX Beamer.Two popular formats provided packages:revealjs::revealjs_presentation - HTML presentation reveal.js.\nRequires revealjs package.revealjs::revealjs_presentation - HTML presentation reveal.js.\nRequires revealjs package.rmdshower, https://github.com/MangoTheCat/rmdshower, provides wrapper around shower, https://github.com/shower/shower, presentation enginermdshower, https://github.com/MangoTheCat/rmdshower, provides wrapper around shower, https://github.com/shower/shower, presentation engine","code":""},{"path":"r-markdown-formats.html","id":"dashboards","chapter":"41 R Markdown formats","heading":"41.6 Dashboards","text":"Dashboards useful way communicate large amounts information visually quickly.\nFlexdashboard makes particularly easy create dashboards using R Markdown convention headers affect layout:level 1 header (#) begins new page dashboard.level 2 header (##) begins new column.level 3 header (###) begins new row.example, can produce dashboard:Using code:Flexdashboard also provides simple tools creating sidebars, tabsets, value boxes, gauges.\nlearn flexdashboard visit http://rmarkdown.rstudio.com/flexdashboard/.","code":"---\ntitle: \"Diamonds distribution dashboard\"\noutput: flexdashboard::flex_dashboard\n---\n\n```{r setup, include = FALSE}\nlibrary(ggplot2)\nlibrary(dplyr)\nknitr::opts_chunk$set(fig.width = 5, fig.asp = 1/3)\n```\n\n## Column 1\n\n### Carat\n\n```{r}\nggplot(diamonds, aes(carat)) + geom_histogram(binwidth = 0.1)\n```\n\n### Cut\n\n```{r}\nggplot(diamonds, aes(cut)) + geom_bar()\n```\n\n### Colour\n\n```{r}\nggplot(diamonds, aes(color)) + geom_bar()\n```\n\n## Column 2\n\n### The largest diamonds\n\n```{r}\ndiamonds %>% \n  arrange(desc(carat)) %>% \n  head(100) %>% \n  select(carat, cut, color, price) %>% \n  DT::datatable()\n```"},{"path":"r-markdown-formats.html","id":"interactivity","chapter":"41 R Markdown formats","heading":"41.7 Interactivity","text":"HTML format (document, notebook, presentation, dashboard) can contain interactive components.","code":""},{"path":"r-markdown-formats.html","id":"htmlwidgets","chapter":"41 R Markdown formats","heading":"41.7.1 htmlwidgets","text":"HTML interactive format, can take advantage interactivity htmlwidgets, R functions produce interactive HTML visualisations.\nexample, take leaflet map .\n’re viewing page web, can drag map around, zoom , etc.\nobviously can’t book, rmarkdown automatically inserts static screenshot .great thing htmlwidgets don’t need know anything HTML JavaScript use .\ndetails wrapped inside package, don’t need worry .many packages provide htmlwidgets, including:dygraphs, http://rstudio.github.io/dygraphs/, interactive time series visualisations.dygraphs, http://rstudio.github.io/dygraphs/, interactive time series visualisations.DT, http://rstudio.github.io/DT/, interactive tables.DT, http://rstudio.github.io/DT/, interactive tables.threejs, https://github.com/bwlewis/rthreejs interactive 3d plots.threejs, https://github.com/bwlewis/rthreejs interactive 3d plots.DiagrammeR, http://rich-iannone.github.io/DiagrammeR/ diagrams (like flow charts simple node-link diagrams).DiagrammeR, http://rich-iannone.github.io/DiagrammeR/ diagrams (like flow charts simple node-link diagrams).learn htmlwidgets see complete list packages provide visit http://www.htmlwidgets.org/.","code":"\nlibrary(leaflet)\nleaflet() %>%\n  setView(174.764, -36.877, zoom = 16) %>% \n  addTiles() %>%\n  addMarkers(174.764, -36.877, popup = \"Maungawhau\") "},{"path":"r-markdown-formats.html","id":"shiny","chapter":"41 R Markdown formats","heading":"41.7.2 Shiny","text":"htmlwidgets provide client-side interactivity — interactivity happens browser, independently R.\none hand, ’s great can distribute HTML file without connection R.\nHowever, fundamentally limits can things implemented HTML JavaScript.\nalternative approach use shiny, package allows create interactivity using R code, JavaScript.call Shiny code R Markdown document, add runtime: shiny header:can use “input” functions add interactive components document:can refer values input$name input$age, code uses automatically re-run whenever change.can’t show live shiny app shiny interactions occur server-side.\nmeans can write interactive apps without knowing JavaScript, need server run .\nintroduces logistical issue: Shiny apps need Shiny server run online.\nrun shiny apps computer, shiny automatically sets shiny server , need public facing shiny server want publish sort interactivity online.\n’s fundamental trade-shiny: can anything shiny document can R, requires someone running R.Learn Shiny http://shiny.rstudio.com/.","code":"title: \"Shiny Web App\"\noutput: html_document\nruntime: shiny\nlibrary(shiny)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)"},{"path":"r-markdown-formats.html","id":"websites","chapter":"41 R Markdown formats","heading":"41.8 Websites","text":"little additional infrastructure can use R Markdown generate complete website:Put .Rmd files single directory.\nindex.Rmd become home page.Put .Rmd files single directory.\nindex.Rmd become home page.Add YAML file named _site.yml provides navigation site.\nexample:\nname: \"-website\"\nnavbar:\n  title: \"Website\"\n  left:\n    - text: \"Home\"\n      href: index.html\n    - text: \"Viridis Colors\"\n      href: 1-example.html\n    - text: \"Terrain Colors\"\n      href: 3-inline.htmlAdd YAML file named _site.yml provides navigation site.\nexample:Execute rmarkdown::render_site() build _site, directory files ready deploy standalone static website, use RStudio Project website directory.\nRStudio add Build tab IDE can use build preview site.Read http://rmarkdown.rstudio.com/rmarkdown_websites.html.","code":"name: \"my-website\"\nnavbar:\n  title: \"My Website\"\n  left:\n    - text: \"Home\"\n      href: index.html\n    - text: \"Viridis Colors\"\n      href: 1-example.html\n    - text: \"Terrain Colors\"\n      href: 3-inline.html"},{"path":"r-markdown-formats.html","id":"other-formats","chapter":"41 R Markdown formats","heading":"41.9 Other formats","text":"packages provide even output formats:bookdown package, https://github.com/rstudio/bookdown, makes easy write books, like one.\nlearn , read Authoring Books R Markdown, Yihui Xie, , course, written bookdown.\nVisit http://www.bookdown.org see bookdown books written wider R community.bookdown package, https://github.com/rstudio/bookdown, makes easy write books, like one.\nlearn , read Authoring Books R Markdown, Yihui Xie, , course, written bookdown.\nVisit http://www.bookdown.org see bookdown books written wider R community.prettydoc package, https://github.com/yixuan/prettydoc/, provides lightweight document formats range attractive themes.prettydoc package, https://github.com/yixuan/prettydoc/, provides lightweight document formats range attractive themes.rticles package, https://github.com/rstudio/rticles, compiles selection formats tailored specific scientific journals.rticles package, https://github.com/rstudio/rticles, compiles selection formats tailored specific scientific journals.See http://rmarkdown.rstudio.com/formats.html list even formats.\ncan also create following instructions http://rmarkdown.rstudio.com/developer_custom_formats.html.","code":""},{"path":"r-markdown-formats.html","id":"learning-more-5","chapter":"41 R Markdown formats","heading":"41.10 Learning more","text":"learn effective communication different formats recommend following resources:improve presentation skills, recommend Presentation Patterns, Neal Ford, Matthew McCollough, Nathaniel Schutta.\nprovides set effective patterns (low- high-level) can apply improve presentations.improve presentation skills, recommend Presentation Patterns, Neal Ford, Matthew McCollough, Nathaniel Schutta.\nprovides set effective patterns (low- high-level) can apply improve presentations.give academic talks, recommend reading Leek group guide giving talks.give academic talks, recommend reading Leek group guide giving talks.haven’t taken , ’ve heard good things Matt McGarrity’s online course public speaking: https://www.coursera.org/learn/public-speaking.haven’t taken , ’ve heard good things Matt McGarrity’s online course public speaking: https://www.coursera.org/learn/public-speaking.creating lot dashboards, make sure read Stephen ’s Information Dashboard Design: Effective Visual Communication Data.\nhelp create dashboards truly useful, just pretty look .creating lot dashboards, make sure read Stephen ’s Information Dashboard Design: Effective Visual Communication Data.\nhelp create dashboards truly useful, just pretty look .Effectively communicating ideas often benefits knowledge graphic design.\nNon-Designer’s Design Book great place start.Effectively communicating ideas often benefits knowledge graphic design.\nNon-Designer’s Design Book great place start.","code":""},{"path":"r-markdown-workflow.html","id":"r-markdown-workflow","chapter":"42 R Markdown workflow","heading":"42 R Markdown workflow","text":"Earlier, discussed basic workflow capturing R code work interactively console, capture works script editor.\nR Markdown brings together console script editor, blurring lines interactive exploration long-term code capture.\ncan rapidly iterate within chunk, editing re-executing Cmd/Ctrl + Shift + Enter.\n’re happy, move start new chunk.R Markdown also important tightly integrates prose code.\nmakes great analysis notebook lets develop code record thoughts.\nanalysis notebook shares many goals classic lab notebook physical sciences.\n:Records .\nRegardless great memory , don’t record , come time forgotten important details.\nWrite don’t forget!Records .\nRegardless great memory , don’t record , come time forgotten important details.\nWrite don’t forget!Supports rigorous thinking.\nlikely come strong analysis record thoughts go, continue reflect .\nalso saves time eventually write analysis share others.Supports rigorous thinking.\nlikely come strong analysis record thoughts go, continue reflect .\nalso saves time eventually write analysis share others.Helps others understand work.\nrare data analysis , ’ll often working part team.\nlab notebook helps share ’ve done, colleagues lab mates.Helps others understand work.\nrare data analysis , ’ll often working part team.\nlab notebook helps share ’ve done, colleagues lab mates.Much good advice using lab notebooks effectively can also translated analysis notebooks.\n’ve drawn experiences Colin Purrington’s advice lab notebooks (http://colinpurrington.com/tips/lab-notebooks) come following tips:Ensure notebook descriptive title, evocative filename, first paragraph briefly describes aims analysis.Ensure notebook descriptive title, evocative filename, first paragraph briefly describes aims analysis.Use YAML header date field record date started working notebook:\ndate: 2016-08-23\nUse ISO8601 YYYY-MM-DD format ’s ambiguity.\nUse even don’t normally write dates way!Use YAML header date field record date started working notebook:Use ISO8601 YYYY-MM-DD format ’s ambiguity.\nUse even don’t normally write dates way!spend lot time analysis idea turns dead end, don’t delete !\nWrite brief note failed leave notebook.\nhelp avoid going dead end come back analysis future.spend lot time analysis idea turns dead end, don’t delete !\nWrite brief note failed leave notebook.\nhelp avoid going dead end come back analysis future.Generally, ’re better data entry outside R.\nneed record small snippet data, clearly lay using tibble::tribble().Generally, ’re better data entry outside R.\nneed record small snippet data, clearly lay using tibble::tribble().discover error data file, never modify directly, instead write code correct value.\nExplain made fix.discover error data file, never modify directly, instead write code correct value.\nExplain made fix.finish day, make sure can knit notebook (’re using caching, make sure clear caches).\nlet fix problems code still fresh mind.finish day, make sure can knit notebook (’re using caching, make sure clear caches).\nlet fix problems code still fresh mind.want code reproducible long-run (.e. can come back run next month next year), ’ll need track versions packages code uses.\nrigorous approach use packrat, http://rstudio.github.io/packrat/, stores packages project directory, checkpoint, https://github.com/RevolutionAnalytics/checkpoint, reinstall packages available specified date.\nquick dirty hack include chunk runs sessionInfo() — won’t let easily recreate packages today, least ’ll know .want code reproducible long-run (.e. can come back run next month next year), ’ll need track versions packages code uses.\nrigorous approach use packrat, http://rstudio.github.io/packrat/, stores packages project directory, checkpoint, https://github.com/RevolutionAnalytics/checkpoint, reinstall packages available specified date.\nquick dirty hack include chunk runs sessionInfo() — won’t let easily recreate packages today, least ’ll know .going create many, many, many analysis notebooks course career.\ngoing organise can find future?\nrecommend storing individual projects, coming good naming scheme.going create many, many, many analysis notebooks course career.\ngoing organise can find future?\nrecommend storing individual projects, coming good naming scheme.","code":"date: 2016-08-23"}]
